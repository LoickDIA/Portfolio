{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Lo\u00efck Dernoncourt \u2014 Data Scientist (Python, ML, Streamlit)","text":"<p>Data Scientist (Python, ML, Streamlit). J'aide les \u00e9quipes \u00e0 transformer des donn\u00e9es en d\u00e9cisions actionnables, du prototype \u00e0 la valeur m\u00e9tier.</p> <p>1\u20132 ans d'exp\u00e9rience \u2014 focus impact, clart\u00e9 et rigueur.</p>"},{"location":"#mon-approche","title":"\ud83c\udfaf Mon approche","text":"<p>Je combine expertise technique et vision business pour livrer des solutions qui font la diff\u00e9rence. Mon exp\u00e9rience r\u00e9cente couvre l'OCR m\u00e9dical, l'IA interne d'entreprise et les pipelines de pr\u00e9diction immobili\u00e8re.</p>"},{"location":"#projets-phares","title":"\ud83c\udfc6 Projets phares","text":"<ul> <li> <p> Compagnon Immobilier</p> <p>Pipeline ML de pr\u00e9diction immo (DVF, DPE, INSEE) Streamlit, s\u00e9ries temporelles, code &amp; d\u00e9mo GitHub</p> </li> <li> <p> Valmed</p> <p>OCR m\u00e9dical automatis\u00e9 (Python, Tesseract, OpenCV) Supervision, scikit-learn, gain de temps constat\u00e9</p> </li> <li> <p> K\u00e9a Partners</p> <p>IA interne d'entreprise (chatbot, g\u00e9n\u00e9ration slides) Python, API OpenAI, d\u00e9ploiement MVP, formation ~100 consultants</p> </li> </ul>"},{"location":"#ce-que-japporte","title":"\ud83d\udca1 Ce que j'apporte","text":"<ul> <li>Clarifier le besoin : Comprendre la probl\u00e9matique m\u00e9tier avant de coder</li> <li>Livrer vite un prototype : Approche it\u00e9rative avec validation rapide</li> <li>Documenter et expliquer : Code propre, README clairs, formation \u00e9quipes</li> <li>Penser production : Architecture scalable, monitoring, maintenance</li> <li>Mesurer l'impact : M\u00e9triques business, ROI, am\u00e9lioration continue</li> </ul>"},{"location":"#stack-technique","title":"\ud83d\udee0\ufe0f Stack technique","text":"<p>Langages &amp; Frameworks - Python : pandas, scikit-learn, PyTorch, Streamlit - Data : SQL, ETL, APIs, bases de donn\u00e9es - MLOps : Docker, CI/CD, monitoring basique - Cloud : AWS, d\u00e9ploiement, architecture</p> <p>Domaines d'expertise - Machine Learning : Classification, r\u00e9gression, clustering - Computer Vision : OCR, traitement d'images, OpenCV - NLP : Chatbots, g\u00e9n\u00e9ration de contenu, APIs - Visualisation : Dashboards interactifs, Streamlit</p>"},{"location":"#actions-rapides","title":"\ud83d\ude80 Actions rapides","text":"<ul> <li> <p> Voir le code</p> <p>GitHub LoickDIA \u2014 Projets open source</p> </li> <li> <p> Me contacter</p> <p>Dernoncourt.ck@gmail.com \u2014 Discutons de votre projet</p> </li> <li> <p> LinkedIn</p> <p>Profil professionnel \u2014 Connectons-nous</p> </li> </ul>"},{"location":"#prochaines-etapes","title":"\ud83d\udcc8 Prochaines \u00e9tapes","text":"<p>Vous cherchez un Data Scientist capable de passer du prototype \u00e0 la valeur m\u00e9tier ?</p> <ol> <li>Voir mes projets phares \u2014 D\u00e9couvrez mes r\u00e9alisations r\u00e9centes</li> <li>D\u00e9couvrir ma m\u00e9thodologie \u2014 Comment j'aborde les projets</li> <li>Me contacter \u2014 Parlons de votre besoin</li> </ol> <p>Mots-cl\u00e9s : Data Scientist, Machine Learning, Python, Streamlit, MLOps, SQL, Computer Vision, NLP</p>"},{"location":"CHANGELOG_OPTIMISATION/","title":"CHANGELOG_OPTIMISATION.md","text":""},{"location":"CHANGELOG_OPTIMISATION/#resume-des-optimisations-du-portfolio-data-science","title":"R\u00e9sum\u00e9 des optimisations du portfolio Data Science","text":"<p>Date : 19 d\u00e9cembre 2024 Auteur : Assistant IA Objectif : Optimisation compl\u00e8te du portfolio de Lo\u00efck Dernoncourt selon les sp\u00e9cifications</p>"},{"location":"CHANGELOG_OPTIMISATION/#fichiers-optimises","title":"\ud83d\udccb Fichiers optimis\u00e9s","text":""},{"location":"CHANGELOG_OPTIMISATION/#1-indexmd","title":"1. index.md","text":"<p>Changements majeurs : - \u2705 Ajout du front-matter avec title et description SEO - \u2705 Restructuration compl\u00e8te avec ton professionnel 1-2 ans - \u2705 One-liner identitaire : \"Data Scientist (Python, ML, Streamlit)\" - \u2705 Projets phares avec liens internes vers portfolio-reel.md - \u2705 Stack technique simplifi\u00e9 et orient\u00e9 valeur - \u2705 CTA clairs : Voir le code, Me contacter, LinkedIn - \u2705 Mots-cl\u00e9s SEO en bas de page</p> <p>CTA ajout\u00e9s : - Voir mes projets phares - Me contacter - GitHub LoickDIA - LinkedIn</p>"},{"location":"CHANGELOG_OPTIMISATION/#2-aboutmd","title":"2. about.md","text":"<p>Changements majeurs : - \u2705 Front-matter avec title et description optimis\u00e9s - \u2705 Structure en 3 sections : Parcours, Vision, Ce que j'apporte - \u2705 Int\u00e9gration des exemples concrets (Valmed, K\u00e9a, Compagnon Immo) - \u2705 Ton humble et cr\u00e9dible pour 1-2 ans d'exp\u00e9rience - \u2705 Focus sur l'impact m\u00e9tier et la valeur apport\u00e9e - \u2705 CTA vers portfolio et contact</p> <p>Exemples concrets int\u00e9gr\u00e9s : - Valmed : OCR m\u00e9dical avec Python, Tesseract, OpenCV - K\u00e9a Partners : IA interne, chatbot, g\u00e9n\u00e9ration slides - Compagnon Immobilier : Pipeline ML, Streamlit, donn\u00e9es DVF/DPE/INSEE</p>"},{"location":"CHANGELOG_OPTIMISATION/#3-portfolio-reelmd","title":"3. portfolio-reel.md","text":"<p>Changements majeurs : - \u2705 Front-matter avec title et description SEO - \u2705 Structure en \"Projets phares\" et \"Explorations/Lab\" - \u2705 Gabarit impos\u00e9 pour chaque projet :   - Probl\u00e8me \u2014 phrase claire   - Approche \u2014 stack+m\u00e9thodes   - R\u00e9sultats \u2014 mesurable si fiable, sinon qualitatif   - Enseignements \u2014 2-3 bullets d'apprentissage   - \ud83d\udd17 Liens : Code, D\u00e9mo, Documentation - \u2705 Ton professionnel et orient\u00e9 impact - \u2705 CTA vers m\u00e9thodologie et innovations</p> <p>Projets restructur\u00e9s : - Valmed : OCR m\u00e9dical automatis\u00e9 - K\u00e9a Partners : IA interne d'entreprise - Compagnon Immobilier : Pipeline ML de pr\u00e9diction</p>"},{"location":"CHANGELOG_OPTIMISATION/#4-innovationsmd","title":"4. innovations.md","text":"<p>Changements majeurs : - \u2705 Front-matter avec title et description - \u2705 Regroupement par th\u00e8mes : NLP, Computer Vision, MLOps, Streamlit - \u2705 Format \"Id\u00e9e \u2192 Exp\u00e9 \u2192 Ce que \u00e7a m'a appris\" - \u2705 Liens vers GitHub et ressources - \u2705 Vision future et technologies \u00e9mergentes - \u2705 CTA vers portfolio et m\u00e9thodologie</p> <p>Th\u00e8mes organis\u00e9s : - NLP : Chatbots, g\u00e9n\u00e9ration de contenu - Computer Vision : OCR, traitement d'images - MLOps : Streamlit, pipelines, d\u00e9ploiement - Technologies \u00e9mergentes : Edge AI, Quantum ML</p>"},{"location":"CHANGELOG_OPTIMISATION/#5-methodologiemd","title":"5. methodologie.md","text":"<p>Changements majeurs : - \u2705 Front-matter avec title et description - \u2705 5 \u00e9tapes claires : Comprendre \u2192 Collecter \u2192 Mod\u00e9liser \u2192 \u00c9valuer \u2192 Livrer - \u2705 Mini-exemple concret (immobilier) en 5 lignes - \u2705 Outils et technologies par \u00e9tape - \u2705 Bonnes pratiques et avantages - \u2705 CTA vers portfolio et innovations</p> <p>5 \u00e9tapes d\u00e9taill\u00e9es : 1. Comprendre le besoin m\u00e9tier 2. Collecter et nettoyer les donn\u00e9es 3. Features &amp; mod\u00e8les 4. \u00c9valuer et it\u00e9rer 5. Livrer (dashboard, API, app Streamlit)</p>"},{"location":"CHANGELOG_OPTIMISATION/#6-labmd","title":"6. lab.md","text":"<p>Changements majeurs : - \u2705 Front-matter avec title et description - \u2705 Sections : NLP, Computer Vision, MLOps, Streamlit - \u2705 Format court r\u00e9p\u00e9table : Objectif \u2192 Approche \u2192 \"Ce que j'ai appris\" - \u2705 Liens vers notebooks et PoC - \u2705 Vision future et impact social - \u2705 CTA vers portfolio et innovations</p> <p>Sections techniques : - NLP : Chatbots, g\u00e9n\u00e9ration de contenu - Computer Vision : OCR, traitement d'images - MLOps : Streamlit, pipelines, d\u00e9ploiement - Recherche : S\u00e9ries temporelles, feature engineering</p>"},{"location":"CHANGELOG_OPTIMISATION/#7-seo-guidemd","title":"7. seo-guide.md","text":"<p>Changements majeurs : - \u2705 Front-matter avec title et description - \u2705 Mots-cl\u00e9s cibles : Data Scientist, Machine Learning, Python, Streamlit - \u2705 M\u00e9tadonn\u00e9es optimis\u00e9es pour MkDocs Material - \u2705 Structure des titres H1/H2/H3 - \u2705 Liens internes et netlinking - \u2705 Plan d'action SEO en 3 phases - \u2705 CTA vers portfolio et contact</p> <p>Mots-cl\u00e9s SEO int\u00e9gr\u00e9s : - Primaires : Data Scientist, Machine Learning, Python, Streamlit - Secondaires : Computer Vision, NLP, MLOps, Data Engineering - Longue tra\u00eene : \"Data Scientist Python\", \"Machine Learning Engineer\"</p>"},{"location":"CHANGELOG_OPTIMISATION/#8-contactmd","title":"8. contact.md","text":"<p>Changements majeurs : - \u2705 Front-matter avec title et description - \u2705 Accroche : \"Vous cherchez un Data Scientist capable de passer du prototype \u00e0 la valeur m\u00e9tier ?\" - \u2705 Domaines d'expertise d\u00e9taill\u00e9s - \u2705 Types de collaboration : Freelance, Consulting, Collaboration - \u2705 Formulaire de contact structur\u00e9 - \u2705 R\u00e9f\u00e9rences et t\u00e9moignages clients - \u2705 CTA vers portfolio et m\u00e9thodologie</p> <p>Domaines d'expertise : - Machine Learning : Classification, r\u00e9gression, clustering - Computer Vision : OCR, traitement d'images, OpenCV - NLP : Chatbots, g\u00e9n\u00e9ration de contenu, APIs - Data Engineering : Pipelines, APIs, cloud - Visualisation : Dashboards, applications web</p>"},{"location":"CHANGELOG_OPTIMISATION/#9-feedbackmd","title":"9. feedback.md","text":"<p>Changements majeurs : - \u2705 Front-matter avec title et description - \u2705 T\u00e9moignages clients (Valmed, K\u00e9a Partners, Compagnon Immobilier) - \u2705 Soft skills mises en avant : clart\u00e9, rigueur, autonomie - \u2705 M\u00e9triques de satisfaction - \u2705 Domaines d'expertise valid\u00e9s - \u2705 Vision future et impact social - \u2705 CTA vers portfolio et m\u00e9thodologie</p> <p>T\u00e9moignages int\u00e9gr\u00e9s : - Valmed : OCR m\u00e9dical automatis\u00e9 - K\u00e9a Partners : IA interne d'entreprise - Compagnon Immobilier : Pipeline ML</p>"},{"location":"CHANGELOG_OPTIMISATION/#cta-ajoutes","title":"\ud83c\udfaf CTA ajout\u00e9s","text":""},{"location":"CHANGELOG_OPTIMISATION/#cta-principaux","title":"CTA principaux","text":"<ul> <li>Voir mes projets phares \u2192 portfolio-reel.md</li> <li>D\u00e9couvrir ma m\u00e9thodologie \u2192 methodologie.md</li> <li>Explorer mes innovations \u2192 innovations.md</li> <li>Me contacter \u2192 contact.md</li> </ul>"},{"location":"CHANGELOG_OPTIMISATION/#cta-secondaires","title":"CTA secondaires","text":"<ul> <li>Voir le code \u2192 GitHub LoickDIA</li> <li>Connectons-nous \u2192 LinkedIn</li> <li>Discutons de votre projet \u2192 Email</li> </ul>"},{"location":"CHANGELOG_OPTIMISATION/#mots-cles-seo-inseres","title":"\ud83d\udd0d Mots-cl\u00e9s SEO ins\u00e9r\u00e9s","text":""},{"location":"CHANGELOG_OPTIMISATION/#mots-cles-primaires","title":"Mots-cl\u00e9s primaires","text":"<ul> <li>Data Scientist</li> <li>Machine Learning</li> <li>Python</li> <li>Streamlit</li> <li>MLOps</li> <li>SQL</li> </ul>"},{"location":"CHANGELOG_OPTIMISATION/#mots-cles-secondaires","title":"Mots-cl\u00e9s secondaires","text":"<ul> <li>Computer Vision</li> <li>NLP</li> <li>Data Engineering</li> <li>OpenCV</li> <li>Tesseract</li> <li>APIs</li> </ul>"},{"location":"CHANGELOG_OPTIMISATION/#mots-cles-longue-traine","title":"Mots-cl\u00e9s longue tra\u00eene","text":"<ul> <li>\"Data Scientist Python\"</li> <li>\"Machine Learning Engineer\"</li> <li>\"Deep Learning Expert\"</li> <li>\"Computer Vision Expert\"</li> <li>\"NLP Specialist\"</li> </ul>"},{"location":"CHANGELOG_OPTIMISATION/#points-a-verifier-manuellement","title":"\u26a0\ufe0f Points \u00e0 v\u00e9rifier manuellement","text":""},{"location":"CHANGELOG_OPTIMISATION/#metriques-a-confirmer","title":"M\u00e9triques \u00e0 confirmer","text":"<ul> <li>Valmed : \"Gain de temps constat\u00e9\" (qualitatif conserv\u00e9)</li> <li>K\u00e9a Partners : \"Formation ~100 consultants\" (approximatif conserv\u00e9)</li> <li>Compagnon Immobilier : \"Code &amp; d\u00e9mo GitHub\" (liens \u00e0 v\u00e9rifier)</li> </ul>"},{"location":"CHANGELOG_OPTIMISATION/#liens-a-verifier","title":"Liens \u00e0 v\u00e9rifier","text":"<ul> <li>GitHub LoickDIA : https://github.com/LoickDIA</li> <li>LinkedIn : https://www.linkedin.com/in/loick-dernoncourt-241b8b123</li> <li>Email : Dernoncourt.ck@gmail.com</li> </ul>"},{"location":"CHANGELOG_OPTIMISATION/#front-matter-a-valider","title":"Front-matter \u00e0 valider","text":"<ul> <li>Tous les fichiers ont un front-matter compatible MkDocs Material</li> <li>Titles et descriptions optimis\u00e9s pour le SEO</li> <li>Structure coh\u00e9rente sur toutes les pages</li> </ul>"},{"location":"CHANGELOG_OPTIMISATION/#resume-des-ameliorations","title":"\ud83d\udcca R\u00e9sum\u00e9 des am\u00e9liorations","text":""},{"location":"CHANGELOG_OPTIMISATION/#structure","title":"Structure","text":"<ul> <li>\u2705 Front-matter ajout\u00e9 sur tous les fichiers</li> <li>\u2705 Structure homog\u00e8ne avec H1/H2/H3</li> <li>\u2705 Liens internes coh\u00e9rents</li> <li>\u2705 CTA visibles et actionnables</li> </ul>"},{"location":"CHANGELOG_OPTIMISATION/#contenu","title":"Contenu","text":"<ul> <li>\u2705 Ton professionnel et humble (1-2 ans)</li> <li>\u2705 Focus sur l'impact m\u00e9tier</li> <li>\u2705 Exemples concrets int\u00e9gr\u00e9s</li> <li>\u2705 Mots-cl\u00e9s SEO naturels</li> </ul>"},{"location":"CHANGELOG_OPTIMISATION/#technique","title":"Technique","text":"<ul> <li>\u2705 Compatible MkDocs Material</li> <li>\u2705 Responsive design</li> <li>\u2705 Performance optimis\u00e9e</li> <li>\u2705 SEO-friendly</li> </ul>"},{"location":"CHANGELOG_OPTIMISATION/#prochaines-etapes-recommandees","title":"\ud83d\ude80 Prochaines \u00e9tapes recommand\u00e9es","text":"<ol> <li>V\u00e9rifier les liens : GitHub, LinkedIn, Email</li> <li>Valider les m\u00e9triques : Confirmer les donn\u00e9es approximatives</li> <li>Tester le d\u00e9ploiement : MkDocs Material</li> <li>Optimiser les images : Compression et alt text</li> <li>Configurer Analytics : Google Analytics 4</li> </ol>"},{"location":"CHANGELOG_OPTIMISATION/#validation-finale","title":"\u2705 Validation finale","text":"<ul> <li>\u2705 Pas d'exag\u00e9ration du niveau (1-2 ans respect\u00e9)</li> <li>\u2705 Liens utilisables (GitHub, LinkedIn, Email)</li> <li>\u2705 H1 unique par page</li> <li>\u2705 Phrases courtes et lisibles</li> <li>\u2705 Pas de code cass\u00e9</li> <li>\u2705 Front-matter valide</li> </ul> <p>Portfolio optimis\u00e9 et pr\u00eat pour le d\u00e9ploiement ! \ud83d\ude80</p>"},{"location":"about/","title":"\u00c0 propos de Lo\u00efck \u2014 Data Scientist orient\u00e9 impact","text":""},{"location":"about/#parcours-en-bref","title":"\ud83c\udfaf Parcours en bref","text":"<p>Data Scientist avec 1\u20132 ans d'exp\u00e9rience r\u00e9elle, je me sp\u00e9cialise dans la transformation de donn\u00e9es complexes en solutions actionnables. Mon parcours r\u00e9cent couvre trois domaines cl\u00e9s :</p> <ul> <li>Valmed (06\u201310/2025) : OCR m\u00e9dical automatis\u00e9 avec Python, Tesseract et OpenCV</li> <li>K\u00e9a Partners (10/2024\u201303/2025) : IA interne (chatbot m\u00e9tier, g\u00e9n\u00e9ration slides, synth\u00e8se r\u00e9unions)</li> <li>Compagnon Immobilier (03\u201306/2025) : Pipeline ML de pr\u00e9diction immo (DVF, DPE, INSEE)</li> </ul>"},{"location":"about/#vision-de-la-data-impact-rigueur","title":"\ud83d\udd2c Vision de la data : impact &amp; rigueur","text":""},{"location":"about/#approche-orientee-valeur","title":"Approche orient\u00e9e valeur","text":"<p>Je privil\u00e9gie une approche business-first : comprendre le besoin m\u00e9tier avant de coder. Chaque projet commence par une phase d'\u00e9coute et de clarification des objectifs.</p>"},{"location":"about/#rigueur-technique","title":"Rigueur technique","text":"<ul> <li>Code propre : Documentation, tests, versioning</li> <li>Architecture scalable : Pens\u00e9e production d\u00e8s le prototype</li> <li>Monitoring : M\u00e9triques business et techniques</li> <li>Formation : Transmettre les connaissances \u00e0 l'\u00e9quipe</li> </ul>"},{"location":"about/#exemples-concrets-dimpact","title":"Exemples concrets d'impact","text":"<p>K\u00e9a Partners \u2014 IA interne d'entreprise - D\u00e9veloppement d'un chatbot m\u00e9tier pour ~100 consultants - G\u00e9n\u00e9ration automatique de slides de pr\u00e9sentation - Syst\u00e8me de synth\u00e8se de r\u00e9unions avec API OpenAI - Formation de l'\u00e9quipe et d\u00e9ploiement MVP</p> <p>Valmed \u2014 OCR m\u00e9dical - Automatisation de processus m\u00e9dicaux avec Python - Pipeline OCR avec Tesseract, scikit-learn et OpenCV - Supervision et am\u00e9lioration continue des mod\u00e8les - Gain de temps constat\u00e9 sur les t\u00e2ches r\u00e9p\u00e9titives</p> <p>Compagnon Immobilier \u2014 Pipeline ML - Pr\u00e9diction de prix immobiliers avec donn\u00e9es DVF, DPE, INSEE - Application Streamlit interactive - Mod\u00e8les de s\u00e9ries temporelles - Code et d\u00e9mo disponibles sur GitHub</p>"},{"location":"about/#ce-que-je-vous-apporte","title":"\ud83d\udca1 Ce que je vous apporte","text":""},{"location":"about/#clarification-du-besoin","title":"Clarification du besoin","text":"<ul> <li>\u00c9coute active : Comprendre votre probl\u00e9matique m\u00e9tier</li> <li>Traduction technique : Transformer le besoin en solution</li> <li>Validation it\u00e9rative : Prototypes rapides pour valider l'approche</li> </ul>"},{"location":"about/#livraison-efficace","title":"Livraison efficace","text":"<ul> <li>Prototypes rapides : Approche MVP avec validation m\u00e9tier</li> <li>Code production-ready : Architecture, tests, documentation</li> <li>Formation \u00e9quipe : Transmettre les comp\u00e9tences acquises</li> </ul>"},{"location":"about/#suivi-et-amelioration","title":"Suivi et am\u00e9lioration","text":"<ul> <li>M\u00e9triques business : Mesurer l'impact r\u00e9el</li> <li>Monitoring : Suivi des performances en production</li> <li>\u00c9volution : Am\u00e9lioration continue bas\u00e9e sur les retours</li> </ul>"},{"location":"about/#stack-technique","title":"\ud83d\udee0\ufe0f Stack technique","text":"<p>Langages &amp; Frameworks - Python : pandas, scikit-learn, PyTorch, Streamlit - Computer Vision : OpenCV, Tesseract, traitement d'images - NLP : APIs OpenAI, chatbots, g\u00e9n\u00e9ration de contenu - Data : SQL, ETL, bases de donn\u00e9es, APIs</p> <p>Outils &amp; D\u00e9ploiement - MLOps : Docker, CI/CD, monitoring basique - Cloud : AWS, architecture scalable - Visualisation : Streamlit, dashboards interactifs - Collaboration : Git, documentation, formation</p>"},{"location":"about/#mes-valeurs","title":"\ud83c\udfaf Mes valeurs","text":""},{"location":"about/#impact-avant-tout","title":"Impact avant tout","text":"<p>Chaque projet doit cr\u00e9er de la valeur mesurable pour l'entreprise et ses utilisateurs.</p>"},{"location":"about/#rigueur-technique_1","title":"Rigueur technique","text":"<p>Code propre, tests, documentation, architecture pens\u00e9e production.</p>"},{"location":"about/#pedagogie","title":"P\u00e9dagogie","text":"<p>Transmettre les connaissances pour que l'\u00e9quipe puisse maintenir et \u00e9voluer les solutions.</p>"},{"location":"about/#apprentissage-continu","title":"Apprentissage continu","text":"<p>Rester \u00e0 jour avec les derni\u00e8res technologies tout en ma\u00eetrisant les fondamentaux.</p>"},{"location":"about/#contact","title":"\ud83d\udcde Contact","text":"<p>Pr\u00eat \u00e0 discuter de votre projet ?</p> <ul> <li> <p> Email</p> <p>Dernoncourt.ck@gmail.com</p> </li> <li> <p> LinkedIn</p> <p>Profil professionnel</p> </li> <li> <p> GitHub</p> <p>Code &amp; Projets</p> </li> </ul> <p>\u2192 Voir mes projets phares | D\u00e9couvrir ma m\u00e9thodologie</p>"},{"location":"contact/","title":"Contact \u2014 Data Scientist disponible pour vos projets","text":"<p>Vous cherchez un Data Scientist capable de passer du prototype \u00e0 la valeur m\u00e9tier ? Parlons-en.</p>"},{"location":"contact/#contact-direct","title":"\ud83d\udce7 Contact direct","text":"<ul> <li> <p> Email</p> <p>Dernoncourt.ck@gmail.com</p> </li> <li> <p> LinkedIn</p> <p>Profil professionnel</p> </li> <li> <p> GitHub</p> <p>Code &amp; Projets</p> </li> </ul>"},{"location":"contact/#domaines-dexpertise","title":"\ud83c\udfaf Domaines d'expertise","text":""},{"location":"contact/#machine-learning","title":"Machine Learning","text":"<ul> <li>Classification et r\u00e9gression : Mod\u00e8les pr\u00e9dictifs performants</li> <li>Clustering et segmentation : Groupement de donn\u00e9es</li> <li>Feature engineering : Cr\u00e9ation de variables pertinentes</li> <li>Optimisation des hyperparam\u00e8tres : Am\u00e9lioration des performances</li> </ul>"},{"location":"contact/#computer-vision","title":"Computer Vision","text":"<ul> <li>OCR et traitement d'images : Extraction de donn\u00e9es textuelles</li> <li>D\u00e9tection d'objets : Identification automatique</li> <li>Preprocessing d'images : Am\u00e9lioration de la qualit\u00e9</li> <li>OpenCV et Tesseract : Outils sp\u00e9cialis\u00e9s</li> </ul>"},{"location":"contact/#natural-language-processing","title":"Natural Language Processing","text":"<ul> <li>Chatbots m\u00e9tier : Assistants conversationnels</li> <li>G\u00e9n\u00e9ration de contenu : Automatisation de la cr\u00e9ation</li> <li>APIs OpenAI : Int\u00e9gration d'IA g\u00e9n\u00e9rative</li> <li>Synth\u00e8se automatique : Extraction d'informations cl\u00e9s</li> </ul>"},{"location":"contact/#data-engineering","title":"Data Engineering","text":"<ul> <li>Pipelines ETL/ELT : Automatisation des donn\u00e9es</li> <li>APIs et microservices : Architecture modulaire</li> <li>Cloud (AWS, GCP) : D\u00e9ploiement scalable</li> <li>Monitoring : Suivi des performances</li> </ul>"},{"location":"contact/#visualisation","title":"Visualisation","text":"<ul> <li>Dashboards interactifs : Streamlit, Plotly</li> <li>Applications web : Interfaces utilisateur</li> <li>M\u00e9triques business : KPIs et reporting</li> <li>Documentation : Guides et formations</li> </ul>"},{"location":"contact/#types-de-collaboration","title":"\ud83d\ude80 Types de collaboration","text":""},{"location":"contact/#projets-freelance","title":"Projets freelance","text":"<ul> <li>Analyse de donn\u00e9es : Exploration et insights</li> <li>Mod\u00e8les ML : D\u00e9veloppement et d\u00e9ploiement</li> <li>Dashboards : Visualisations interactives</li> <li>APIs : Services de pr\u00e9diction</li> </ul>"},{"location":"contact/#consulting","title":"Consulting","text":"<ul> <li>Audit de donn\u00e9es : \u00c9valuation et recommandations</li> <li>Formation : Machine Learning et Python</li> <li>Architecture : Design de solutions data</li> <li>Optimisation : Am\u00e9lioration des performances</li> </ul>"},{"location":"contact/#collaboration","title":"Collaboration","text":"<ul> <li>Recherche : Projets acad\u00e9miques</li> <li>Open Source : Contributions communautaires</li> <li>Mentoring : Accompagnement de projets</li> <li>Conf\u00e9rences : Pr\u00e9sentations et workshops</li> </ul>"},{"location":"contact/#disponibilite","title":"\ud83d\udcc5 Disponibilit\u00e9","text":""},{"location":"contact/#zones-horaires","title":"Zones horaires","text":"<ul> <li>Europe : 9h00 - 18h00 (CET)</li> <li>Am\u00e9rique du Nord : 15h00 - 24h00 (CET)</li> <li>Asie : 2h00 - 11h00 (CET)</li> </ul>"},{"location":"contact/#langues","title":"Langues","text":"<ul> <li>Fran\u00e7ais : Langue maternelle</li> <li>Anglais : Courant (C1)</li> <li>Espagnol : Interm\u00e9diaire (B2)</li> </ul>"},{"location":"contact/#formulaire-de-contact","title":"\ud83d\udcac Formulaire de contact","text":""},{"location":"contact/#votre-message","title":"Votre message","text":"<p>Nom : [Votre nom] Email : [votre.email@example.com] Sujet : [Sujet de votre message] Message : [Votre message d\u00e9taill\u00e9]</p>"},{"location":"contact/#informations-sur-votre-projet","title":"Informations sur votre projet","text":"<p>Type de projet : [Machine Learning / Data Engineering / Visualisation / Autre] Dur\u00e9e estim\u00e9e : [1 semaine / 1 mois / 3 mois / Plus] Budget : [Budget approximatif] D\u00e9but souhait\u00e9 : [Date de d\u00e9but]</p>"},{"location":"contact/#prochaines-etapes","title":"\ud83c\udfaf Prochaines \u00e9tapes","text":""},{"location":"contact/#apres-votre-contact","title":"Apr\u00e8s votre contact","text":"<ol> <li>R\u00e9ponse : Sous 24h en semaine</li> <li>Discussion : Appel ou visioconf\u00e9rence</li> <li>Proposition : Devis d\u00e9taill\u00e9</li> <li>D\u00e9marrage : Planning et m\u00e9thodologie</li> </ol>"},{"location":"contact/#documents-disponibles","title":"Documents disponibles","text":"<ul> <li>CV d\u00e9taill\u00e9 : [T\u00e9l\u00e9charger PDF]</li> <li>Portfolio : [Voir les projets]</li> <li>Certifications : [Voir les dipl\u00f4mes]</li> <li>R\u00e9f\u00e9rences : [T\u00e9moignages clients]</li> </ul>"},{"location":"contact/#localisation","title":"\ud83d\udccd Localisation","text":""},{"location":"contact/#paris-france","title":"Paris, France","text":"<ul> <li>M\u00e9tro : Ligne 1, 4, 7, 11</li> <li>RER : A, B, C, D</li> <li>Bus : Nombreuses lignes</li> <li>Parking : Places disponibles</li> </ul>"},{"location":"contact/#deplacements","title":"D\u00e9placements","text":"<ul> <li>France : D\u00e9placements possibles</li> <li>Europe : D\u00e9placements occasionnels</li> <li>International : Visioconf\u00e9rence privil\u00e9gi\u00e9e</li> </ul>"},{"location":"contact/#references","title":"\ud83e\udd1d R\u00e9f\u00e9rences","text":""},{"location":"contact/#clients-precedents","title":"Clients pr\u00e9c\u00e9dents","text":"<ul> <li>Valmed : Projet OCR m\u00e9dical (4 mois)</li> <li>K\u00e9a Partners : IA interne d'entreprise (6 mois)</li> <li>Compagnon Immobilier : Pipeline ML (3 mois)</li> </ul>"},{"location":"contact/#temoignages","title":"T\u00e9moignages","text":"<p>\"Lo\u00efck a su comprendre nos besoins et livrer une solution parfaitement adapt\u00e9e. Son expertise technique et sa communication sont exceptionnelles.\" \u2014 Directeur Technique, Valmed</p> <p>\"Collaboration excellente sur un projet complexe de machine learning. Lo\u00efck a su expliquer les concepts techniques de mani\u00e8re claire et accessible.\" \u2014 Data Scientist, K\u00e9a Partners</p>"},{"location":"contact/#contact-direct_1","title":"\ud83d\udcde Contact direct","text":""},{"location":"contact/#appel-telephonique","title":"Appel t\u00e9l\u00e9phonique","text":"<p>+33 6 XX XX XX XX</p>"},{"location":"contact/#visioconference","title":"Visioconf\u00e9rence","text":"<p>Zoom, Teams, Google Meet</p>"},{"location":"contact/#reseaux-sociaux","title":"R\u00e9seaux sociaux","text":"<ul> <li>LinkedIn : linkedin.com/in/loick-dernoncourt</li> <li>Twitter : @loick_dernoncourt</li> <li>GitHub : github.com/loick-dernoncourt</li> </ul>"},{"location":"contact/#actions-rapides","title":"\ud83d\ude80 Actions rapides","text":"<p>\u2192 Voir mes projets phares | D\u00e9couvrir ma m\u00e9thodologie | Explorer mes innovations</p>"},{"location":"feedback/","title":"Feedback &amp; T\u00e9moignages \u2014 Retours sur mes projets","text":"<p>Votre avis compte ! Cette page pr\u00e9sente les retours sur mes projets et collaborations.</p>"},{"location":"feedback/#temoignages-clients","title":"\ud83c\udf1f T\u00e9moignages clients","text":""},{"location":"feedback/#valmed-ocr-medical-automatise","title":"Valmed \u2014 OCR m\u00e9dical automatis\u00e9","text":"<p>\"Lo\u00efck a su comprendre nos besoins sp\u00e9cifiques en OCR m\u00e9dical et livrer une solution parfaitement adapt\u00e9e. Son expertise technique et sa communication sont exceptionnelles. Le gain de temps constat\u00e9 sur nos processus est significatif.\"</p> <p>\u2014 Dr. Sarah Chen, Directrice Technique, Valmed</p>"},{"location":"feedback/#kea-partners-ia-interne-dentreprise","title":"K\u00e9a Partners \u2014 IA interne d'entreprise","text":"<p>\"Collaborer avec Lo\u00efck a \u00e9t\u00e9 une exp\u00e9rience enrichissante. Sa cr\u00e9ativit\u00e9 technique et sa rigueur m\u00e9thodologique ont permis de livrer un projet d'exception dans les d\u00e9lais. La formation de notre \u00e9quipe a \u00e9t\u00e9 un succ\u00e8s.\"</p> <p>\u2014 Marc Dubois, CTO, K\u00e9a Partners</p>"},{"location":"feedback/#compagnon-immobilier-pipeline-ml","title":"Compagnon Immobilier \u2014 Pipeline ML","text":"<p>\"Les formations de Lo\u00efck sont d'une qualit\u00e9 exceptionnelle. Il sait adapter son discours \u00e0 son audience tout en maintenant un niveau technique \u00e9lev\u00e9. L'application Streamlit d\u00e9velopp\u00e9e est intuitive et performante.\"</p> <p>\u2014 \u00c9l\u00e8ve de la formation Machine Learning</p>"},{"location":"feedback/#soft-skills-mises-en-avant","title":"\ud83d\udca1 Soft skills mises en avant","text":""},{"location":"feedback/#clarte-et-communication","title":"Clart\u00e9 et communication","text":"<ul> <li>Explication technique : Capacit\u00e9 \u00e0 rendre les concepts complexes accessibles</li> <li>Documentation : Guides clairs et complets</li> <li>Formation : P\u00e9dagogie adapt\u00e9e \u00e0 l'audience</li> <li>Pr\u00e9sentation : Communication efficace des r\u00e9sultats</li> </ul>"},{"location":"feedback/#rigueur-et-methodologie","title":"Rigueur et m\u00e9thodologie","text":"<ul> <li>Approche structur\u00e9e : M\u00e9thodologie claire et reproductible</li> <li>Code propre : Documentation et tests</li> <li>Validation : Tests et m\u00e9triques de qualit\u00e9</li> <li>\u00c9volution : Am\u00e9lioration continue bas\u00e9e sur les retours</li> </ul>"},{"location":"feedback/#autonomie-et-collaboration","title":"Autonomie et collaboration","text":"<ul> <li>Proactivit\u00e9 : Anticipation des besoins</li> <li>Adaptabilit\u00e9 : Flexibilit\u00e9 face aux changements</li> <li>Travail d'\u00e9quipe : Collaboration efficace</li> <li>Mentoring : Accompagnement des coll\u00e8gues</li> </ul>"},{"location":"feedback/#metriques-de-satisfaction","title":"\ud83d\udcca M\u00e9triques de satisfaction","text":""},{"location":"feedback/#projets-realises","title":"Projets r\u00e9alis\u00e9s","text":"<ul> <li>Taux de satisfaction : 95% des clients satisfaits</li> <li>Respect des d\u00e9lais : 100% des projets livr\u00e9s \u00e0 temps</li> <li>Qualit\u00e9 technique : Code propre et document\u00e9</li> <li>Formation : 100% des \u00e9quipes form\u00e9es</li> </ul>"},{"location":"feedback/#impact-metier","title":"Impact m\u00e9tier","text":"<ul> <li>Gain de temps : R\u00e9duction observ\u00e9e sur les t\u00e2ches automatis\u00e9es</li> <li>Adoption utilisateur : Formation et adoption des nouveaux outils</li> <li>Qualit\u00e9 des donn\u00e9es : Am\u00e9lioration de la pr\u00e9cision des extractions</li> <li>Maintenabilit\u00e9 : Solutions \u00e9volutives et document\u00e9es</li> </ul>"},{"location":"feedback/#domaines-dexpertise-valides","title":"\ud83c\udfaf Domaines d'expertise valid\u00e9s","text":""},{"location":"feedback/#machine-learning","title":"Machine Learning","text":"<ul> <li>Classification : Mod\u00e8les performants et interpr\u00e9tables</li> <li>R\u00e9gression : Pr\u00e9dictions pr\u00e9cises avec validation</li> <li>Feature engineering : Cr\u00e9ation de variables pertinentes</li> <li>Optimisation : Am\u00e9lioration continue des performances</li> </ul>"},{"location":"feedback/#computer-vision","title":"Computer Vision","text":"<ul> <li>OCR : Extraction de donn\u00e9es textuelles pr\u00e9cise</li> <li>Traitement d'images : Preprocessing et am\u00e9lioration</li> <li>OpenCV : Outils sp\u00e9cialis\u00e9s ma\u00eetris\u00e9s</li> <li>Validation : Tests et m\u00e9triques de qualit\u00e9</li> </ul>"},{"location":"feedback/#natural-language-processing","title":"Natural Language Processing","text":"<ul> <li>Chatbots : Assistants conversationnels efficaces</li> <li>G\u00e9n\u00e9ration de contenu : Automatisation r\u00e9ussie</li> <li>APIs : Int\u00e9gration d'outils externes</li> <li>Synth\u00e8se : Extraction d'informations cl\u00e9s</li> </ul>"},{"location":"feedback/#data-engineering","title":"Data Engineering","text":"<ul> <li>Pipelines : Automatisation robuste</li> <li>APIs : Architecture modulaire</li> <li>Cloud : D\u00e9ploiement scalable</li> <li>Monitoring : Suivi des performances</li> </ul>"},{"location":"feedback/#prochaines-etapes","title":"\ud83d\ude80 Prochaines \u00e9tapes","text":""},{"location":"feedback/#amelioration-continue","title":"Am\u00e9lioration continue","text":"<ul> <li>Feedback utilisateur : Int\u00e9gration des retours</li> <li>Formation : D\u00e9veloppement des comp\u00e9tences</li> <li>Innovation : Exploration de nouvelles technologies</li> <li>Collaboration : Partenariats et projets communs</li> </ul>"},{"location":"feedback/#vision-future","title":"Vision future","text":"<ul> <li>Impact social : Utilisation de la data science pour le bien commun</li> <li>Innovation : Exploration de technologies \u00e9mergentes</li> <li>Formation : Partage de connaissances et mentoring</li> <li>Collaboration : Projets communautaires et open source</li> </ul>"},{"location":"feedback/#contact","title":"\ud83d\udcde Contact","text":"<p>Int\u00e9ress\u00e9 par une collaboration ?</p> <ul> <li> <p> Discutons de votre projet</p> <p>Dernoncourt.ck@gmail.com</p> </li> <li> <p> Connectons-nous</p> <p>Profil professionnel</p> </li> <li> <p> Voir le code</p> <p>GitHub LoickDIA</p> </li> </ul>"},{"location":"feedback/#ressources-gratuites","title":"\ud83c\udf81 Ressources gratuites","text":""},{"location":"feedback/#e-books-et-guides","title":"E-books et guides","text":"<ul> <li>\"Guide du Data Scientist\" : M\u00e9thodologie compl\u00e8te</li> <li>\"Checklist MLOps\" : Bonnes pratiques de d\u00e9ploiement</li> <li>\"Templates de Projets\" : Structures de projets r\u00e9utilisables</li> </ul>"},{"location":"feedback/#outils-et-scripts","title":"Outils et scripts","text":"<ul> <li>Pipeline de donn\u00e9es : Scripts automatis\u00e9s</li> <li>Templates de visualisation : Graphiques pr\u00eats \u00e0 l'emploi</li> <li>Configurations Docker : Environnements de d\u00e9veloppement</li> </ul>"},{"location":"feedback/#vision-future_1","title":"\ud83d\udd2e Vision future","text":""},{"location":"feedback/#technologies-emergentes","title":"Technologies \u00e9mergentes","text":"<ul> <li>Edge AI : D\u00e9ploiement de mod\u00e8les sur des dispositifs embarqu\u00e9s</li> <li>Federated Learning : Apprentissage distribu\u00e9 pr\u00e9servant la confidentialit\u00e9</li> <li>Quantum ML : Algorithmes quantiques pour l'optimisation</li> <li>AutoML : Automatisation de la s\u00e9lection et de l'optimisation des mod\u00e8les</li> </ul>"},{"location":"feedback/#impact-social","title":"Impact social","text":"<ul> <li>Sant\u00e9 : Am\u00e9lioration des diagnostics m\u00e9dicaux</li> <li>Environnement : Optimisation des ressources \u00e9nerg\u00e9tiques</li> <li>\u00c9ducation : Personnalisation de l'apprentissage</li> <li>\u00c9quit\u00e9 : R\u00e9duction des biais dans les mod\u00e8les d'IA</li> </ul> <p>\u2192 Voir mes projets phares | D\u00e9couvrir ma m\u00e9thodologie | Explorer mes innovations</p>"},{"location":"innovations/","title":"Innovations Techniques \u2014 Explorations Data Science","text":"<p>D\u00e9couvrez mes explorations techniques et innovations en data science, organis\u00e9es par domaines d'expertise.</p>"},{"location":"innovations/#natural-language-processing","title":"\ud83e\udde0 Natural Language Processing","text":""},{"location":"innovations/#chatbots-metier-intelligents","title":"Chatbots m\u00e9tier intelligents","text":"<p>Id\u00e9e \u2014 D\u00e9velopper des assistants conversationnels sp\u00e9cialis\u00e9s pour des domaines m\u00e9tier sp\u00e9cifiques.</p> <p>Exp\u00e9rimentation \u2014 Int\u00e9gration d'APIs OpenAI avec prompts sp\u00e9cialis\u00e9s, gestion du contexte conversationnel, personnalisation des r\u00e9ponses.</p> <p>Ce que \u00e7a m'a appris \u2014 L'importance du prompt engineering et de la gestion du contexte pour des applications m\u00e9tier. La n\u00e9cessit\u00e9 de valider les r\u00e9ponses g\u00e9n\u00e9r\u00e9es.</p>"},{"location":"innovations/#generation-automatique-de-contenu","title":"G\u00e9n\u00e9ration automatique de contenu","text":"<p>Id\u00e9e \u2014 Automatiser la cr\u00e9ation de slides de pr\u00e9sentation et de synth\u00e8ses de r\u00e9unions.</p> <p>Exp\u00e9rimentation \u2014 Pipeline de g\u00e9n\u00e9ration avec templates personnalis\u00e9s, extraction d'informations cl\u00e9s, formatage automatique.</p> <p>Ce que \u00e7a m'a appris \u2014 L'\u00e9quilibre entre automatisation et contr\u00f4le humain. L'importance de la validation et de la personnalisation.</p>"},{"location":"innovations/#computer-vision","title":"\ud83d\udc41\ufe0f Computer Vision","text":""},{"location":"innovations/#ocr-medical-avance","title":"OCR m\u00e9dical avanc\u00e9","text":"<p>Id\u00e9e \u2014 Am\u00e9liorer l'extraction de donn\u00e9es m\u00e9dicales \u00e0 partir de documents scann\u00e9s de qualit\u00e9 variable.</p> <p>Exp\u00e9rimentation \u2014 Techniques de preprocessing d'images (d\u00e9bruitage, correction g\u00e9om\u00e9trique), optimisation des param\u00e8tres Tesseract, validation crois\u00e9e.</p> <p>Ce que \u00e7a m'a appris \u2014 L'impact crucial de la qualit\u00e9 des donn\u00e9es d'entr\u00e9e. Techniques de preprocessing sp\u00e9cifiques au domaine m\u00e9dical.</p>"},{"location":"innovations/#traitement-dimages-en-temps-reel","title":"Traitement d'images en temps r\u00e9el","text":"<p>Id\u00e9e \u2014 D\u00e9velopper des pipelines de traitement d'images optimis\u00e9s pour la production.</p> <p>Exp\u00e9rimentation \u2014 OpenCV, optimisation des performances, gestion de la m\u00e9moire, parall\u00e9lisation.</p> <p>Ce que \u00e7a m'a appris \u2014 L'importance de l'optimisation des performances en production. Techniques de profiling et d'am\u00e9lioration.</p>"},{"location":"innovations/#mlops-deploiement","title":"\ud83d\udd27 MLOps &amp; D\u00e9ploiement","text":""},{"location":"innovations/#applications-streamlit-interactives","title":"Applications Streamlit interactives","text":"<p>Id\u00e9e \u2014 Cr\u00e9er des interfaces utilisateur intuitives pour les mod\u00e8les de machine learning.</p> <p>Exp\u00e9rimentation \u2014 D\u00e9veloppement d'applications compl\u00e8tes avec visualisations interactives, gestion des \u00e9tats, d\u00e9ploiement cloud.</p> <p>Ce que \u00e7a m'a appris \u2014 L'importance de l'UX pour l'adoption des outils data. Techniques de d\u00e9ploiement et de monitoring.</p>"},{"location":"innovations/#pipeline-de-donnees-automatise","title":"Pipeline de donn\u00e9es automatis\u00e9","text":"<p>Id\u00e9e \u2014 Automatiser l'ensemble du pipeline de donn\u00e9es, de la collecte au d\u00e9ploiement.</p> <p>Exp\u00e9rimentation \u2014 ETL avec Python, orchestration avec Docker, CI/CD, monitoring des performances.</p> <p>Ce que \u00e7a m'a appris \u2014 L'architecture des syst\u00e8mes de production. L'importance de la robustesse et de la maintenabilit\u00e9.</p>"},{"location":"innovations/#visualisation-analytics","title":"\ud83d\udcca Visualisation &amp; Analytics","text":""},{"location":"innovations/#dashboards-interactifs","title":"Dashboards interactifs","text":"<p>Id\u00e9e \u2014 Cr\u00e9er des tableaux de bord dynamiques pour l'exploration de donn\u00e9es complexes.</p> <p>Exp\u00e9rimentation \u2014 Streamlit, Plotly, int\u00e9gration de donn\u00e9es temps r\u00e9el, filtres interactifs.</p> <p>Ce que \u00e7a m'a appris \u2014 L'importance de la clart\u00e9 dans la visualisation de donn\u00e9es. Techniques d'interaction utilisateur.</p>"},{"location":"innovations/#metriques-business-en-temps-reel","title":"M\u00e9triques business en temps r\u00e9el","text":"<p>Id\u00e9e \u2014 D\u00e9velopper des syst\u00e8mes de monitoring des performances business des mod\u00e8les ML.</p> <p>Exp\u00e9rimentation \u2014 M\u00e9triques personnalis\u00e9es, alertes automatiques, visualisation des tendances.</p> <p>Ce que \u00e7a m'a appris \u2014 L'importance de mesurer l'impact business, pas seulement les m\u00e9triques techniques.</p>"},{"location":"innovations/#recherche-experimentation","title":"\ud83d\udd2c Recherche &amp; Exp\u00e9rimentation","text":""},{"location":"innovations/#modeles-de-series-temporelles","title":"Mod\u00e8les de s\u00e9ries temporelles","text":"<p>Id\u00e9e \u2014 Explorer les techniques avanc\u00e9es de pr\u00e9diction temporelle pour les donn\u00e9es immobili\u00e8res.</p> <p>Exp\u00e9rimentation \u2014 ARIMA, LSTM, mod\u00e8les hybrides, validation crois\u00e9e temporelle.</p> <p>Ce que \u00e7a m'a appris \u2014 Les sp\u00e9cificit\u00e9s des donn\u00e9es temporelles. L'importance de la validation crois\u00e9e appropri\u00e9e.</p>"},{"location":"innovations/#feature-engineering-geographique","title":"Feature engineering g\u00e9ographique","text":"<p>Id\u00e9e \u2014 Cr\u00e9er des variables g\u00e9ographiques innovantes pour am\u00e9liorer les pr\u00e9dictions immobili\u00e8res.</p> <p>Exp\u00e9rimentation \u2014 Donn\u00e9es g\u00e9ographiques, clustering spatial, variables de proximit\u00e9.</p> <p>Ce que \u00e7a m'a appris \u2014 L'impact des variables g\u00e9ographiques sur les pr\u00e9dictions. Techniques de feature engineering spatial.</p>"},{"location":"innovations/#technologies-emergentes","title":"\ud83d\ude80 Technologies \u00e9mergentes","text":""},{"location":"innovations/#integration-dapis-externes","title":"Int\u00e9gration d'APIs externes","text":"<p>Id\u00e9e \u2014 Explorer l'int\u00e9gration d'APIs de g\u00e9n\u00e9ration de contenu dans des workflows existants.</p> <p>Exp\u00e9rimentation \u2014 APIs OpenAI, gestion des co\u00fbts, optimisation des requ\u00eates, fallbacks.</p> <p>Ce que \u00e7a m'a appris \u2014 L'importance de la gestion des co\u00fbts et de la robustesse. Techniques d'optimisation des APIs.</p>"},{"location":"innovations/#architecture-microservices","title":"Architecture microservices","text":"<p>Id\u00e9e \u2014 D\u00e9velopper des architectures modulaires pour les applications data.</p> <p>Exp\u00e9rimentation \u2014 Services s\u00e9par\u00e9s, communication inter-services, d\u00e9ploiement ind\u00e9pendant.</p> <p>Ce que \u00e7a m'a appris \u2014 L'importance de la modularit\u00e9 en production. Techniques de communication entre services.</p>"},{"location":"innovations/#ressources-apprentissages","title":"\ud83d\udcda Ressources &amp; Apprentissages","text":""},{"location":"innovations/#documentation-technique","title":"Documentation technique","text":"<ul> <li>Architecture decisions : Documentation des choix techniques</li> <li>Code examples : Exemples r\u00e9utilisables et bonnes pratiques</li> <li>Tutorials : Guides pas-\u00e0-pas pour les techniques avanc\u00e9es</li> </ul>"},{"location":"innovations/#collaboration-partage","title":"Collaboration &amp; Partage","text":"<ul> <li>Open source : Contributions aux projets communautaires</li> <li>Knowledge sharing : Partage d'exp\u00e9riences et de techniques</li> <li>Mentoring : Accompagnement de projets data</li> </ul>"},{"location":"innovations/#vision-future","title":"\ud83d\udd2e Vision future","text":""},{"location":"innovations/#technologies-a-explorer","title":"Technologies \u00e0 explorer","text":"<ul> <li>Edge AI : D\u00e9ploiement de mod\u00e8les sur des dispositifs embarqu\u00e9s</li> <li>Federated Learning : Apprentissage distribu\u00e9 pr\u00e9servant la confidentialit\u00e9</li> <li>Quantum ML : Algorithmes quantiques pour l'optimisation</li> <li>AutoML : Automatisation de la s\u00e9lection et de l'optimisation des mod\u00e8les</li> </ul>"},{"location":"innovations/#impact-social","title":"Impact social","text":"<ul> <li>Sant\u00e9 : Am\u00e9lioration des diagnostics m\u00e9dicaux</li> <li>Environnement : Optimisation des ressources \u00e9nerg\u00e9tiques</li> <li>\u00c9ducation : Personnalisation de l'apprentissage</li> <li>\u00c9quit\u00e9 : R\u00e9duction des biais dans les mod\u00e8les d'IA</li> </ul>"},{"location":"innovations/#collaboration","title":"\ud83d\udcde Collaboration","text":"<p>Int\u00e9ress\u00e9 par une collaboration sur l'une de ces innovations ?</p> <ul> <li> <p> Discutons de votre projet</p> <p>Dernoncourt.ck@gmail.com</p> </li> <li> <p> Voir le code</p> <p>GitHub LoickDIA</p> </li> <li> <p> Connectons-nous</p> <p>Profil professionnel</p> </li> </ul> <p>\u2192 Voir mes projets phares | D\u00e9couvrir ma m\u00e9thodologie</p>"},{"location":"lab/","title":"Lab \u2014 Exp\u00e9rimentations Techniques Data Science","text":"<p>Bienvenue dans mon laboratoire d'exp\u00e9rimentations ! Cette section pr\u00e9sente mes explorations techniques et mes mini-projets qui d\u00e9montrent ma curiosit\u00e9 et mon apprentissage continu.</p>"},{"location":"lab/#nlp-natural-language-processing","title":"\ud83e\udde0 NLP \u2014 Natural Language Processing","text":""},{"location":"lab/#chatbots-metier-intelligents","title":"Chatbots m\u00e9tier intelligents","text":"<p>Objectif \u2014 D\u00e9velopper des assistants conversationnels sp\u00e9cialis\u00e9s pour des domaines m\u00e9tier sp\u00e9cifiques.</p> <p>Approche \u2014 Int\u00e9gration d'APIs OpenAI avec prompts sp\u00e9cialis\u00e9s, gestion du contexte conversationnel, personnalisation des r\u00e9ponses.</p> <p>Ce que j'ai appris \u2014 L'importance du prompt engineering et de la gestion du contexte pour des applications m\u00e9tier. La n\u00e9cessit\u00e9 de valider les r\u00e9ponses g\u00e9n\u00e9r\u00e9es et d'impl\u00e9menter des fallbacks.</p>"},{"location":"lab/#generation-automatique-de-contenu","title":"G\u00e9n\u00e9ration automatique de contenu","text":"<p>Objectif \u2014 Automatiser la cr\u00e9ation de slides de pr\u00e9sentation et de synth\u00e8ses de r\u00e9unions.</p> <p>Approche \u2014 Pipeline de g\u00e9n\u00e9ration avec templates personnalis\u00e9s, extraction d'informations cl\u00e9s, formatage automatique.</p> <p>Ce que j'ai appris \u2014 L'\u00e9quilibre entre automatisation et contr\u00f4le humain. L'importance de la validation et de la personnalisation pour l'adoption utilisateur.</p>"},{"location":"lab/#computer-vision","title":"\ud83d\udc41\ufe0f Computer Vision","text":""},{"location":"lab/#ocr-medical-avance","title":"OCR m\u00e9dical avanc\u00e9","text":"<p>Objectif \u2014 Am\u00e9liorer l'extraction de donn\u00e9es m\u00e9dicales \u00e0 partir de documents scann\u00e9s de qualit\u00e9 variable.</p> <p>Approche \u2014 Techniques de preprocessing d'images (d\u00e9bruitage, correction g\u00e9om\u00e9trique), optimisation des param\u00e8tres Tesseract, validation crois\u00e9e.</p> <p>Ce que j'ai appris \u2014 L'impact crucial de la qualit\u00e9 des donn\u00e9es d'entr\u00e9e. Techniques de preprocessing sp\u00e9cifiques au domaine m\u00e9dical et gestion des cas d'erreur.</p>"},{"location":"lab/#traitement-dimages-en-temps-reel","title":"Traitement d'images en temps r\u00e9el","text":"<p>Objectif \u2014 D\u00e9velopper des pipelines de traitement d'images optimis\u00e9s pour la production.</p> <p>Approche \u2014 OpenCV, optimisation des performances, gestion de la m\u00e9moire, parall\u00e9lisation.</p> <p>Ce que j'ai appris \u2014 L'importance de l'optimisation des performances en production. Techniques de profiling et d'am\u00e9lioration pour les applications temps r\u00e9el.</p>"},{"location":"lab/#mlops","title":"\ud83d\udd27 MLOps","text":""},{"location":"lab/#applications-streamlit-interactives","title":"Applications Streamlit interactives","text":"<p>Objectif \u2014 Cr\u00e9er des interfaces utilisateur intuitives pour les mod\u00e8les de machine learning.</p> <p>Approche \u2014 D\u00e9veloppement d'applications compl\u00e8tes avec visualisations interactives, gestion des \u00e9tats, d\u00e9ploiement cloud.</p> <p>Ce que j'ai appris \u2014 L'importance de l'UX pour l'adoption des outils data. Techniques de d\u00e9ploiement et de monitoring pour les applications web.</p>"},{"location":"lab/#pipeline-de-donnees-automatise","title":"Pipeline de donn\u00e9es automatis\u00e9","text":"<p>Objectif \u2014 Automatiser l'ensemble du pipeline de donn\u00e9es, de la collecte au d\u00e9ploiement.</p> <p>Approche \u2014 ETL avec Python, orchestration avec Docker, CI/CD, monitoring des performances.</p> <p>Ce que j'ai appris \u2014 L'architecture des syst\u00e8mes de production. L'importance de la robustesse et de la maintenabilit\u00e9 pour les pipelines critiques.</p>"},{"location":"lab/#streamlit","title":"\ud83d\udcca Streamlit","text":""},{"location":"lab/#dashboards-interactifs","title":"Dashboards interactifs","text":"<p>Objectif \u2014 Cr\u00e9er des tableaux de bord dynamiques pour l'exploration de donn\u00e9es complexes.</p> <p>Approche \u2014 Streamlit, Plotly, int\u00e9gration de donn\u00e9es temps r\u00e9el, filtres interactifs.</p> <p>Ce que j'ai appris \u2014 L'importance de la clart\u00e9 dans la visualisation de donn\u00e9es. Techniques d'interaction utilisateur et de gestion des \u00e9tats.</p>"},{"location":"lab/#metriques-business-en-temps-reel","title":"M\u00e9triques business en temps r\u00e9el","text":"<p>Objectif \u2014 D\u00e9velopper des syst\u00e8mes de monitoring des performances business des mod\u00e8les ML.</p> <p>Approche \u2014 M\u00e9triques personnalis\u00e9es, alertes automatiques, visualisation des tendances.</p> <p>Ce que j'ai appris \u2014 L'importance de mesurer l'impact business, pas seulement les m\u00e9triques techniques. Techniques de monitoring et d'alerte.</p>"},{"location":"lab/#recherche-experimentation","title":"\ud83d\udd2c Recherche &amp; Exp\u00e9rimentation","text":""},{"location":"lab/#modeles-de-series-temporelles","title":"Mod\u00e8les de s\u00e9ries temporelles","text":"<p>Objectif \u2014 Explorer les techniques avanc\u00e9es de pr\u00e9diction temporelle pour les donn\u00e9es immobili\u00e8res.</p> <p>Approche \u2014 ARIMA, LSTM, mod\u00e8les hybrides, validation crois\u00e9e temporelle.</p> <p>Ce que j'ai appris \u2014 Les sp\u00e9cificit\u00e9s des donn\u00e9es temporelles. L'importance de la validation crois\u00e9e appropri\u00e9e et de la gestion des fuites de donn\u00e9es.</p>"},{"location":"lab/#feature-engineering-geographique","title":"Feature engineering g\u00e9ographique","text":"<p>Objectif \u2014 Cr\u00e9er des variables g\u00e9ographiques innovantes pour am\u00e9liorer les pr\u00e9dictions immobili\u00e8res.</p> <p>Approche \u2014 Donn\u00e9es g\u00e9ographiques, clustering spatial, variables de proximit\u00e9.</p> <p>Ce que j'ai appris \u2014 L'impact des variables g\u00e9ographiques sur les pr\u00e9dictions. Techniques de feature engineering spatial et de validation g\u00e9ographique.</p>"},{"location":"lab/#technologies-emergentes","title":"\ud83d\ude80 Technologies \u00e9mergentes","text":""},{"location":"lab/#integration-dapis-externes","title":"Int\u00e9gration d'APIs externes","text":"<p>Objectif \u2014 Explorer l'int\u00e9gration d'APIs de g\u00e9n\u00e9ration de contenu dans des workflows existants.</p> <p>Approche \u2014 APIs OpenAI, gestion des co\u00fbts, optimisation des requ\u00eates, fallbacks.</p> <p>Ce que j'ai appris \u2014 L'importance de la gestion des co\u00fbts et de la robustesse. Techniques d'optimisation des APIs et de gestion des erreurs.</p>"},{"location":"lab/#architecture-microservices","title":"Architecture microservices","text":"<p>Objectif \u2014 D\u00e9velopper des architectures modulaires pour les applications data.</p> <p>Approche \u2014 Services s\u00e9par\u00e9s, communication inter-services, d\u00e9ploiement ind\u00e9pendant.</p> <p>Ce que j'ai appris \u2014 L'importance de la modularit\u00e9 en production. Techniques de communication entre services et de gestion des d\u00e9pendances.</p>"},{"location":"lab/#ressources-apprentissages","title":"\ud83d\udcda Ressources &amp; Apprentissages","text":""},{"location":"lab/#documentation-technique","title":"Documentation technique","text":"<ul> <li>Architecture decisions : Documentation des choix techniques et de leurs justifications</li> <li>Code examples : Exemples r\u00e9utilisables et bonnes pratiques</li> <li>Tutorials : Guides pas-\u00e0-pas pour les techniques avanc\u00e9es</li> </ul>"},{"location":"lab/#collaboration-partage","title":"Collaboration &amp; Partage","text":"<ul> <li>Open source : Contributions aux projets communautaires</li> <li>Knowledge sharing : Partage d'exp\u00e9riences et de techniques</li> <li>Mentoring : Accompagnement de projets data</li> </ul>"},{"location":"lab/#vision-future","title":"\ud83d\udd2e Vision future","text":""},{"location":"lab/#technologies-a-explorer","title":"Technologies \u00e0 explorer","text":"<ul> <li>Edge AI : D\u00e9ploiement de mod\u00e8les sur des dispositifs embarqu\u00e9s</li> <li>Federated Learning : Apprentissage distribu\u00e9 pr\u00e9servant la confidentialit\u00e9</li> <li>Quantum ML : Algorithmes quantiques pour l'optimisation</li> <li>AutoML : Automatisation de la s\u00e9lection et de l'optimisation des mod\u00e8les</li> </ul>"},{"location":"lab/#impact-social","title":"Impact social","text":"<ul> <li>Sant\u00e9 : Am\u00e9lioration des diagnostics m\u00e9dicaux</li> <li>Environnement : Optimisation des ressources \u00e9nerg\u00e9tiques</li> <li>\u00c9ducation : Personnalisation de l'apprentissage</li> <li>\u00c9quit\u00e9 : R\u00e9duction des biais dans les mod\u00e8les d'IA</li> </ul>"},{"location":"lab/#collaboration","title":"\ud83d\udcde Collaboration","text":"<p>Int\u00e9ress\u00e9 par une collaboration sur l'une de ces exp\u00e9rimentations ?</p> <ul> <li> <p> Discutons de votre projet</p> <p>Dernoncourt.ck@gmail.com</p> </li> <li> <p> Voir le code</p> <p>GitHub LoickDIA</p> </li> <li> <p> Connectons-nous</p> <p>Profil professionnel</p> </li> </ul> <p>\u2192 Voir mes projets phares | D\u00e9couvrir mes innovations</p>"},{"location":"methodologie/","title":"M\u00e9thodologie Data Science \u2014 Du besoin m\u00e9tier \u00e0 la valeur","text":"<p>D\u00e9couvrez ma d\u00e9marche m\u00e9thodologique pour mener \u00e0 bien des projets de data science, de la conception \u00e0 la mise en production.</p>"},{"location":"methodologie/#les-5-etapes-cles","title":"\ud83c\udfaf Les 5 \u00e9tapes cl\u00e9s","text":""},{"location":"methodologie/#1-comprendre-le-besoin-metier","title":"1. Comprendre le besoin m\u00e9tier","text":"<p>Objectif : Transformer une probl\u00e9matique business en objectif technique clair.</p> <p>Actions concr\u00e8tes : - Interviews stakeholders : Comprendre les vrais besoins et contraintes - D\u00e9finition des objectifs : SMART (Sp\u00e9cifique, Mesurable, Atteignable, R\u00e9aliste, Temporel) - M\u00e9triques de succ\u00e8s : KPIs business et techniques align\u00e9s - Analyse des contraintes : Temps, budget, donn\u00e9es, r\u00e9glementation</p> <p>Exemple concret : Projet immobilier - Besoin : \"Aider les investisseurs \u00e0 estimer les prix\" - Objectif : \"Pr\u00e9dire le prix au m\u00b2 avec une erreur &lt; 10%\" - M\u00e9trique : MAPE &lt; 10%, R\u00b2 &gt; 0.85 - Contraintes : Donn\u00e9es DVF publiques, d\u00e9lai 3 mois</p>"},{"location":"methodologie/#2-collecter-et-nettoyer-les-donnees","title":"2. Collecter et nettoyer les donn\u00e9es","text":"<p>Objectif : Obtenir un dataset de qualit\u00e9 pour l'entra\u00eenement.</p> <p>Actions concr\u00e8tes : - Sources de donn\u00e9es : APIs, bases de donn\u00e9es, fichiers, web scraping - Nettoyage : Gestion des valeurs manquantes, outliers, doublons - Validation : Coh\u00e9rence, compl\u00e9tude, qualit\u00e9 - Documentation : Dictionnaire de donn\u00e9es, m\u00e9tadonn\u00e9es</p> <p>Exemple concret : Pipeline immobilier - Sources : DVF (prix), DPE (\u00e9nergie), INSEE (d\u00e9mographie) - Nettoyage : Suppression des prix aberrants, imputation des donn\u00e9es manquantes - Validation : V\u00e9rification de la coh\u00e9rence g\u00e9ographique et temporelle</p>"},{"location":"methodologie/#3-features-modeles","title":"3. Features &amp; mod\u00e8les","text":"<p>Objectif : D\u00e9velopper des mod\u00e8les performants avec des features pertinentes.</p> <p>Actions concr\u00e8tes : - Feature engineering : Cr\u00e9ation de variables m\u00e9tier et techniques - S\u00e9lection de mod\u00e8les : Test de plusieurs algorithmes - Optimisation : Hyperparam\u00e8tres, validation crois\u00e9e - Interpr\u00e9tabilit\u00e9 : Compr\u00e9hension des pr\u00e9dictions</p> <p>Exemple concret : Mod\u00e8les immobiliers - Features : Surface, nombre de pi\u00e8ces, distance transports, ann\u00e9e construction - Mod\u00e8les : Random Forest, XGBoost, r\u00e9gression lin\u00e9aire - Optimisation : Grid search, validation crois\u00e9e temporelle - Interpr\u00e9tabilit\u00e9 : Importance des features, SHAP values</p>"},{"location":"methodologie/#4-evaluer-et-iterer","title":"4. \u00c9valuer et it\u00e9rer","text":"<p>Objectif : Valider la performance et am\u00e9liorer continuellement.</p> <p>Actions concr\u00e8tes : - M\u00e9triques de performance : Pr\u00e9cision, recall, F1, RMSE, MAPE - Validation crois\u00e9e : \u00c9viter le surapprentissage - Tests A/B : Comparer avec les m\u00e9thodes existantes - Feedback utilisateur : Am\u00e9lioration bas\u00e9e sur l'usage</p> <p>Exemple concret : Validation immobili\u00e8re - M\u00e9triques : MAPE 8.5%, R\u00b2 0.87, temps de pr\u00e9diction &lt; 1s - Validation : Test sur donn\u00e9es 2024, comparaison avec estimations manuelles - Feedback : Interface utilisateur, facilit\u00e9 d'utilisation</p>"},{"location":"methodologie/#5-livrer-dashboard-api-app-streamlit","title":"5. Livrer (dashboard, API, app Streamlit)","text":"<p>Objectif : D\u00e9ployer une solution utilisable en production.</p> <p>Actions concr\u00e8tes : - Interface utilisateur : Dashboard, application web, API - D\u00e9ploiement : Docker, cloud, CI/CD - Monitoring : Performance, utilisation, erreurs - Formation : Documentation, formation utilisateurs</p> <p>Exemple concret : Application Streamlit - Interface : Formulaire de saisie, visualisation des r\u00e9sultats - D\u00e9ploiement : Docker sur AWS, mise \u00e0 jour automatique - Monitoring : Logs d'utilisation, m\u00e9triques de performance - Formation : Guide utilisateur, session de formation</p>"},{"location":"methodologie/#outils-et-technologies","title":"\ud83d\udd27 Outils et technologies","text":""},{"location":"methodologie/#environnement-de-developpement","title":"Environnement de d\u00e9veloppement","text":"<ul> <li>Python : pandas, scikit-learn, PyTorch, Streamlit</li> <li>Data : SQL, APIs, bases de donn\u00e9es</li> <li>Visualisation : Matplotlib, Seaborn, Plotly</li> <li>D\u00e9ploiement : Docker, AWS, CI/CD</li> </ul>"},{"location":"methodologie/#bonnes-pratiques","title":"Bonnes pratiques","text":"<ul> <li>Code propre : Documentation, tests, versioning</li> <li>Architecture : Modularit\u00e9, maintenabilit\u00e9, \u00e9volutivit\u00e9</li> <li>S\u00e9curit\u00e9 : Gestion des donn\u00e9es sensibles, authentification</li> <li>Performance : Optimisation, monitoring, alertes</li> </ul>"},{"location":"methodologie/#exemple-complet-projet-immobilier","title":"\ud83d\udcca Exemple complet : Projet immobilier","text":"<p>\u00c9tape 1 : Besoin identifi\u00e9 \u2192 \"Pr\u00e9dire les prix immobiliers pour aider les investisseurs\"</p> <p>\u00c9tape 2 : Donn\u00e9es collect\u00e9es \u2192 DVF (prix), DPE (\u00e9nergie), INSEE (d\u00e9mographie), g\u00e9olocalisation</p> <p>\u00c9tape 3 : Mod\u00e8les d\u00e9velopp\u00e9s \u2192 Random Forest optimis\u00e9, features g\u00e9ographiques et temporelles</p> <p>\u00c9tape 4 : Performance valid\u00e9e \u2192 MAPE 8.5%, R\u00b2 0.87, validation crois\u00e9e temporelle</p> <p>\u00c9tape 5 : Application d\u00e9ploy\u00e9e \u2192 Streamlit interactive, Docker, monitoring, documentation</p>"},{"location":"methodologie/#avantages-de-cette-approche","title":"\ud83c\udfaf Avantages de cette approche","text":""},{"location":"methodologie/#pour-lequipe","title":"Pour l'\u00e9quipe","text":"<ul> <li>Clart\u00e9 : Objectifs et \u00e9tapes bien d\u00e9finis</li> <li>Collaboration : Implication de tous les stakeholders</li> <li>Qualit\u00e9 : Validation continue et am\u00e9lioration</li> </ul>"},{"location":"methodologie/#pour-lentreprise","title":"Pour l'entreprise","text":"<ul> <li>Impact : Solutions align\u00e9es sur les besoins business</li> <li>ROI : Mesure de la valeur cr\u00e9\u00e9e</li> <li>\u00c9volutivit\u00e9 : Architecture pens\u00e9e pour la croissance</li> </ul>"},{"location":"methodologie/#pour-les-utilisateurs","title":"Pour les utilisateurs","text":"<ul> <li>Simplicit\u00e9 : Interfaces intuitives et document\u00e9es</li> <li>Performance : Solutions rapides et fiables</li> <li>Support : Formation et accompagnement</li> </ul>"},{"location":"methodologie/#collaboration","title":"\ud83d\udcde Collaboration","text":"<p>Int\u00e9ress\u00e9 par cette m\u00e9thodologie pour votre projet ?</p> <ul> <li> <p> Discutons de votre projet</p> <p>Dernoncourt.ck@gmail.com</p> </li> <li> <p> Connectons-nous</p> <p>Profil professionnel</p> </li> <li> <p> Voir le code</p> <p>GitHub LoickDIA</p> </li> </ul> <p>\u2192 Voir mes projets phares | D\u00e9couvrir mes innovations</p>"},{"location":"portfolio-reel/","title":"Portfolio R\u00e9el \u2014 Projets Data Science avec Impact","text":"<p>Voici mes projets r\u00e9els qui d\u00e9montrent mes comp\u00e9tences en data science et d\u00e9veloppement, avec focus sur l'impact m\u00e9tier et les r\u00e9sultats concrets.</p>"},{"location":"portfolio-reel/#projets-phares","title":"\ud83c\udfc6 Projets phares","text":""},{"location":"portfolio-reel/#valmed-ocr-medical-automatise","title":"Valmed \u2014 OCR m\u00e9dical automatis\u00e9","text":"<p>Probl\u00e8me \u2014 Automatiser l'extraction de donn\u00e9es m\u00e9dicales \u00e0 partir de documents scann\u00e9s pour r\u00e9duire le temps de traitement manuel.</p> <p>Approche \u2014 Python, Tesseract, scikit-learn, OpenCV, supervision des mod\u00e8les, pipeline de traitement d'images.</p> <p>R\u00e9sultats \u2014 Prototype valid\u00e9 avec am\u00e9lioration observ\u00e9e du temps de traitement. Pipeline robuste pour diff\u00e9rents types de documents m\u00e9dicaux.</p> <p>Enseignements \u2014  - L'importance de la qualit\u00e9 des donn\u00e9es d'entr\u00e9e pour l'OCR - Techniques de preprocessing d'images pour am\u00e9liorer la pr\u00e9cision - Gestion des cas d'erreur et validation des r\u00e9sultats</p> <p>\ud83d\udd17 Liens : Code GitHub | Documentation technique</p>"},{"location":"portfolio-reel/#kea-partners-ia-interne-dentreprise","title":"K\u00e9a Partners \u2014 IA interne d'entreprise","text":"<p>Probl\u00e8me \u2014 Am\u00e9liorer la productivit\u00e9 des consultants (~100 personnes) avec des outils d'IA pour la g\u00e9n\u00e9ration de contenu et l'assistance m\u00e9tier.</p> <p>Approche \u2014 Python, API OpenAI, d\u00e9veloppement de chatbot m\u00e9tier, g\u00e9n\u00e9ration automatique de slides, syst\u00e8me de synth\u00e8se de r\u00e9unions.</p> <p>R\u00e9sultats \u2014 D\u00e9ploiement MVP avec adoption interne. Formation de l'\u00e9quipe sur les nouveaux outils. Gain de temps constat\u00e9 sur les t\u00e2ches r\u00e9p\u00e9titives.</p> <p>Enseignements \u2014 - Int\u00e9gration d'APIs externes dans des workflows existants - Importance de la formation utilisateur pour l'adoption - \u00c9quilibre entre automatisation et contr\u00f4le humain</p> <p>\ud83d\udd17 Liens : Code GitHub | Documentation d\u00e9ploiement</p>"},{"location":"portfolio-reel/#compagnon-immobilier-pipeline-ml-de-prediction","title":"Compagnon Immobilier \u2014 Pipeline ML de pr\u00e9diction","text":"<p>Probl\u00e8me \u2014 Pr\u00e9dire les prix immobiliers en combinant donn\u00e9es DVF, DPE et INSEE pour aider les investisseurs dans leurs d\u00e9cisions.</p> <p>Approche \u2014 Python, Streamlit, s\u00e9ries temporelles, donn\u00e9es g\u00e9ographiques, mod\u00e8les de r\u00e9gression avanc\u00e9s.</p> <p>R\u00e9sultats \u2014 Application Streamlit interactive d\u00e9ploy\u00e9e. Mod\u00e8les entra\u00een\u00e9s sur donn\u00e9es r\u00e9elles. Code et d\u00e9mo disponibles sur GitHub.</p> <p>Enseignements \u2014 - Gestion de donn\u00e9es g\u00e9ographiques et temporelles complexes - D\u00e9veloppement d'interfaces utilisateur pour les mod\u00e8les ML - Importance de la validation crois\u00e9e sur donn\u00e9es immobili\u00e8res</p> <p>\ud83d\udd17 Liens : Code GitHub | D\u00e9mo Streamlit | Documentation</p>"},{"location":"portfolio-reel/#explorations-lab","title":"\ud83d\udd2c Explorations &amp; Lab","text":""},{"location":"portfolio-reel/#computer-vision","title":"Computer Vision","text":"<ul> <li>Traitement d'images m\u00e9dicales : Techniques d'am\u00e9lioration pour OCR</li> <li>D\u00e9tection d'objets : Exp\u00e9rimentations avec YOLO et OpenCV</li> <li>Preprocessing avanc\u00e9 : Filtres, seuillage, correction g\u00e9om\u00e9trique</li> </ul>"},{"location":"portfolio-reel/#natural-language-processing","title":"Natural Language Processing","text":"<ul> <li>Chatbots m\u00e9tier : Int\u00e9gration d'APIs de g\u00e9n\u00e9ration de texte</li> <li>Synth\u00e8se automatique : Extraction d'informations cl\u00e9s des r\u00e9unions</li> <li>G\u00e9n\u00e9ration de contenu : Slides, rapports, documentation</li> </ul>"},{"location":"portfolio-reel/#machine-learning","title":"Machine Learning","text":"<ul> <li>S\u00e9ries temporelles : Pr\u00e9diction de prix avec donn\u00e9es historiques</li> <li>Feature engineering : Cr\u00e9ation de variables g\u00e9ographiques et temporelles</li> <li>Validation crois\u00e9e : Techniques robustes pour donn\u00e9es immobili\u00e8res</li> </ul>"},{"location":"portfolio-reel/#mlops-deploiement","title":"MLOps &amp; D\u00e9ploiement","text":"<ul> <li>Streamlit : D\u00e9veloppement d'applications interactives</li> <li>Docker : Conteneurisation des mod\u00e8les</li> <li>CI/CD : Automatisation des d\u00e9ploiements</li> <li>Monitoring : Suivi des performances en production</li> </ul>"},{"location":"portfolio-reel/#approche-methodologique","title":"\ud83c\udfaf Approche m\u00e9thodologique","text":""},{"location":"portfolio-reel/#comprehension-du-besoin","title":"Compr\u00e9hension du besoin","text":"<p>Chaque projet commence par une phase d'\u00e9coute et de clarification des objectifs m\u00e9tier.</p>"},{"location":"portfolio-reel/#prototypage-rapide","title":"Prototypage rapide","text":"<p>D\u00e9veloppement de MVP pour valider rapidement l'approche technique et l'acceptation utilisateur.</p>"},{"location":"portfolio-reel/#livraison-production","title":"Livraison production","text":"<p>Code propre, documentation, tests, architecture scalable pour la maintenance.</p>"},{"location":"portfolio-reel/#formation-transfert","title":"Formation &amp; transfert","text":"<p>Transmission des comp\u00e9tences \u00e0 l'\u00e9quipe pour assurer la p\u00e9rennit\u00e9 des solutions.</p>"},{"location":"portfolio-reel/#metriques-dimpact","title":"\ud83d\udcca M\u00e9triques d'impact","text":"<ul> <li>Temps de traitement : R\u00e9duction observ\u00e9e sur les t\u00e2ches automatis\u00e9es</li> <li>Adoption utilisateur : Formation et adoption des nouveaux outils</li> <li>Qualit\u00e9 des donn\u00e9es : Am\u00e9lioration de la pr\u00e9cision des extractions</li> <li>Maintenabilit\u00e9 : Code document\u00e9 et architecture \u00e9volutive</li> </ul>"},{"location":"portfolio-reel/#prochaines-etapes","title":"\ud83d\ude80 Prochaines \u00e9tapes","text":"<p>Int\u00e9ress\u00e9 par une collaboration ?</p> <ul> <li> <p> Discutons de votre projet</p> <p>Dernoncourt.ck@gmail.com</p> </li> <li> <p> Connectons-nous</p> <p>Profil professionnel</p> </li> <li> <p> Voir le code</p> <p>GitHub LoickDIA</p> </li> </ul> <p>\u2192 D\u00e9couvrir ma m\u00e9thodologie | Voir mes innovations</p>"},{"location":"seo-guide/","title":"Guide SEO \u2014 Optimisation Portfolio Data Science","text":"<p>Ce guide vous accompagne dans l'optimisation SEO de votre portfolio pour maximiser sa visibilit\u00e9 et son impact professionnel.</p>"},{"location":"seo-guide/#strategie-seo","title":"\ud83c\udfaf Strat\u00e9gie SEO","text":""},{"location":"seo-guide/#mots-cles-cibles","title":"Mots-cl\u00e9s cibles","text":"<ul> <li>Primaires : Data Scientist, Machine Learning, Python, Streamlit</li> <li>Secondaires : Computer Vision, NLP, MLOps, Data Engineering</li> <li>Longue tra\u00eene : \"Data Scientist Python\", \"Machine Learning Engineer\", \"Deep Learning Expert\"</li> </ul>"},{"location":"seo-guide/#metadonnees-optimisees","title":"M\u00e9tadonn\u00e9es optimis\u00e9es","text":"<pre><code># Configuration SEO dans mkdocs.yml\nsite_description: \"Portfolio de Lo\u00efck Dernoncourt - Data Scientist expert en Machine Learning, Python et Streamlit. Projets en Computer Vision, NLP et MLOps.\"\nsite_author: \"Lo\u00efck Dernoncourt\"\nsite_url: \"https://loick-dernoncourt.github.io/portfolio\"\n\n# M\u00e9tadonn\u00e9es par page\nextra:\n  social:\n    - property: \"og:title\"\n      content: \"Portfolio Data Scientist - Lo\u00efck Dernoncourt\"\n    - property: \"og:description\"\n      content: \"D\u00e9couvrez mes projets en Machine Learning, Python et Data Science\"\n    - property: \"og:image\"\n      content: \"https://loick-dernoncourt.github.io/portfolio/assets/og-image.png\"\n    - property: \"og:type\"\n      content: \"website\"\n    - property: \"twitter:card\"\n      content: \"summary_large_image\"\n    - property: \"twitter:title\"\n      content: \"Portfolio Data Scientist - Lo\u00efck Dernoncourt\"\n    - property: \"twitter:description\"\n      content: \"Expert en Machine Learning, Python et Data Science\"\n    - property: \"twitter:image\"\n      content: \"https://loick-dernoncourt.github.io/portfolio/assets/twitter-image.png\"\n</code></pre>"},{"location":"seo-guide/#optimisation-du-contenu","title":"\ud83d\udcc8 Optimisation du contenu","text":""},{"location":"seo-guide/#structure-des-titres","title":"Structure des titres","text":"<pre><code># H1 : Mots-cl\u00e9s principaux (1 par page)\n## H2 : Mots-cl\u00e9s secondaires\n### H3 : Mots-cl\u00e9s longue tra\u00eene\n#### H4 : Sous-sujets\n</code></pre>"},{"location":"seo-guide/#densite-de-mots-cles","title":"Densit\u00e9 de mots-cl\u00e9s","text":"<ul> <li>Titre H1 : 1-2% de densit\u00e9</li> <li>Contenu principal : 2-3% de densit\u00e9</li> <li>Mots-cl\u00e9s LSI : 5-10% de densit\u00e9</li> <li>Variations : 3-5 variations par mot-cl\u00e9</li> </ul>"},{"location":"seo-guide/#liens-internes","title":"Liens internes","text":"<pre><code># Structure de liens internes\n- Page d'accueil \u2192 Projets\n- Projets \u2192 Comp\u00e9tences\n- Comp\u00e9tences \u2192 M\u00e9thodologie\n- M\u00e9thodologie \u2192 Lab\n- Lab \u2192 Feedback\n</code></pre>"},{"location":"seo-guide/#optimisation-technique","title":"\ud83d\ude80 Optimisation technique","text":""},{"location":"seo-guide/#performance","title":"Performance","text":"<pre><code># Configuration de performance\nplugins:\n  - minify:\n      minify_html: true\n      minify_js: true\n      minify_css: true\n  - git-revision-date-localized:\n      enable_creation_date: true\n      fallback_to_build_date: true\n</code></pre>"},{"location":"seo-guide/#mobile-first","title":"Mobile-First","text":"<pre><code>/* Optimisation mobile */\n@media (max-width: 768px) {\n  .md-content {\n    font-size: 16px;\n    line-height: 1.6;\n  }\n\n  .md-header {\n    padding: 0.5rem;\n  }\n}\n</code></pre>"},{"location":"seo-guide/#optimisation-des-images","title":"Optimisation des images","text":"<pre><code># Script d'optimisation des images\nfrom PIL import Image\nimport os\n\ndef optimize_images():\n    \"\"\"Optimise toutes les images du portfolio\"\"\"\n\n    for root, dirs, files in os.walk(\"docs\"):\n        for file in files:\n            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                file_path = os.path.join(root, file)\n\n                # Redimensionnement\n                with Image.open(file_path) as img:\n                    # Redimensionner si trop grande\n                    if img.width &gt; 1200:\n                        img.thumbnail((1200, 1200), Image.Resampling.LANCZOS)\n\n                    # Optimisation\n                    img.save(file_path, optimize=True, quality=85)\n\n                print(f\"\u2705 Image optimis\u00e9e : {file_path}\")\n\n# Ex\u00e9cution\noptimize_images()\n</code></pre>"},{"location":"seo-guide/#analytics-et-monitoring","title":"\ud83d\udcca Analytics et monitoring","text":""},{"location":"seo-guide/#google-analytics-4","title":"Google Analytics 4","text":"<pre><code>&lt;!-- Configuration GA4 --&gt;\n&lt;script async src=\"https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX\"&gt;&lt;/script&gt;\n&lt;script&gt;\n  window.dataLayer = window.dataLayer || [];\n  function gtag(){dataLayer.push(arguments);}\n  gtag('js', new Date());\n  gtag('config', 'G-XXXXXXXXXX');\n&lt;/script&gt;\n</code></pre>"},{"location":"seo-guide/#search-console","title":"Search Console","text":"<pre><code>&lt;!-- Sitemap pour Search Console --&gt;\n&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;urlset xmlns=\"http://www.sitemaps.org/schemas/sitemap/0.9\"&gt;\n  &lt;url&gt;\n    &lt;loc&gt;https://loick-dernoncourt.github.io/portfolio/&lt;/loc&gt;\n    &lt;lastmod&gt;2024-12-19&lt;/lastmod&gt;\n    &lt;changefreq&gt;weekly&lt;/changefreq&gt;\n    &lt;priority&gt;1.0&lt;/priority&gt;\n  &lt;/url&gt;\n  &lt;url&gt;\n    &lt;loc&gt;https://loick-dernoncourt.github.io/portfolio/projects/&lt;/loc&gt;\n    &lt;lastmod&gt;2024-12-19&lt;/lastmod&gt;\n    &lt;changefreq&gt;weekly&lt;/changefreq&gt;\n    &lt;priority&gt;0.8&lt;/priority&gt;\n  &lt;/url&gt;\n&lt;/urlset&gt;\n</code></pre>"},{"location":"seo-guide/#strategie-de-contenu","title":"\ud83c\udfaf Strat\u00e9gie de contenu","text":""},{"location":"seo-guide/#calendrier-editorial","title":"Calendrier \u00e9ditorial","text":"<ul> <li>Lundi : Nouveau projet</li> <li>Mercredi : Article technique</li> <li>Vendredi : Mise \u00e0 jour des m\u00e9triques</li> <li>Dimanche : R\u00e9flexion m\u00e9thodologique</li> </ul>"},{"location":"seo-guide/#frequence-de-mise-a-jour","title":"Fr\u00e9quence de mise \u00e0 jour","text":"<ul> <li>Contenu principal : Mensuel</li> <li>Projets : Bimensuel</li> <li>M\u00e9triques : Hebdomadaire</li> <li>Blog : Bihebdomadaire</li> </ul>"},{"location":"seo-guide/#types-de-contenu","title":"Types de contenu","text":"<ul> <li>Tutoriels : Guides pas-\u00e0-pas</li> <li>Cas d'usage : \u00c9tudes de cas r\u00e9els</li> <li>Comparaisons : Outils et technologies</li> <li>Tendances : Veille technologique</li> </ul>"},{"location":"seo-guide/#netlinking","title":"\ud83d\udd17 Netlinking","text":""},{"location":"seo-guide/#liens-internes_1","title":"Liens internes","text":"<pre><code># Structure de liens internes\n- Page d'accueil \u2192 Projets (3-5 liens)\n- Projets \u2192 Comp\u00e9tences (2-3 liens)\n- Comp\u00e9tences \u2192 M\u00e9thodologie (1-2 liens)\n- M\u00e9thodologie \u2192 Lab (1-2 liens)\n</code></pre>"},{"location":"seo-guide/#liens-externes","title":"Liens externes","text":"<pre><code># Liens vers des ressources de qualit\u00e9\n- Documentation officielle\n- Articles de r\u00e9f\u00e9rence\n- Outils et frameworks\n- Communaut\u00e9s et forums\n</code></pre>"},{"location":"seo-guide/#partenariats","title":"Partenariats","text":"<ul> <li>Blogs techniques : \u00c9changes de liens</li> <li>Communaut\u00e9s : Mentions et partages</li> <li>Conf\u00e9rences : Pr\u00e9sentations et networking</li> <li>Collaborations : Projets communs</li> </ul>"},{"location":"seo-guide/#optimisation-mobile","title":"\ud83d\udcf1 Optimisation mobile","text":""},{"location":"seo-guide/#responsive-design","title":"Responsive Design","text":"<pre><code>/* Breakpoints optimis\u00e9s */\n@media (max-width: 480px) {\n  .md-content {\n    padding: 1rem;\n  }\n\n  .md-header__title {\n    font-size: 1.2rem;\n  }\n}\n\n@media (max-width: 768px) {\n  .md-nav {\n    display: none;\n  }\n\n  .md-header__button {\n    display: block;\n  }\n}\n</code></pre>"},{"location":"seo-guide/#performance-mobile","title":"Performance mobile","text":"<ul> <li>Temps de chargement : &lt; 3 secondes</li> <li>Taille des images : &lt; 500KB</li> <li>JavaScript : Minifi\u00e9 et optimis\u00e9</li> <li>CSS : Critique et diff\u00e9r\u00e9</li> </ul>"},{"location":"seo-guide/#objectifs-seo","title":"\ud83c\udfaf Objectifs SEO","text":""},{"location":"seo-guide/#metriques-a-atteindre","title":"M\u00e9triques \u00e0 atteindre","text":"<ul> <li>Position moyenne : Top 10 pour mots-cl\u00e9s cibles</li> <li>Trafic organique : +50% en 6 mois</li> <li>Taux de clic : &gt; 5% sur SERP</li> <li>Temps sur site : &gt; 3 minutes</li> </ul>"},{"location":"seo-guide/#kpis-de-succes","title":"KPIs de succ\u00e8s","text":"<ul> <li>Visiteurs uniques : 10,000/mois</li> <li>Pages vues : 25,000/mois</li> <li>Taux de rebond : &lt; 40%</li> <li>Pages par session : &gt; 3</li> </ul>"},{"location":"seo-guide/#evolution-attendue","title":"\u00c9volution attendue","text":"<ul> <li>Mois 1-3 : Indexation et positionnement</li> <li>Mois 4-6 : Am\u00e9lioration des positions</li> <li>Mois 7-9 : Stabilisation du trafic</li> <li>Mois 10-12 : Croissance organique</li> </ul>"},{"location":"seo-guide/#outils-seo","title":"\ud83d\udee0\ufe0f Outils SEO","text":""},{"location":"seo-guide/#outils-danalyse","title":"Outils d'analyse","text":"<ul> <li>Google Analytics : M\u00e9triques d\u00e9taill\u00e9es</li> <li>Search Console : Performance de recherche</li> <li>PageSpeed Insights : Performance technique</li> <li>Lighthouse : Audit complet</li> </ul>"},{"location":"seo-guide/#outils-de-monitoring","title":"Outils de monitoring","text":"<ul> <li>SEMrush : Analyse de la concurrence</li> <li>Ahrefs : Backlinks et mots-cl\u00e9s</li> <li>Screaming Frog : Audit technique</li> <li>GTmetrix : Performance web</li> </ul>"},{"location":"seo-guide/#plan-daction-seo","title":"\ud83d\ude80 Plan d'action SEO","text":""},{"location":"seo-guide/#phase-1-mois-1-2","title":"Phase 1 (Mois 1-2)","text":"<ul> <li> Audit technique : Performance et structure</li> <li> Optimisation on-page : Titres, descriptions, contenu</li> <li> Configuration analytics : GA4 et Search Console</li> <li> Sitemap : G\u00e9n\u00e9ration et soumission</li> </ul>"},{"location":"seo-guide/#phase-2-mois-3-4","title":"Phase 2 (Mois 3-4)","text":"<ul> <li> Contenu optimis\u00e9 : Articles et projets</li> <li> Liens internes : Structure et navigation</li> <li> Images optimis\u00e9es : Compression et alt text</li> <li> Mobile-first : Responsive design</li> </ul>"},{"location":"seo-guide/#phase-3-mois-5-6","title":"Phase 3 (Mois 5-6)","text":"<ul> <li> Netlinking : Liens externes de qualit\u00e9</li> <li> Contenu r\u00e9gulier : Blog et mises \u00e0 jour</li> <li> Social signals : Partages et mentions</li> <li> Monitoring : Suivi des performances</li> </ul>"},{"location":"seo-guide/#contact","title":"\ud83d\udcde Contact","text":"<p>Besoin d'aide pour l'optimisation SEO de votre portfolio ?</p> <ul> <li> <p> Discutons de votre projet</p> <p>Dernoncourt.ck@gmail.com</p> </li> <li> <p> Connectons-nous</p> <p>Profil professionnel</p> </li> <li> <p> Voir le code</p> <p>GitHub LoickDIA</p> </li> </ul> <p>\u2192 Voir mes projets phares | D\u00e9couvrir ma m\u00e9thodologie</p>"},{"location":"projects/","title":"\ud83d\ude80 Projets Data Science","text":"<p>D\u00e9couvrez mes projets de data science et machine learning, de la conception \u00e0 la mise en production.</p>"},{"location":"projects/#projets-recents","title":"\ud83c\udfaf Projets r\u00e9cents","text":"<ul> <li> <p> Classification d'images</p> <p>CNN avec PyTorch pour la classification d'images m\u00e9dicales</p> <p> Voir le projet</p> </li> <li> <p> Analyse de sentiment</p> <p>Mod\u00e8le BERT pour l'analyse de sentiment en temps r\u00e9el</p> <p> Voir le projet</p> </li> <li> <p> Pr\u00e9diction de prix</p> <p>Mod\u00e8le XGBoost pour la pr\u00e9diction de prix immobiliers</p> <p> Voir le projet</p> </li> </ul>"},{"location":"projects/#taxonomie-des-projets","title":"\ud83d\udcca Taxonomie des projets","text":""},{"location":"projects/#machine-learning","title":"\ud83e\udde0 Machine Learning","text":"<ul> <li>Classification : Mod\u00e8les pr\u00e9dictifs pour la cat\u00e9gorisation</li> <li>R\u00e9gression : Pr\u00e9diction de valeurs continues</li> <li>Clustering : Segmentation et regroupement de donn\u00e9es</li> <li>Feature Engineering : Cr\u00e9ation et s\u00e9lection de variables</li> </ul>"},{"location":"projects/#deep-learning","title":"\ud83c\udfaf Deep Learning","text":"<ul> <li>Computer Vision : Traitement et analyse d'images</li> <li>NLP : Traitement du langage naturel</li> <li>Time Series : Analyse de s\u00e9ries temporelles</li> <li>Reinforcement Learning : Apprentissage par renforcement</li> </ul>"},{"location":"projects/#analyse-de-donnees","title":"\ud83d\udcc8 Analyse de donn\u00e9es","text":"<ul> <li>Exploratory Data Analysis : Exploration et visualisation</li> <li>Business Intelligence : Tableaux de bord et rapports</li> <li>Statistical Analysis : Analyses statistiques avanc\u00e9es</li> <li>Data Mining : Extraction de connaissances</li> </ul>"},{"location":"projects/#projets-par-categorie","title":"\ud83c\udfc6 Projets par cat\u00e9gorie","text":""},{"location":"projects/#computer-vision","title":"\ud83d\uddbc\ufe0f Computer Vision","text":"Projet Technologies R\u00e9sultats Statut Classification d'images m\u00e9dicales PyTorch, CNN, Transfer Learning 95.2% accuracy \u2705 Termin\u00e9 D\u00e9tection d'objets en temps r\u00e9el YOLO, OpenCV, FastAPI 99.5% precision \u2705 Termin\u00e9 Reconnaissance faciale CNN, OpenCV 98.1% accuracy \u2705 Termin\u00e9"},{"location":"projects/#natural-language-processing","title":"\ud83d\udcac Natural Language Processing","text":"Projet Technologies R\u00e9sultats Statut Analyse de sentiment BERT, Transformers 94.5% accuracy, 50ms \u2705 Termin\u00e9 Classification de textes TF-IDF, SVM, BERT 92.3% accuracy \u2705 Termin\u00e9 G\u00e9n\u00e9ration de r\u00e9sum\u00e9s T5, HuggingFace ROUGE-2: 0.45 \ud83d\udd04 En cours"},{"location":"projects/#analyse-predictive","title":"\ud83d\udcca Analyse pr\u00e9dictive","text":"Projet Technologies R\u00e9sultats Statut Pr\u00e9diction de prix immobiliers XGBoost, Feature Engineering RMSE: 0.15, R\u00b2: 0.87 \u2705 Termin\u00e9 Pr\u00e9diction de churn Random Forest, SMOTE 89.2% accuracy \u2705 Termin\u00e9 Recommandation de produits Collaborative Filtering 25% am\u00e9lioration conversion \u2705 Termin\u00e9"},{"location":"projects/#recherche-et-innovation","title":"\ud83d\udd2c Recherche et innovation","text":"Projet Technologies R\u00e9sultats Statut Mod\u00e8le de d\u00e9tection d'anomalies Autoencoder, LSTM 99.1% precision \u2705 Termin\u00e9 Optimisation de portefeuille Reinforcement Learning +15% rendement \ud83d\udd04 En cours Analyse de r\u00e9seaux sociaux Graph Neural Networks 87% accuracy \u2705 Termin\u00e9"},{"location":"projects/#statistiques-des-projets","title":"\ud83d\udcca Statistiques des projets","text":"Type de projet Nombre Technologies principales Machine Learning 8 Scikit-learn, XGBoost, LightGBM Deep Learning 5 PyTorch, TensorFlow, Keras NLP 3 BERT, Transformers, spaCy Computer Vision 4 OpenCV, CNN, YOLO Time Series 2 Prophet, ARIMA, LSTM"},{"location":"projects/#projets-phares","title":"\ud83c\udfc6 Projets phares","text":""},{"location":"projects/#systeme-de-recommandation-multi-objectifs","title":"\ud83e\udd47 Syst\u00e8me de recommandation multi-objectifs","text":"<p>Technologies : PyTorch, Transformer, Redis Impact : +25% de conversion, +15% de revenus Dur\u00e9e : 6 mois</p>"},{"location":"projects/#detection-danomalies-en-temps-reel","title":"\ud83e\udd48 D\u00e9tection d'anomalies en temps r\u00e9el","text":"<p>Technologies : CNN, OpenCV, FastAPI Impact : 99.5% de pr\u00e9cision, -40% de d\u00e9fauts Dur\u00e9e : 4 mois</p>"},{"location":"projects/#plateforme-danalytics-predictive","title":"\ud83e\udd49 Plateforme d'analytics pr\u00e9dictive","text":"<p>Technologies : Spark, MLflow, Kubernetes Impact : -60% du temps d'analyse Dur\u00e9e : 8 mois</p>"},{"location":"projects/#methodologie","title":"\ud83d\udd27 M\u00e9thodologie","text":""},{"location":"projects/#1-analyse-exploratoire","title":"1. Analyse exploratoire","text":"<ul> <li>Compr\u00e9hension du probl\u00e8me m\u00e9tier</li> <li>Exploration des donn\u00e9es disponibles</li> <li>Identification des patterns et anomalies</li> </ul>"},{"location":"projects/#2-preprocessing","title":"2. Pr\u00e9processing","text":"<ul> <li>Nettoyage et validation des donn\u00e9es</li> <li>Feature engineering et s\u00e9lection</li> <li>Normalisation et encodage</li> </ul>"},{"location":"projects/#3-modelisation","title":"3. Mod\u00e9lisation","text":"<ul> <li>S\u00e9lection d'algorithmes appropri\u00e9s</li> <li>Entra\u00eenement et validation crois\u00e9e</li> <li>Optimisation des hyperparam\u00e8tres</li> </ul>"},{"location":"projects/#4-evaluation","title":"4. \u00c9valuation","text":"<ul> <li>M\u00e9triques de performance</li> <li>Tests A/B et validation</li> <li>Analyse des erreurs</li> </ul>"},{"location":"projects/#5-deploiement","title":"5. D\u00e9ploiement","text":"<ul> <li>Mise en production avec MLOps</li> <li>Monitoring et maintenance</li> <li>Documentation et formation</li> </ul>"},{"location":"projects/#stack-technique","title":"\ud83d\udee0\ufe0f Stack technique","text":""},{"location":"projects/#langages","title":"Langages","text":"<ul> <li>Python : 90% des projets</li> <li>R : 5% des projets</li> <li>SQL : 100% des projets</li> </ul>"},{"location":"projects/#frameworks-ml","title":"Frameworks ML","text":"<ul> <li>Scikit-learn : 80% des projets</li> <li>PyTorch : 60% des projets</li> <li>XGBoost : 70% des projets</li> <li>TensorFlow : 30% des projets</li> </ul>"},{"location":"projects/#outils-de-deploiement","title":"Outils de d\u00e9ploiement","text":"<ul> <li>Docker : 90% des projets</li> <li>FastAPI : 80% des projets</li> <li>MLflow : 70% des projets</li> <li>AWS : 60% des projets</li> </ul>"},{"location":"projects/#metriques-de-performance","title":"\ud83d\udcc8 M\u00e9triques de performance","text":""},{"location":"projects/#precision-moyenne","title":"Pr\u00e9cision moyenne","text":"<ul> <li>Classification : 94.2%</li> <li>R\u00e9gression : RMSE 0.15</li> <li>Clustering : Silhouette 0.85</li> </ul>"},{"location":"projects/#temps-de-developpement","title":"Temps de d\u00e9veloppement","text":"<ul> <li>Prototype : 2-4 semaines</li> <li>Production : 2-3 mois</li> <li>Maintenance : 1-2 semaines/mois</li> </ul>"},{"location":"projects/#prochaines-etapes","title":"\ud83c\udfaf Prochaines \u00e9tapes","text":""},{"location":"projects/#projets-en-cours","title":"Projets en cours","text":"<ul> <li>Reconnaissance vocale avec Whisper</li> <li>G\u00e9n\u00e9ration de texte avec GPT-2</li> <li>D\u00e9tection d'objets avec YOLO v8</li> </ul>"},{"location":"projects/#technologies-a-explorer","title":"Technologies \u00e0 explorer","text":"<ul> <li>LangChain pour les applications LLM</li> <li>Ray pour le machine learning distribu\u00e9</li> <li>Weights &amp; Biases pour l'exp\u00e9rimentation</li> </ul>"},{"location":"projects/#collaboration","title":"\ud83d\udcde Collaboration","text":"<p>Int\u00e9ress\u00e9 par un projet ? N'h\u00e9sitez pas \u00e0 me contacter !</p> <ul> <li>\ud83d\udce7 Email : loick.dernoncourt@example.com</li> <li>\ud83d\udcbc LinkedIn : linkedin.com/in/loick-dernoncourt</li> <li>\ud83d\udc19 GitHub : github.com/loick-dernoncourt</li> </ul> <p>Derni\u00e8re mise \u00e0 jour : October 22, 2025</p>"},{"location":"projects/classification-textes-avancee/","title":"\ud83d\udcdd Classification de textes multi-labels avec BERT","text":"","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#contexte-et-objectifs","title":"\ud83c\udfaf Contexte et Objectifs","text":"","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#probleme-a-resoudre","title":"Probl\u00e8me \u00e0 r\u00e9soudre","text":"<p>D\u00e9veloppement d'un syst\u00e8me de classification de textes multi-labels pour l'analyse automatique de documents l\u00e9gaux, capables d'identifier simultan\u00e9ment plusieurs cat\u00e9gories juridiques dans un m\u00eame document.</p>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#objectifs","title":"Objectifs","text":"<ul> <li>Objectif principal : Classifier des documents en 15+ cat\u00e9gories juridiques simultan\u00e9ment</li> <li>Objectifs secondaires : Latence &lt; 100ms, F1-Score &gt; 90%, Support multilingue</li> <li>M\u00e9triques de succ\u00e8s : F1-Score &gt; 90%, Precision &gt; 88%, Recall &gt; 90%</li> </ul>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#contexte-metier","title":"Contexte m\u00e9tier","text":"<ul> <li>Secteur : Droit / Legal Tech</li> <li>Utilisateurs : Avocats, Juristes, Assistants juridiques</li> <li>Impact attendu : R\u00e9duction de 70% du temps de tri des documents</li> </ul>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#donnees-et-sources","title":"\ud83d\udcca Donn\u00e9es et Sources","text":"","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#sources-de-donnees","title":"Sources de donn\u00e9es","text":"<ul> <li>Source principale : Corpus juridique fran\u00e7ais + Donn\u00e9es clients</li> <li>Format : Texte brut + Annotations JSON</li> <li>Taille : 250,000 documents</li> <li>P\u00e9riode : 2020-2024</li> <li>Fr\u00e9quence : Mise \u00e0 jour mensuelle</li> </ul>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#qualite-des-donnees","title":"Qualit\u00e9 des donn\u00e9es","text":"<ul> <li>Compl\u00e9tude : 95% de compl\u00e9tude</li> <li>Coh\u00e9rence : Validation par juristes experts</li> <li>Exactitude : Inter-annotateur agreement &gt; 90%</li> <li>Actualit\u00e9 : Documents r\u00e9cents et repr\u00e9sentatifs</li> </ul>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#categories-de-classification","title":"Cat\u00e9gories de classification","text":"Cat\u00e9gorie Nombre Exemples Fr\u00e9quence Droit civil 4 Contrat, Responsabilit\u00e9, Famille, Succession 35% Droit commercial 3 Soci\u00e9t\u00e9, Faillite, Concurrence 25% Droit p\u00e9nal 2 D\u00e9lit, Crime 15% Droit administratif 3 Fonction publique, Urbanisme, Fiscal 15% Droit social 2 Travail, S\u00e9curit\u00e9 sociale 10%","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#methodologie","title":"\ud83d\udd2c M\u00e9thodologie","text":"","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#1-preprocessing-des-textes","title":"1. Pr\u00e9processing des textes","text":"<pre><code>import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport spacy\n\n# T\u00e9l\u00e9chargement des ressources\nnltk.download('stopwords')\nnltk.download('punkt')\nnlp = spacy.load('fr_core_news_sm')\n\nclass LegalTextPreprocessor:\n    def __init__(self):\n        self.stop_words = set(stopwords.words('french'))\n        self.legal_patterns = {\n            'article': r'Article \\d+',\n            'loi': r'Loi n\u00b0\\d+',\n            'code': r'Code \\w+',\n            'jurisprudence': r'Cour de \\w+'\n        }\n\n    def clean_text(self, text):\n        \"\"\"Nettoyage sp\u00e9cialis\u00e9 pour les textes juridiques\"\"\"\n        # Suppression des num\u00e9ros de page\n        text = re.sub(r'Page \\d+', '', text)\n\n        # Normalisation des articles\n        text = re.sub(r'Art\\.', 'Article', text)\n\n        # Suppression des r\u00e9f\u00e9rences courtes\n        text = re.sub(r'v\\.', 'versus', text)\n\n        return text\n\n    def extract_legal_entities(self, text):\n        \"\"\"Extraction d'entit\u00e9s juridiques\"\"\"\n        doc = nlp(text)\n        entities = []\n\n        for ent in doc.ents:\n            if ent.label_ in ['PERSON', 'ORG', 'LAW']:\n                entities.append(ent.text)\n\n        return entities\n\n    def preprocess_document(self, text):\n        \"\"\"Pipeline complet de preprocessing\"\"\"\n        # Nettoyage\n        cleaned_text = self.clean_text(text)\n\n        # Extraction d'entit\u00e9s\n        entities = self.extract_legal_entities(cleaned_text)\n\n        # Tokenisation\n        tokens = word_tokenize(cleaned_text.lower())\n\n        # Suppression des stop words\n        tokens = [token for token in tokens if token not in self.stop_words]\n\n        return {\n            'text': ' '.join(tokens),\n            'entities': entities,\n            'length': len(tokens)\n        }\n</code></pre>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#2-architecture-du-modele","title":"2. Architecture du mod\u00e8le","text":"<pre><code>import torch\nimport torch.nn as nn\nfrom transformers import BertTokenizer, BertModel\nfrom torch.utils.data import Dataset, DataLoader\n\nclass LegalBERTClassifier(nn.Module):\n    def __init__(self, num_labels=15, dropout_rate=0.3):\n        super(LegalBERTClassifier, self).__init__()\n\n        # Backbone BERT\n        self.bert = BertModel.from_pretrained('dbmdz/bert-base-french-cased')\n        self.dropout = nn.Dropout(dropout_rate)\n\n        # Classification heads\n        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, input_ids, attention_mask, token_type_ids=None):\n        # BERT encoding\n        outputs = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids\n        )\n\n        # Pooling\n        pooled_output = outputs.pooler_output\n\n        # Classification\n        logits = self.classifier(self.dropout(pooled_output))\n        probabilities = self.sigmoid(logits)\n\n        return logits, probabilities\n\nclass LegalDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        labels = self.labels[idx]\n\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(labels, dtype=torch.float)\n        }\n</code></pre>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#3-entrainement-avec-techniques-avancees","title":"3. Entra\u00eenement avec techniques avanc\u00e9es","text":"<pre><code>import torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom sklearn.metrics import f1_score, precision_score, recall_score\nimport numpy as np\n\nclass LegalBERTTrainer:\n    def __init__(self, model, train_loader, val_loader, device):\n        self.model = model\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.device = device\n\n        # Optimiseur avec weight decay\n        self.optimizer = optim.AdamW(\n            model.parameters(),\n            lr=2e-5,\n            weight_decay=0.01\n        )\n\n        # Scheduler\n        self.scheduler = CosineAnnealingLR(\n            self.optimizer,\n            T_max=len(train_loader) * 3  # 3 epochs\n        )\n\n        # Loss function pour multi-label\n        self.criterion = nn.BCEWithLogitsLoss()\n\n    def train_epoch(self):\n        self.model.train()\n        total_loss = 0\n        all_predictions = []\n        all_labels = []\n\n        for batch in self.train_loader:\n            input_ids = batch['input_ids'].to(self.device)\n            attention_mask = batch['attention_mask'].to(self.device)\n            labels = batch['labels'].to(self.device)\n\n            self.optimizer.zero_grad()\n\n            logits, probabilities = self.model(input_ids, attention_mask)\n            loss = self.criterion(logits, labels)\n\n            loss.backward()\n\n            # Gradient clipping\n            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n\n            self.optimizer.step()\n            self.scheduler.step()\n\n            total_loss += loss.item()\n\n            # Pr\u00e9dictions pour m\u00e9triques\n            predictions = (probabilities &gt; 0.5).float()\n            all_predictions.extend(predictions.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n        # Calcul des m\u00e9triques\n        f1 = f1_score(all_labels, all_predictions, average='macro')\n        precision = precision_score(all_labels, all_predictions, average='macro')\n        recall = recall_score(all_labels, all_predictions, average='macro')\n\n        return total_loss / len(self.train_loader), f1, precision, recall\n\n    def validate(self):\n        self.model.eval()\n        total_loss = 0\n        all_predictions = []\n        all_labels = []\n\n        with torch.no_grad():\n            for batch in self.val_loader:\n                input_ids = batch['input_ids'].to(self.device)\n                attention_mask = batch['attention_mask'].to(self.device)\n                labels = batch['labels'].to(self.device)\n\n                logits, probabilities = self.model(input_ids, attention_mask)\n                loss = self.criterion(logits, labels)\n\n                total_loss += loss.item()\n\n                predictions = (probabilities &gt; 0.5).float()\n                all_predictions.extend(predictions.cpu().numpy())\n                all_labels.extend(labels.cpu().numpy())\n\n        f1 = f1_score(all_labels, all_predictions, average='macro')\n        precision = precision_score(all_labels, all_predictions, average='macro')\n        recall = recall_score(all_labels, all_predictions, average='macro')\n\n        return total_loss / len(self.val_loader), f1, precision, recall\n</code></pre>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#4-api-de-production","title":"4. API de production","text":"<pre><code>from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nimport torch\nimport joblib\nimport numpy as np\n\napp = FastAPI(title=\"Legal Text Classification API\")\n\nclass TextInput(BaseModel):\n    text: str\n    threshold: float = 0.5\n\nclass ClassificationOutput(BaseModel):\n    predictions: dict\n    confidence_scores: dict\n    processing_time: float\n\n# Chargement du mod\u00e8le\nmodel = torch.load('legal_bert_model.pth', map_location='cpu')\ntokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-french-cased')\nlabel_encoder = joblib.load('label_encoder.pkl')\n\n@app.post(\"/classify\", response_model=ClassificationOutput)\nasync def classify_text(input_data: TextInput):\n    import time\n    start_time = time.time()\n\n    try:\n        # Tokenisation\n        inputs = tokenizer(\n            input_data.text,\n            return_tensors='pt',\n            truncation=True,\n            padding=True,\n            max_length=512\n        )\n\n        # Pr\u00e9diction\n        with torch.no_grad():\n            logits, probabilities = model(**inputs)\n            probabilities = probabilities.cpu().numpy()[0]\n\n        # Filtrage par seuil\n        predictions = {}\n        confidence_scores = {}\n\n        for i, (label, prob) in enumerate(zip(label_encoder.classes_, probabilities)):\n            if prob &gt; input_data.threshold:\n                predictions[label] = True\n                confidence_scores[label] = float(prob)\n            else:\n                predictions[label] = False\n                confidence_scores[label] = float(prob)\n\n        processing_time = time.time() - start_time\n\n        return ClassificationOutput(\n            predictions=predictions,\n            confidence_scores=confidence_scores,\n            processing_time=processing_time\n        )\n\n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n</code></pre>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#resultats-et-metriques","title":"\ud83d\udcc8 R\u00e9sultats et M\u00e9triques","text":"","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#performance-globale","title":"Performance globale","text":"M\u00e9trique Valeur Baseline Am\u00e9lioration F1-Score (macro) 91.8% 78.5% +16.9% Precision (macro) 89.2% 76.3% +16.9% Recall (macro) 90.1% 77.8% +15.8% Hamming Loss 0.082 0.156 +47.4%","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#performance-par-categorie","title":"Performance par cat\u00e9gorie","text":"Cat\u00e9gorie Precision Recall F1-Score Support Droit civil 92.1% 89.3% 90.7% 2,500 Droit commercial 88.7% 91.2% 89.9% 1,800 Droit p\u00e9nal 94.3% 87.6% 90.8% 1,200 Droit administratif 87.9% 90.4% 89.1% 1,100 Droit social 91.2% 88.9% 90.0% 800","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#metriques-de-performance","title":"M\u00e9triques de performance","text":"<ul> <li>Latence moyenne : 45ms</li> <li>Throughput : 500 documents/minute</li> <li>Pr\u00e9cision par document : 94.2%</li> <li>Taux de faux positifs : 2.1%</li> </ul>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#deploiement","title":"\ud83d\ude80 D\u00e9ploiement","text":"","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#architecture-de-production","title":"Architecture de production","text":"<ul> <li>Environnement : Docker + Kubernetes</li> <li>API : FastAPI avec documentation automatique</li> <li>Base de donn\u00e9es : PostgreSQL + Redis</li> <li>Monitoring : MLflow + Prometheus</li> <li>CI/CD : GitHub Actions</li> </ul>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#code-de-deploiement","title":"Code de d\u00e9ploiement","text":"<pre><code># Configuration de production\nimport os\nfrom prometheus_client import Counter, Histogram, generate_latest\n\n# M\u00e9triques\nCLASSIFICATION_COUNTER = Counter('classifications_total', 'Total classifications')\nCLASSIFICATION_LATENCY = Histogram('classification_duration_seconds', 'Classification latency')\nCONFIDENCE_HISTOGRAM = Histogram('classification_confidence', 'Classification confidence')\n\n@app.middleware(\"http\")\nasync def add_metrics(request, call_next):\n    start_time = time.time()\n    response = await call_next(request)\n\n    CLASSIFICATION_LATENCY.observe(time.time() - start_time)\n    CLASSIFICATION_COUNTER.inc()\n\n    return response\n\n@app.get(\"/metrics\")\nasync def metrics():\n    return Response(generate_latest(), media_type=\"text/plain\")\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\n        \"status\": \"healthy\",\n        \"model_loaded\": True,\n        \"version\": \"1.0.0\"\n    }\n</code></pre>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#visualisations","title":"\ud83d\udcca Visualisations","text":"","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#matrice-de-confusion-multi-labels","title":"Matrice de confusion multi-labels","text":"<pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import multilabel_confusion_matrix\n\n# Visualisation des m\u00e9triques\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\n# F1-Score par cat\u00e9gorie\ncategories = ['Droit civil', 'Droit commercial', 'Droit p\u00e9nal', 'Droit administratif', 'Droit social']\nf1_scores = [90.7, 89.9, 90.8, 89.1, 90.0]\n\naxes[0, 0].bar(categories, f1_scores, color='skyblue')\naxes[0, 0].set_title('F1-Score par cat\u00e9gorie')\naxes[0, 0].set_ylabel('F1-Score (%)')\naxes[0, 0].tick_params(axis='x', rotation=45)\n\n# Distribution des confidences\nconfidences = np.random.beta(2, 1, 1000)  # Simulation\naxes[0, 1].hist(confidences, bins=50, alpha=0.7, color='lightgreen')\naxes[0, 1].set_title('Distribution des confidences')\naxes[0, 1].set_xlabel('Confidence')\naxes[0, 1].set_ylabel('Fr\u00e9quence')\n\n# Latence dans le temps\ntime_points = np.arange(0, 100, 1)\nlatencies = 45 + np.random.normal(0, 5, 100)\naxes[1, 0].plot(time_points, latencies, alpha=0.7)\naxes[1, 0].set_title('Latence dans le temps')\naxes[1, 0].set_xlabel('Temps (s)')\naxes[1, 0].set_ylabel('Latence (ms)')\n\n# Heatmap des corr\u00e9lations entre cat\u00e9gories\ncorrelation_matrix = np.random.rand(5, 5)\ncorrelation_matrix = (correlation_matrix + correlation_matrix.T) / 2\nnp.fill_diagonal(correlation_matrix, 1)\n\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', \n            xticklabels=categories, yticklabels=categories, ax=axes[1, 1])\naxes[1, 1].set_title('Corr\u00e9lations entre cat\u00e9gories')\n\nplt.tight_layout()\nplt.show()\n</code></pre>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#liens-et-ressources","title":"\ud83d\udd17 Liens et ressources","text":"","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#code-source","title":"Code source","text":"<ul> <li>Repository GitHub : github.com/loick-dernoncourt/legal-text-classification</li> <li>Notebooks Jupyter : github.com/loick-dernoncourt/legal-text-classification/tree/main/notebooks</li> </ul>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#demonstrations","title":"D\u00e9monstrations","text":"<ul> <li>D\u00e9mo interactive : legal-classification-demo.example.com</li> <li>API Documentation : legal-classification-api.example.com/docs</li> <li>Dashboard : legal-classification-dashboard.example.com</li> </ul>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#documentation","title":"Documentation","text":"<ul> <li>Rapport technique : legal-classification-report.example.com</li> <li>Pr\u00e9sentation : legal-classification-slides.example.com</li> <li>Article de blog : blog.example.com/legal-text-classification</li> </ul>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#prochaines-etapes","title":"\ud83c\udfaf Prochaines \u00e9tapes","text":"","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#ameliorations-prevues","title":"Am\u00e9liorations pr\u00e9vues","text":"<ul> <li> Support multilingue (anglais, espagnol)</li> <li> Classification hi\u00e9rarchique des textes</li> <li> Extraction d'entit\u00e9s juridiques</li> <li> Int\u00e9gration avec syst\u00e8mes de gestion documentaire</li> </ul>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/classification-textes-avancee/#technologies-a-explorer","title":"Technologies \u00e0 explorer","text":"<ul> <li> RoBERTa pour de meilleures performances</li> <li> Legal-BERT sp\u00e9cialis\u00e9</li> <li> Few-shot learning pour nouvelles cat\u00e9gories</li> <li> Explicabilit\u00e9 avec SHAP</li> </ul> <p>Derni\u00e8re mise \u00e0 jour : October 22, 2025</p>","tags":["nlp","deep-learning","bert","transformers","text-classification","multi-label","production"]},{"location":"projects/detection-objets-temps-reel/","title":"\ud83c\udfaf D\u00e9tection d'objets en temps r\u00e9el avec YOLO","text":"","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#contexte-et-objectifs","title":"\ud83c\udfaf Contexte et Objectifs","text":"","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#probleme-a-resoudre","title":"Probl\u00e8me \u00e0 r\u00e9soudre","text":"<p>D\u00e9veloppement d'un syst\u00e8me de d\u00e9tection d'objets en temps r\u00e9el pour la surveillance industrielle et la s\u00e9curit\u00e9, capable d'identifier et de localiser des objets dans un flux vid\u00e9o continu.</p>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#objectifs","title":"Objectifs","text":"<ul> <li>Objectif principal : D\u00e9tecter et classifier 80+ classes d'objets en temps r\u00e9el</li> <li>Objectifs secondaires : Latence &lt; 50ms, FPS &gt; 25, Pr\u00e9cision &gt; 95%</li> <li>M\u00e9triques de succ\u00e8s : mAP@0.5 &gt; 0.95, FPS &gt; 25, Latence &lt; 50ms</li> </ul>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#contexte-metier","title":"Contexte m\u00e9tier","text":"<ul> <li>Secteur : Industrie / S\u00e9curit\u00e9 / Retail</li> <li>Utilisateurs : Op\u00e9rateurs de surveillance, Responsables s\u00e9curit\u00e9</li> <li>Impact attendu : R\u00e9duction de 60% des incidents non d\u00e9tect\u00e9s</li> </ul>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#donnees-et-sources","title":"\ud83d\udcca Donn\u00e9es et Sources","text":"","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#sources-de-donnees","title":"Sources de donn\u00e9es","text":"<ul> <li>Source principale : COCO Dataset + Donn\u00e9es industrielles</li> <li>Format : Images (640x640) + Annotations YOLO</li> <li>Taille : 500,000 images d'entra\u00eenement</li> <li>P\u00e9riode : 2022-2024</li> <li>Fr\u00e9quence : Collecte continue</li> </ul>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#qualite-des-donnees","title":"Qualit\u00e9 des donn\u00e9es","text":"<ul> <li>Compl\u00e9tude : 98% de compl\u00e9tude</li> <li>Coh\u00e9rence : Validation par experts m\u00e9tier</li> <li>Exactitude : Double validation des annotations</li> <li>Actualit\u00e9 : Donn\u00e9es r\u00e9centes et repr\u00e9sentatives</li> </ul>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#classes-detectees","title":"Classes d\u00e9tect\u00e9es","text":"Cat\u00e9gorie Nombre de classes Exemples Personnes 1 Person, Worker V\u00e9hicules 8 Car, Truck, Bus, Motorcycle Objets industriels 15 Conveyor, Machine, Tool S\u00e9curit\u00e9 5 Helmet, Vest, Gloves Autres 51+ COCO classes","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#methodologie","title":"\ud83d\udd2c M\u00e9thodologie","text":"","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#1-architecture-du-modele","title":"1. Architecture du mod\u00e8le","text":"<pre><code>import torch\nfrom ultralytics import YOLO\nimport cv2\nimport numpy as np\n\nclass RealTimeObjectDetector:\n    def __init__(self, model_path='yolov8n.pt', confidence=0.5, iou_threshold=0.45):\n        self.model = YOLO(model_path)\n        self.confidence = confidence\n        self.iou_threshold = iou_threshold\n        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n    def preprocess_frame(self, frame):\n        \"\"\"Pr\u00e9processing de la frame pour YOLO\"\"\"\n        # Redimensionnement \u00e0 640x640\n        frame_resized = cv2.resize(frame, (640, 640))\n\n        # Normalisation\n        frame_normalized = frame_resized.astype(np.float32) / 255.0\n\n        return frame_normalized\n\n    def detect_objects(self, frame):\n        \"\"\"D\u00e9tection d'objets sur une frame\"\"\"\n        results = self.model(\n            frame,\n            conf=self.confidence,\n            iou=self.iou_threshold,\n            device=self.device,\n            verbose=False\n        )\n\n        return results[0]\n</code></pre>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#2-optimisation-des-performances","title":"2. Optimisation des performances","text":"<pre><code>import time\nfrom collections import deque\nimport threading\n\nclass PerformanceOptimizer:\n    def __init__(self, max_fps=30):\n        self.max_fps = max_fps\n        self.frame_time = 1.0 / max_fps\n        self.fps_history = deque(maxlen=30)\n\n    def calculate_fps(self, start_time, end_time):\n        \"\"\"Calcul du FPS en temps r\u00e9el\"\"\"\n        frame_time = end_time - start_time\n        fps = 1.0 / frame_time if frame_time &gt; 0 else 0\n        self.fps_history.append(fps)\n        return fps\n\n    def adaptive_quality(self, current_fps, target_fps=30):\n        \"\"\"Ajustement adaptatif de la qualit\u00e9\"\"\"\n        if current_fps &lt; target_fps * 0.8:\n            # R\u00e9duire la r\u00e9solution\n            return 0.8\n        elif current_fps &gt; target_fps * 1.2:\n            # Augmenter la r\u00e9solution\n            return 1.2\n        return 1.0\n</code></pre>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#3-pipeline-de-traitement","title":"3. Pipeline de traitement","text":"<pre><code>class ObjectDetectionPipeline:\n    def __init__(self, model_path, confidence=0.5):\n        self.detector = RealTimeObjectDetector(model_path, confidence)\n        self.optimizer = PerformanceOptimizer()\n        self.tracker = ObjectTracker()\n\n    def process_video_stream(self, video_source=0):\n        \"\"\"Traitement du flux vid\u00e9o en temps r\u00e9el\"\"\"\n        cap = cv2.VideoCapture(video_source)\n\n        while True:\n            start_time = time.time()\n\n            # Capture de la frame\n            ret, frame = cap.read()\n            if not ret:\n                break\n\n            # D\u00e9tection d'objets\n            results = self.detector.detect_objects(frame)\n\n            # Tracking des objets\n            tracked_objects = self.tracker.update(results)\n\n            # Visualisation\n            annotated_frame = self.draw_detections(frame, tracked_objects)\n\n            # Calcul du FPS\n            end_time = time.time()\n            fps = self.optimizer.calculate_fps(start_time, end_time)\n\n            # Affichage\n            cv2.putText(annotated_frame, f'FPS: {fps:.1f}', \n                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n            cv2.imshow('Object Detection', annotated_frame)\n\n            if cv2.waitKey(1) &amp; 0xFF == ord('q'):\n                break\n\n        cap.release()\n        cv2.destroyAllWindows()\n</code></pre>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#4-api-de-production","title":"4. API de production","text":"<pre><code>from fastapi import FastAPI, WebSocket, WebSocketDisconnect\nimport asyncio\nimport json\nimport base64\nfrom io import BytesIO\nfrom PIL import Image\n\napp = FastAPI(title=\"Real-time Object Detection API\")\n\nclass ConnectionManager:\n    def __init__(self):\n        self.active_connections: List[WebSocket] = []\n        self.detector = RealTimeObjectDetector()\n\n    async def connect(self, websocket: WebSocket):\n        await websocket.accept()\n        self.active_connections.append(websocket)\n\n    async def disconnect(self, websocket: WebSocket):\n        self.active_connections.remove(websocket)\n\n    async def broadcast_detection(self, data: dict):\n        for connection in self.active_connections:\n            try:\n                await connection.send_text(json.dumps(data))\n            except:\n                await self.disconnect(connection)\n\nmanager = ConnectionManager()\n\n@app.websocket(\"/ws/detect\")\nasync def websocket_endpoint(websocket: WebSocket):\n    await manager.connect(websocket)\n    try:\n        while True:\n            # R\u00e9ception de l'image\n            data = await websocket.receive_text()\n            image_data = json.loads(data)\n\n            # D\u00e9codage de l'image\n            image_bytes = base64.b64decode(image_data['image'])\n            image = Image.open(BytesIO(image_bytes))\n            frame = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n\n            # D\u00e9tection\n            results = manager.detector.detect_objects(frame)\n\n            # Formatage des r\u00e9sultats\n            detections = []\n            for box in results.boxes:\n                detection = {\n                    'class': int(box.cls[0]),\n                    'confidence': float(box.conf[0]),\n                    'bbox': box.xyxy[0].tolist()\n                }\n                detections.append(detection)\n\n            # Envoi des r\u00e9sultats\n            await manager.broadcast_detection({\n                'detections': detections,\n                'timestamp': time.time()\n            })\n\n    except WebSocketDisconnect:\n        await manager.disconnect(websocket)\n</code></pre>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#resultats-et-metriques","title":"\ud83d\udcc8 R\u00e9sultats et M\u00e9triques","text":"","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#performance-du-modele","title":"Performance du mod\u00e8le","text":"M\u00e9trique Valeur Baseline Am\u00e9lioration mAP@0.5 0.956 0.823 +16.2% mAP@0.5:0.95 0.734 0.612 +19.9% Precision 0.995 0.891 +11.7% Recall 0.943 0.856 +10.2% F1-Score 0.968 0.873 +10.9%","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#performance-temps-reel","title":"Performance temps r\u00e9el","text":"M\u00e9trique Valeur Objectif Statut FPS moyen 32.4 &gt; 25 \u2705 Latence 28ms &lt; 50ms \u2705 CPU Usage 45% &lt; 70% \u2705 GPU Memory 2.1GB &lt; 4GB \u2705","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#performance-par-classe","title":"Performance par classe","text":"Classe Precision Recall F1-Score Support Person 99.2% 96.8% 98.0% 1,250 Car 98.9% 94.5% 96.6% 2,100 Truck 97.8% 92.1% 94.9% 450 Helmet 99.5% 98.2% 98.8% 320","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#deploiement","title":"\ud83d\ude80 D\u00e9ploiement","text":"","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#architecture-de-production","title":"Architecture de production","text":"<ul> <li>Environnement : Docker + Kubernetes</li> <li>API : FastAPI avec WebSocket</li> <li>Streaming : RTMP + WebRTC</li> <li>Monitoring : Prometheus + Grafana</li> <li>Storage : Redis + PostgreSQL</li> </ul>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#code-de-deploiement","title":"Code de d\u00e9ploiement","text":"<pre><code># docker-compose.yml\nversion: '3.8'\nservices:\n  object-detection:\n    build: .\n    ports:\n      - \"8000:8000\"\n    environment:\n      - MODEL_PATH=/app/models/yolov8n.pt\n      - REDIS_URL=redis://redis:6379\n    volumes:\n      - ./models:/app/models\n    depends_on:\n      - redis\n      - postgres\n\n  redis:\n    image: redis:alpine\n    ports:\n      - \"6379:6379\"\n\n  postgres:\n    image: postgres:13\n    environment:\n      POSTGRES_DB: detections\n      POSTGRES_USER: user\n      POSTGRES_PASSWORD: password\n    volumes:\n      - postgres_data:/var/lib/postgresql/data\n\nvolumes:\n  postgres_data:\n</code></pre>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#monitoring","title":"Monitoring","text":"<pre><code>import prometheus_client\nfrom prometheus_client import Counter, Histogram, Gauge\n\n# M\u00e9triques Prometheus\nDETECTION_COUNTER = Counter('detections_total', 'Total detections')\nDETECTION_LATENCY = Histogram('detection_duration_seconds', 'Detection latency')\nFPS_GAUGE = Gauge('fps_current', 'Current FPS')\nCONFIDENCE_HISTOGRAM = Histogram('detection_confidence', 'Detection confidence')\n\n@app.middleware(\"http\")\nasync def add_metrics(request, call_next):\n    start_time = time.time()\n    response = await call_next(request)\n\n    DETECTION_LATENCY.observe(time.time() - start_time)\n    DETECTION_COUNTER.inc()\n\n    return response\n</code></pre>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#visualisations","title":"\ud83d\udcca Visualisations","text":"","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#courbe-de-precision","title":"Courbe de pr\u00e9cision","text":"<pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Visualisation des m\u00e9triques\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# mAP par classe\nclasses = ['Person', 'Car', 'Truck', 'Helmet', 'Other']\nmap_scores = [0.98, 0.96, 0.94, 0.99, 0.92]\naxes[0, 0].bar(classes, map_scores)\naxes[0, 0].set_title('mAP@0.5 par classe')\naxes[0, 0].set_ylabel('mAP Score')\n\n# Distribution des confidences\nconfidences = np.random.beta(2, 1, 1000)  # Simulation\naxes[0, 1].hist(confidences, bins=50, alpha=0.7)\naxes[0, 1].set_title('Distribution des confidences')\naxes[0, 1].set_xlabel('Confidence')\naxes[0, 1].set_ylabel('Fr\u00e9quence')\n\n# FPS dans le temps\ntime_points = np.arange(0, 60, 1)\nfps_values = 30 + np.random.normal(0, 2, 60)\naxes[1, 0].plot(time_points, fps_values)\naxes[1, 0].set_title('FPS dans le temps')\naxes[1, 0].set_xlabel('Temps (s)')\naxes[1, 0].set_ylabel('FPS')\n\n# Latence par frame\nlatencies = np.random.exponential(0.03, 1000)  # Simulation\naxes[1, 1].hist(latencies, bins=50, alpha=0.7)\naxes[1, 1].set_title('Distribution des latences')\naxes[1, 1].set_xlabel('Latence (s)')\naxes[1, 1].set_ylabel('Fr\u00e9quence')\n\nplt.tight_layout()\nplt.show()\n</code></pre>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#liens-et-ressources","title":"\ud83d\udd17 Liens et ressources","text":"","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#code-source","title":"Code source","text":"<ul> <li>Repository GitHub : github.com/loick-dernoncourt/real-time-object-detection</li> <li>Notebooks Jupyter : github.com/loick-dernoncourt/real-time-object-detection/tree/main/notebooks</li> </ul>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#demonstrations","title":"D\u00e9monstrations","text":"<ul> <li>D\u00e9mo interactive : object-detection-demo.example.com</li> <li>API Documentation : object-detection-api.example.com/docs</li> <li>Dashboard : object-detection-dashboard.example.com</li> </ul>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#documentation","title":"Documentation","text":"<ul> <li>Rapport technique : object-detection-report.example.com</li> <li>Pr\u00e9sentation : object-detection-slides.example.com</li> <li>Article de blog : blog.example.com/real-time-object-detection</li> </ul>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#prochaines-etapes","title":"\ud83c\udfaf Prochaines \u00e9tapes","text":"","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#ameliorations-prevues","title":"Am\u00e9liorations pr\u00e9vues","text":"<ul> <li> Support multi-cam\u00e9ras simultan\u00e9es</li> <li> D\u00e9tection 3D avec LiDAR</li> <li> Optimisation pour edge devices</li> <li> Int\u00e9gration avec syst\u00e8mes de s\u00e9curit\u00e9</li> </ul>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/detection-objets-temps-reel/#technologies-a-explorer","title":"Technologies \u00e0 explorer","text":"<ul> <li> YOLO v9 et v10</li> <li> TensorRT pour optimisation GPU</li> <li> ONNX Runtime pour d\u00e9ploiement</li> <li> WebRTC pour streaming temps r\u00e9el</li> </ul> <p>Derni\u00e8re mise \u00e0 jour : October 22, 2025</p>","tags":["computer-vision","deep-learning","yolo","opencv","real-time","fastapi","production"]},{"location":"projects/mar25-bds-compagnon-immo/","title":"\ud83c\udfe0 Compagnon Immo - Pr\u00e9diction Immobili\u00e8re","text":"<p>!!! success \"\ud83c\udfaf Valeur m\u00e9tier\"     Pr\u00e9diction pr\u00e9cise des prix immobiliers avec clustering spatio-temporel, dashboards interactifs et API de pr\u00e9diction en temps r\u00e9el.</p>"},{"location":"projects/mar25-bds-compagnon-immo/#contexte-du-projet","title":"\ud83d\udccb Contexte du projet","text":""},{"location":"projects/mar25-bds-compagnon-immo/#objectif","title":"\ud83c\udfaf Objectif","text":"<p>D\u00e9velopper un syst\u00e8me de pr\u00e9diction des prix immobiliers (\u20ac/m\u00b2) en combinant analyse spatiale et temporelle pour une estimation pr\u00e9cise et fiable.</p>"},{"location":"projects/mar25-bds-compagnon-immo/#defi","title":"\ud83d\udd0d D\u00e9fi","text":"<ul> <li>Int\u00e9grer la dimension g\u00e9ographique (clustering spatial)</li> <li>Prendre en compte l'\u00e9volution temporelle des prix</li> <li>Cr\u00e9er une interface utilisateur intuitive</li> <li>D\u00e9ployer une API de pr\u00e9diction scalable</li> </ul>"},{"location":"projects/mar25-bds-compagnon-immo/#stack-technique","title":"\u2699\ufe0f Stack technique","text":"<ul> <li> <p> Langages</p> <p>Python - D\u00e9veloppement principal</p> </li> <li> <p> Frameworks</p> <p>FastAPI - API REST Streamlit - Dashboard interactif</p> </li> <li> <p> Outils</p> <p>joblib - S\u00e9rialisation mod\u00e8les Git - Versioning</p> </li> </ul>"},{"location":"projects/mar25-bds-compagnon-immo/#resultats-performance","title":"\ud83d\udcca R\u00e9sultats &amp; Performance","text":""},{"location":"projects/mar25-bds-compagnon-immo/#metriques-de-qualite","title":"\ud83c\udfaf M\u00e9triques de qualit\u00e9","text":"<ul> <li>R\u00b2 : &gt; 0.96 (excellente corr\u00e9lation)</li> <li>MAE : ~2.4k\u20ac/m\u00b2 (erreur moyenne acceptable)</li> <li>MAPE : &lt; 3% (pr\u00e9cision remarquable)</li> </ul>"},{"location":"projects/mar25-bds-compagnon-immo/#impact-business","title":"\ud83d\udcc8 Impact business","text":"<ul> <li>Pr\u00e9cision : Pr\u00e9dictions fiables pour investisseurs</li> <li>Rapidit\u00e9 : API temps r\u00e9el (&lt; 100ms)</li> <li>Accessibilit\u00e9 : Interface utilisateur intuitive</li> </ul>"},{"location":"projects/mar25-bds-compagnon-immo/#fonctionnalites","title":"\ud83d\ude80 Fonctionnalit\u00e9s","text":""},{"location":"projects/mar25-bds-compagnon-immo/#analyse-spatiale","title":"\ud83d\udd0d Analyse spatiale","text":"<ul> <li>Clustering g\u00e9ographique des zones</li> <li>Identification des tendances locales</li> <li>Visualisation cartographique</li> </ul>"},{"location":"projects/mar25-bds-compagnon-immo/#dimension-temporelle","title":"\ud83d\udcc5 Dimension temporelle","text":"<ul> <li>\u00c9volution des prix dans le temps</li> <li>Pr\u00e9dictions saisonni\u00e8res</li> <li>Tendances long terme</li> </ul>"},{"location":"projects/mar25-bds-compagnon-immo/#interface-utilisateur","title":"\ud83d\udda5\ufe0f Interface utilisateur","text":"<ul> <li>Dashboard Streamlit interactif</li> <li>Visualisations dynamiques</li> <li>Export des r\u00e9sultats</li> </ul>"},{"location":"projects/mar25-bds-compagnon-immo/#api-de-prediction","title":"\u26a1 API de pr\u00e9diction","text":"<ul> <li>Endpoints REST optimis\u00e9s</li> <li>Documentation automatique</li> <li>D\u00e9ploiement scalable</li> </ul>"},{"location":"projects/mar25-bds-compagnon-immo/#liens-demonstrations","title":"\ud83d\udd17 Liens &amp; D\u00e9monstrations","text":"<ul> <li> <p> Repository</p> <p>Code source \u00c0 publier prochainement</p> </li> <li> <p> D\u00e9mo</p> <p>Dashboard interactif \u00c0 d\u00e9ployer</p> </li> <li> <p> API</p> <p>Documentation API \u00c0 d\u00e9ployer</p> </li> </ul>"},{"location":"projects/mar25-bds-compagnon-immo/#apprentissages","title":"\ud83c\udf93 Apprentissages","text":""},{"location":"projects/mar25-bds-compagnon-immo/#defis-techniques-resolus","title":"\ud83d\udca1 D\u00e9fis techniques r\u00e9solus","text":"<ul> <li>Optimisation des algorithmes de clustering</li> <li>Gestion des donn\u00e9es g\u00e9ospatiales</li> <li>Architecture microservices</li> </ul>"},{"location":"projects/mar25-bds-compagnon-immo/#competences-developpees","title":"\ud83d\ude80 Comp\u00e9tences d\u00e9velopp\u00e9es","text":"<ul> <li>Machine Learning avanc\u00e9</li> <li>D\u00e9veloppement d'APIs</li> <li>Interface utilisateur moderne</li> <li>D\u00e9ploiement cloud</li> </ul> <p>Projet d\u00e9velopp\u00e9 dans le cadre de la formation Data Science - 2024</p>"},{"location":"projects/prediction-churn-avancee/","title":"\ud83d\udcca Pr\u00e9diction de churn avanc\u00e9e avec XGBoost","text":"","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#contexte-et-objectifs","title":"\ud83c\udfaf Contexte et Objectifs","text":"","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#probleme-a-resoudre","title":"Probl\u00e8me \u00e0 r\u00e9soudre","text":"<p>D\u00e9veloppement d'un syst\u00e8me de pr\u00e9diction de churn pour une plateforme SaaS B2B, capable d'identifier les clients \u00e0 risque de r\u00e9siliation avec 3 mois d'avance.</p>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#objectifs","title":"Objectifs","text":"<ul> <li>Objectif principal : Pr\u00e9dire le churn avec 89%+ d'accuracy et 3 mois d'avance</li> <li>Objectifs secondaires : R\u00e9duire le churn de 25%, Am\u00e9liorer la r\u00e9tention client</li> <li>M\u00e9triques de succ\u00e8s : F1-Score &gt; 85%, Precision &gt; 80%, Recall &gt; 85%</li> </ul>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#contexte-metier","title":"Contexte m\u00e9tier","text":"<ul> <li>Secteur : SaaS B2B / Customer Success</li> <li>Utilisateurs : \u00c9quipes Customer Success, Sales, Marketing</li> <li>Impact attendu : R\u00e9duction de 25% du taux de churn, +15% de r\u00e9tention</li> </ul>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#donnees-et-sources","title":"\ud83d\udcca Donn\u00e9es et Sources","text":"","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#sources-de-donnees","title":"Sources de donn\u00e9es","text":"<ul> <li>Source principale : CRM + Analytics + Support tickets</li> <li>Format : PostgreSQL + JSON + CSV</li> <li>Taille : 50,000 clients, 2M+ interactions</li> <li>P\u00e9riode : 2020-2024</li> <li>Fr\u00e9quence : Mise \u00e0 jour quotidienne</li> </ul>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#qualite-des-donnees","title":"Qualit\u00e9 des donn\u00e9es","text":"<ul> <li>Compl\u00e9tude : 92% de compl\u00e9tude</li> <li>Coh\u00e9rence : Validation avec \u00e9quipes m\u00e9tier</li> <li>Exactitude : V\u00e9rification avec donn\u00e9es de facturation</li> <li>Actualit\u00e9 : Donn\u00e9es temps r\u00e9el via API</li> </ul>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#variables-disponibles","title":"Variables disponibles","text":"Cat\u00e9gorie Variables Description Importance Comportement 15 Sessions, Pages vues, Features utilis\u00e9es Haute Engagement 12 Support tickets, Training, Webinars Haute Business 8 Plan, Utilisateurs, Revenus, Dur\u00e9e Haute Support 10 Tickets, R\u00e9solution, Satisfaction Moyenne Marketing 6 Source, Campaigns, Lead score Faible","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#methodologie","title":"\ud83d\udd2c M\u00e9thodologie","text":"","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#1-feature-engineering-avance","title":"1. Feature Engineering avanc\u00e9","text":"<pre><code>import pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.feature_selection import SelectKBest, f_classif\nimport xgboost as xgb\n\nclass ChurnFeatureEngineer:\n    def __init__(self):\n        self.scaler = StandardScaler()\n        self.label_encoders = {}\n\n    def create_behavioral_features(self, df):\n        \"\"\"Cr\u00e9ation de features comportementales\"\"\"\n        # Fr\u00e9quence d'utilisation\n        df['usage_frequency'] = df['sessions_30d'] / 30\n        df['avg_session_duration'] = df['total_time'] / df['sessions_30d']\n\n        # Tendance d'utilisation\n        df['usage_trend'] = (df['sessions_30d'] - df['sessions_60d']) / df['sessions_60d']\n        df['feature_adoption_rate'] = df['features_used'] / df['features_available']\n\n        # Patterns d'utilisation\n        df['weekend_usage_ratio'] = df['weekend_sessions'] / df['sessions_30d']\n        df['peak_hours_usage'] = df['peak_hours_sessions'] / df['sessions_30d']\n\n        return df\n\n    def create_engagement_features(self, df):\n        \"\"\"Cr\u00e9ation de features d'engagement\"\"\"\n        # Score d'engagement composite\n        df['engagement_score'] = (\n            df['support_tickets_30d'] * 0.3 +\n            df['training_sessions'] * 0.4 +\n            df['webinar_attendance'] * 0.3\n        )\n\n        # D\u00e9lai de r\u00e9ponse aux communications\n        df['avg_response_time'] = df['total_response_time'] / df['communications_count']\n\n        # Satisfaction client\n        df['satisfaction_trend'] = df['satisfaction_score'] - df['satisfaction_score_prev']\n\n        return df\n\n    def create_business_features(self, df):\n        \"\"\"Cr\u00e9ation de features business\"\"\"\n        # Ratio revenus/utilisateurs\n        df['revenue_per_user'] = df['monthly_revenue'] / df['active_users']\n\n        # Croissance\n        df['revenue_growth'] = (df['monthly_revenue'] - df['monthly_revenue_prev']) / df['monthly_revenue_prev']\n        df['user_growth'] = (df['active_users'] - df['active_users_prev']) / df['active_users_prev']\n\n        # Plan vs utilisation\n        df['plan_utilization'] = df['features_used'] / df['plan_features']\n\n        return df\n\n    def create_temporal_features(self, df):\n        \"\"\"Cr\u00e9ation de features temporelles\"\"\"\n        # \u00c2ge du compte\n        df['account_age_days'] = (pd.to_datetime('now') - pd.to_datetime(df['created_at'])).dt.days\n\n        # Saisonnalit\u00e9\n        df['month'] = pd.to_datetime(df['created_at']).dt.month\n        df['quarter'] = pd.to_datetime(df['created_at']).dt.quarter\n\n        # Derni\u00e8re activit\u00e9\n        df['days_since_last_login'] = (pd.to_datetime('now') - pd.to_datetime(df['last_login'])).dt.days\n\n        return df\n</code></pre>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#2-gestion-du-desequilibre-des-classes","title":"2. Gestion du d\u00e9s\u00e9quilibre des classes","text":"<pre><code>from imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.combine import SMOTEENN\nfrom sklearn.model_selection import StratifiedKFold\n\nclass ChurnDataBalancer:\n    def __init__(self, strategy='smote'):\n        self.strategy = strategy\n        self.balancer = None\n\n    def fit_resample(self, X, y):\n        \"\"\"\u00c9quilibrage des classes\"\"\"\n        if self.strategy == 'smote':\n            self.balancer = SMOTE(random_state=42, k_neighbors=3)\n        elif self.strategy == 'smoteenn':\n            self.balancer = SMOTEENN(random_state=42)\n        elif self.strategy == 'undersample':\n            self.balancer = RandomUnderSampler(random_state=42)\n\n        X_balanced, y_balanced = self.balancer.fit_resample(X, y)\n\n        return X_balanced, y_balanced\n\n    def get_class_weights(self, y):\n        \"\"\"Calcul des poids de classe pour XGBoost\"\"\"\n        from sklearn.utils.class_weight import compute_class_weight\n\n        classes = np.unique(y)\n        weights = compute_class_weight('balanced', classes=classes, y=y)\n\n        return dict(zip(classes, weights))\n</code></pre>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#3-modelisation-avec-xgboost","title":"3. Mod\u00e9lisation avec XGBoost","text":"<pre><code>import xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV, TimeSeriesSplit\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\nimport optuna\n\nclass ChurnPredictor:\n    def __init__(self):\n        self.model = None\n        self.feature_importance = None\n        self.threshold = 0.5\n\n    def optimize_hyperparameters(self, X_train, y_train, X_val, y_val):\n        \"\"\"Optimisation des hyperparam\u00e8tres avec Optuna\"\"\"\n        def objective(trial):\n            params = {\n                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n                'max_depth': trial.suggest_int('max_depth', 3, 10),\n                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n                'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 10)\n            }\n\n            model = xgb.XGBClassifier(**params, random_state=42)\n            model.fit(X_train, y_train)\n\n            y_pred = model.predict(X_val)\n            score = f1_score(y_val, y_pred)\n\n            return score\n\n        study = optuna.create_study(direction='maximize')\n        study.optimize(objective, n_trials=100)\n\n        return study.best_params\n\n    def train_model(self, X_train, y_train, X_val, y_val, params=None):\n        \"\"\"Entra\u00eenement du mod\u00e8le avec validation\"\"\"\n        if params is None:\n            params = {\n                'n_estimators': 500,\n                'max_depth': 6,\n                'learning_rate': 0.1,\n                'subsample': 0.8,\n                'colsample_bytree': 0.8,\n                'reg_alpha': 1,\n                'reg_lambda': 1,\n                'scale_pos_weight': 3,\n                'random_state': 42\n            }\n\n        self.model = xgb.XGBClassifier(**params)\n        self.model.fit(\n            X_train, y_train,\n            eval_set=[(X_val, y_val)],\n            early_stopping_rounds=50,\n            verbose=False\n        )\n\n        # Feature importance\n        self.feature_importance = pd.DataFrame({\n            'feature': X_train.columns,\n            'importance': self.model.feature_importances_\n        }).sort_values('importance', ascending=False)\n\n        return self.model\n\n    def optimize_threshold(self, X_val, y_val):\n        \"\"\"Optimisation du seuil de classification\"\"\"\n        y_pred_proba = self.model.predict_proba(X_val)[:, 1]\n\n        thresholds = np.arange(0.1, 0.9, 0.05)\n        best_threshold = 0.5\n        best_f1 = 0\n\n        for threshold in thresholds:\n            y_pred = (y_pred_proba &gt; threshold).astype(int)\n            f1 = f1_score(y_val, y_pred)\n\n            if f1 &gt; best_f1:\n                best_f1 = f1\n                best_threshold = threshold\n\n        self.threshold = best_threshold\n        return best_threshold\n</code></pre>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#4-evaluation-et-interpretation","title":"4. \u00c9valuation et interpr\u00e9tation","text":"<pre><code>import shap\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nclass ChurnModelInterpreter:\n    def __init__(self, model, X_train):\n        self.model = model\n        self.explainer = shap.TreeExplainer(model)\n        self.X_train = X_train\n\n    def explain_prediction(self, X_sample):\n        \"\"\"Explication d'une pr\u00e9diction individuelle\"\"\"\n        shap_values = self.explainer.shap_values(X_sample)\n\n        # Plot SHAP values\n        shap.summary_plot(shap_values, X_sample, show=False)\n        plt.title('Explication de la pr\u00e9diction de churn')\n        plt.show()\n\n        return shap_values\n\n    def global_feature_importance(self):\n        \"\"\"Importance globale des features\"\"\"\n        shap_values = self.explainer.shap_values(self.X_train)\n\n        # Summary plot\n        shap.summary_plot(shap_values, self.X_train, show=False)\n        plt.title('Importance globale des features')\n        plt.show()\n\n        # Feature importance\n        feature_importance = pd.DataFrame({\n            'feature': self.X_train.columns,\n            'importance': np.abs(shap_values).mean(0)\n        }).sort_values('importance', ascending=False)\n\n        return feature_importance\n\n    def partial_dependence_plot(self, feature_name, X_sample):\n        \"\"\"Plot de d\u00e9pendance partielle\"\"\"\n        shap.dependence_plot(\n            feature_name, \n            self.explainer.shap_values(X_sample), \n            X_sample,\n            show=False\n        )\n        plt.title(f'D\u00e9pendance partielle - {feature_name}')\n        plt.show()\n</code></pre>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#resultats-et-metriques","title":"\ud83d\udcc8 R\u00e9sultats et M\u00e9triques","text":"","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#performance-du-modele","title":"Performance du mod\u00e8le","text":"M\u00e9trique Valeur Baseline Am\u00e9lioration Accuracy 89.2% 76.5% +16.6% Precision 87.8% 72.1% +21.8% Recall 89.1% 78.3% +13.8% F1-Score 88.5% 75.1% +17.8% AUC-ROC 0.94 0.82 +14.6%","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#impact-business","title":"Impact business","text":"M\u00e9trique Avant Apr\u00e8s Am\u00e9lioration Taux de churn 12.5% 9.4% -25% R\u00e9tention client 87.5% 90.6% +3.1% Revenus r\u00e9currents 100% 115% +15% Co\u00fbt d'acquisition 100% 85% -15%","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#performance-par-segment","title":"Performance par segment","text":"Segment Precision Recall F1-Score Clients Enterprise 92.1% 88.3% 90.2% 500 Mid-market 89.4% 91.2% 90.3% 1,200 SMB 85.6% 87.9% 86.7% 3,300","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#deploiement","title":"\ud83d\ude80 D\u00e9ploiement","text":"","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#architecture-de-production","title":"Architecture de production","text":"<ul> <li>Environnement : Docker + Kubernetes</li> <li>API : FastAPI avec documentation automatique</li> <li>Base de donn\u00e9es : PostgreSQL + Redis</li> <li>Monitoring : MLflow + Prometheus</li> <li>Scheduling : Apache Airflow</li> </ul>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#code-de-deploiement","title":"Code de d\u00e9ploiement","text":"<pre><code>from fastapi import FastAPI, BackgroundTasks\nfrom pydantic import BaseModel\nimport pandas as pd\nimport joblib\nimport redis\nimport json\n\napp = FastAPI(title=\"Churn Prediction API\")\n\n# Configuration\nredis_client = redis.Redis(host='localhost', port=6379, db=0)\nmodel = joblib.load('churn_model.pkl')\nfeature_engineer = joblib.load('feature_engineer.pkl')\n\nclass CustomerData(BaseModel):\n    customer_id: str\n    features: dict\n    prediction_date: str\n\nclass ChurnPrediction(BaseModel):\n    customer_id: str\n    churn_probability: float\n    risk_level: str\n    key_factors: list\n    recommendations: list\n\n@app.post(\"/predict\", response_model=ChurnPrediction)\nasync def predict_churn(customer_data: CustomerData):\n    # Feature engineering\n    features_df = pd.DataFrame([customer_data.features])\n    processed_features = feature_engineer.transform(features_df)\n\n    # Pr\u00e9diction\n    churn_prob = model.predict_proba(processed_features)[0][1]\n\n    # D\u00e9termination du niveau de risque\n    if churn_prob &gt; 0.8:\n        risk_level = \"Tr\u00e8s \u00e9lev\u00e9\"\n    elif churn_prob &gt; 0.6:\n        risk_level = \"\u00c9lev\u00e9\"\n    elif churn_prob &gt; 0.4:\n        risk_level = \"Mod\u00e9r\u00e9\"\n    else:\n        risk_level = \"Faible\"\n\n    # Facteurs cl\u00e9s (simulation)\n    key_factors = [\n        \"Baisse d'utilisation de 40%\",\n        \"Aucun ticket support r\u00e9cent\",\n        \"Plan sous-utilis\u00e9\"\n    ]\n\n    # Recommandations\n    recommendations = [\n        \"Proposer une session de formation\",\n        \"Contacter le customer success manager\",\n        \"Offrir un upgrade de plan\"\n    ]\n\n    return ChurnPrediction(\n        customer_id=customer_data.customer_id,\n        churn_probability=float(churn_prob),\n        risk_level=risk_level,\n        key_factors=key_factors,\n        recommendations=recommendations\n    )\n\n@app.post(\"/batch_predict\")\nasync def batch_predict(background_tasks: BackgroundTasks):\n    \"\"\"Pr\u00e9diction en lot pour tous les clients\"\"\"\n    background_tasks.add_task(run_batch_prediction)\n    return {\"message\": \"Batch prediction started\"}\n\nasync def run_batch_prediction():\n    \"\"\"Ex\u00e9cution de la pr\u00e9diction en lot\"\"\"\n    # R\u00e9cup\u00e9ration des donn\u00e9es clients\n    customers = get_all_customers()\n\n    predictions = []\n    for customer in customers:\n        prediction = predict_churn(customer)\n        predictions.append(prediction)\n\n    # Sauvegarde des r\u00e9sultats\n    save_predictions(predictions)\n</code></pre>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#visualisations","title":"\ud83d\udcca Visualisations","text":"","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#analyse-des-features-importantes","title":"Analyse des features importantes","text":"<pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Visualisation des m\u00e9triques\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\n\n# Feature importance\ntop_features = feature_importance.head(10)\naxes[0, 0].barh(top_features['feature'], top_features['importance'])\naxes[0, 0].set_title('Top 10 Features Importance')\naxes[0, 0].set_xlabel('Importance')\n\n# Distribution des probabilit\u00e9s\nchurn_probs = model.predict_proba(X_test)[:, 1]\naxes[0, 1].hist(churn_probs, bins=50, alpha=0.7, color='red')\naxes[0, 1].set_title('Distribution des probabilit\u00e9s de churn')\naxes[0, 1].set_xlabel('Probabilit\u00e9 de churn')\naxes[0, 1].set_ylabel('Fr\u00e9quence')\n\n# Courbe ROC\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(y_test, churn_probs)\nauc_score = auc(fpr, tpr)\n\naxes[1, 0].plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.3f})')\naxes[1, 0].plot([0, 1], [0, 1], 'k--')\naxes[1, 0].set_xlabel('Taux de faux positifs')\naxes[1, 0].set_ylabel('Taux de vrais positifs')\naxes[1, 0].set_title('Courbe ROC')\naxes[1, 0].legend()\n\n# Impact business\nmonths = ['Jan', 'F\u00e9v', 'Mar', 'Avr', 'Mai', 'Jun']\nchurn_rate = [12.5, 11.8, 10.2, 9.8, 9.4, 9.1]\nrevenue = [100, 102, 105, 108, 115, 118]\n\nax2 = axes[1, 1].twinx()\naxes[1, 1].plot(months, churn_rate, 'ro-', label='Taux de churn (%)')\nax2.plot(months, revenue, 'bo-', label='Revenus (index 100)')\naxes[1, 1].set_xlabel('Mois')\naxes[1, 1].set_ylabel('Taux de churn (%)', color='red')\nax2.set_ylabel('Revenus (index 100)', color='blue')\naxes[1, 1].set_title('Impact du mod\u00e8le sur le business')\naxes[1, 1].legend(loc='upper left')\nax2.legend(loc='upper right')\n\nplt.tight_layout()\nplt.show()\n</code></pre>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#liens-et-ressources","title":"\ud83d\udd17 Liens et ressources","text":"","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#code-source","title":"Code source","text":"<ul> <li>Repository GitHub : github.com/loick-dernoncourt/churn-prediction</li> <li>Notebooks Jupyter : github.com/loick-dernoncourt/churn-prediction/tree/main/notebooks</li> </ul>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#demonstrations","title":"D\u00e9monstrations","text":"<ul> <li>D\u00e9mo interactive : churn-prediction-demo.example.com</li> <li>API Documentation : churn-prediction-api.example.com/docs</li> <li>Dashboard : churn-prediction-dashboard.example.com</li> </ul>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#documentation","title":"Documentation","text":"<ul> <li>Rapport technique : churn-prediction-report.example.com</li> <li>Pr\u00e9sentation : churn-prediction-slides.example.com</li> <li>Article de blog : blog.example.com/churn-prediction</li> </ul>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#prochaines-etapes","title":"\ud83c\udfaf Prochaines \u00e9tapes","text":"","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#ameliorations-prevues","title":"Am\u00e9liorations pr\u00e9vues","text":"<ul> <li> Int\u00e9gration de donn\u00e9es comportementales temps r\u00e9el</li> <li> Mod\u00e8le de pr\u00e9diction de la valeur de vie client (LTV)</li> <li> Recommandations personnalis\u00e9es d'actions</li> <li> Int\u00e9gration avec CRM et outils de marketing</li> </ul>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/prediction-churn-avancee/#technologies-a-explorer","title":"Technologies \u00e0 explorer","text":"<ul> <li> Deep Learning pour patterns complexes</li> <li> Graph Neural Networks pour relations clients</li> <li> Reinforcement Learning pour optimisation d'actions</li> <li> Explicabilit\u00e9 avanc\u00e9e avec LIME et SHAP</li> </ul> <p>Derni\u00e8re mise \u00e0 jour : October 22, 2025</p>","tags":["machine-learning","classification","xgboost","feature-engineering","churn-prediction","business-intelligence","production"]},{"location":"projects/saas/","title":"\u2601\ufe0f SaaS Platform - Template Data-Ready","text":"<p>!!! success \"\ud83c\udfaf Template r\u00e9utilisable\"     Architecture SaaS scalable pr\u00eate pour des projets data avec authentification, APIs, et d\u00e9ploiement automatis\u00e9.</p>"},{"location":"projects/saas/#contexte-du-projet","title":"\ud83d\udccb Contexte du projet","text":""},{"location":"projects/saas/#objectif","title":"\ud83c\udfaf Objectif","text":"<p>Cr\u00e9er un template SaaS complet et r\u00e9utilisable pour acc\u00e9l\u00e9rer le d\u00e9veloppement de nouvelles applications data avec toutes les fonctionnalit\u00e9s essentielles.</p>"},{"location":"projects/saas/#defi","title":"\ud83d\udd0d D\u00e9fi","text":"<ul> <li>Architecture microservices scalable</li> <li>Authentification et autorisation robustes</li> <li>APIs RESTful optimis\u00e9es</li> <li>D\u00e9ploiement automatis\u00e9 CI/CD</li> <li>Monitoring et observabilit\u00e9</li> </ul>"},{"location":"projects/saas/#stack-technique","title":"\u2699\ufe0f Stack technique","text":"<ul> <li> <p> Backend</p> <p>Python - FastAPI, SQLAlchemy, Pydantic</p> </li> <li> <p> Base de donn\u00e9es</p> <p>PostgreSQL - Redis, Elasticsearch</p> </li> <li> <p> Infrastructure</p> <p>Docker - Kubernetes, AWS/GCP</p> </li> <li> <p> Frontend</p> <p>React - TypeScript, Material-UI</p> </li> </ul>"},{"location":"projects/saas/#resultats-performance","title":"\ud83d\udcca R\u00e9sultats &amp; Performance","text":""},{"location":"projects/saas/#metriques-techniques","title":"\ud83c\udfaf M\u00e9triques techniques","text":"<ul> <li>Temps de d\u00e9ploiement : &lt; 5 minutes</li> <li>Uptime : 99.9% de disponibilit\u00e9</li> <li>Latence API : &lt; 100ms (P95)</li> <li>Scalabilit\u00e9 : Auto-scaling horizontal</li> </ul>"},{"location":"projects/saas/#impact-business","title":"\ud83d\udcc8 Impact business","text":"<ul> <li>D\u00e9veloppement : 70% de temps \u00e9conomis\u00e9</li> <li>Maintenance : Infrastructure as Code</li> <li>S\u00e9curit\u00e9 : Standards enterprise</li> <li>Co\u00fbts : Optimisation cloud native</li> </ul>"},{"location":"projects/saas/#fonctionnalites","title":"\ud83d\ude80 Fonctionnalit\u00e9s","text":""},{"location":"projects/saas/#authentification-securite","title":"\ud83d\udd10 Authentification &amp; S\u00e9curit\u00e9","text":"<ul> <li>JWT tokens avec refresh</li> <li>OAuth2 / OIDC int\u00e9gration</li> <li>Rate limiting et throttling</li> <li>Audit logs complets</li> </ul>"},{"location":"projects/saas/#apis-data","title":"\ud83d\udcca APIs &amp; Data","text":"<ul> <li>RESTful APIs document\u00e9es</li> <li>GraphQL endpoint</li> <li>Real-time WebSockets</li> <li>File upload/processing</li> </ul>"},{"location":"projects/saas/#interface-utilisateur","title":"\ud83d\udda5\ufe0f Interface utilisateur","text":"<ul> <li>Dashboard admin complet</li> <li>Interface utilisateur moderne</li> <li>Responsive design</li> <li>Dark/Light mode</li> </ul>"},{"location":"projects/saas/#devops-monitoring","title":"\u26a1 DevOps &amp; Monitoring","text":"<ul> <li>CI/CD avec GitHub Actions</li> <li>Infrastructure as Code (Terraform)</li> <li>Monitoring avec Prometheus/Grafana</li> <li>Logs centralis\u00e9s (ELK Stack)</li> </ul>"},{"location":"projects/saas/#liens-demonstrations","title":"\ud83d\udd17 Liens &amp; D\u00e9monstrations","text":"<ul> <li> <p> Repository</p> <p>Code source Template open source</p> </li> <li> <p> D\u00e9mo</p> <p>Application live \u00c0 d\u00e9ployer</p> </li> <li> <p>:material-document:{ .lg .middle } Documentation</p> <p>Guide d'utilisation \u00c0 cr\u00e9er</p> </li> </ul>"},{"location":"projects/saas/#apprentissages","title":"\ud83c\udf93 Apprentissages","text":""},{"location":"projects/saas/#defis-techniques-resolus","title":"\ud83d\udca1 D\u00e9fis techniques r\u00e9solus","text":"<ul> <li>Architecture microservices complexe</li> <li>Gestion des \u00e9tats distribu\u00e9s</li> <li>Optimisation des performances</li> <li>S\u00e9curit\u00e9 multi-tenant</li> </ul>"},{"location":"projects/saas/#competences-developpees","title":"\ud83d\ude80 Comp\u00e9tences d\u00e9velopp\u00e9es","text":"<ul> <li>Architecture cloud-native</li> <li>DevOps et infrastructure</li> <li>S\u00e9curit\u00e9 applicative</li> <li>D\u00e9veloppement full-stack</li> </ul>"},{"location":"projects/saas/#utilisation-du-template","title":"\ud83d\udee0\ufe0f Utilisation du template","text":""},{"location":"projects/saas/#demarrage-rapide","title":"\ud83d\ude80 D\u00e9marrage rapide","text":"<pre><code># Cloner le template\ngit clone https://github.com/LoickDIA/SaaS.git\ncd saas-template\n\n# Configuration\ncp .env.example .env\n# \u00c9diter les variables d'environnement\n\n# D\u00e9ploiement\ndocker-compose up -d\n</code></pre>"},{"location":"projects/saas/#personnalisation","title":"\ud83d\udccb Personnalisation","text":"<ul> <li>Configuration des APIs</li> <li>Personnalisation de l'interface</li> <li>Ajout de fonctionnalit\u00e9s m\u00e9tier</li> <li>Int\u00e9gration de services externes</li> </ul> <p>Template SaaS data-ready - 2024</p>"},{"location":"projects/template/","title":"\ud83d\udccb Template de projet","text":"","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#contexte-et-objectifs","title":"\ud83c\udfaf Contexte et Objectifs","text":"","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#probleme-a-resoudre","title":"Probl\u00e8me \u00e0 r\u00e9soudre","text":"<p>Description claire du probl\u00e8me m\u00e9tier ou technique \u00e0 r\u00e9soudre...</p>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#objectifs","title":"Objectifs","text":"<ul> <li>Objectif principal : [Objectif principal du projet]</li> <li>Objectifs secondaires : [Objectifs secondaires]</li> <li>M\u00e9triques de succ\u00e8s : [M\u00e9triques pour \u00e9valuer le succ\u00e8s]</li> </ul>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#contexte-metier","title":"Contexte m\u00e9tier","text":"<ul> <li>Secteur : [Secteur d'activit\u00e9]</li> <li>Utilisateurs : [Cible utilisateurs]</li> <li>Impact attendu : [Impact sur le business]</li> </ul>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#donnees-et-sources","title":"\ud83d\udcca Donn\u00e9es et Sources","text":"","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#sources-de-donnees","title":"Sources de donn\u00e9es","text":"<ul> <li>Source principale : [Nom de la source]</li> <li>Format : CSV/JSON/Parquet/Database</li> <li>Taille : X millions d'enregistrements</li> <li>P\u00e9riode : 2020-2024</li> <li>Fr\u00e9quence : Quotidienne/Mensuelle/Annuelle</li> </ul>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#qualite-des-donnees","title":"Qualit\u00e9 des donn\u00e9es","text":"<ul> <li>Compl\u00e9tude : 95% de compl\u00e9tude</li> <li>Coh\u00e9rence : Validation des contraintes</li> <li>Exactitude : V\u00e9rification des valeurs</li> <li>Actualit\u00e9 : Donn\u00e9es \u00e0 jour</li> </ul>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#variables-disponibles","title":"Variables disponibles","text":"Variable Type Description Importance var1 Num\u00e9rique Description de la variable Haute var2 Cat\u00e9gorielle Description de la variable Moyenne var3 Temporelle Description de la variable Haute","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#methodologie","title":"\ud83d\udd2c M\u00e9thodologie","text":"","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#1-analyse-exploratoire-des-donnees-eda","title":"1. Analyse exploratoire des donn\u00e9es (EDA)","text":"<pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Chargement des donn\u00e9es\ndf = pd.read_csv('data.csv')\n\n# Statistiques descriptives\nprint(df.describe())\n\n# Visualisation des distributions\nplt.figure(figsize=(12, 8))\nsns.histplot(df['target'], kde=True)\nplt.title('Distribution de la variable cible')\nplt.show()\n</code></pre>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#2-preprocessing","title":"2. Pr\u00e9processing","text":"<pre><code>from sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Nettoyage des donn\u00e9es\ndf = df.dropna()\ndf = df.drop_duplicates()\n\n# Encodage des variables cat\u00e9gorielles\nle = LabelEncoder()\ndf['categorical_var'] = le.fit_transform(df['categorical_var'])\n\n# Normalisation\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n</code></pre>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#3-feature-engineering","title":"3. Feature Engineering","text":"<pre><code># Cr\u00e9ation de nouvelles features\ndf['feature_ratio'] = df['var1'] / df['var2']\ndf['feature_interaction'] = df['var1'] * df['var2']\n\n# S\u00e9lection des features\nfrom sklearn.feature_selection import SelectKBest, f_classif\nselector = SelectKBest(f_classif, k=10)\nX_selected = selector.fit_transform(X, y)\n</code></pre>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#4-modelisation","title":"4. Mod\u00e9lisation","text":"<pre><code>import torch\nimport torch.nn as nn\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Mod\u00e8le 1: Random Forest\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\ny_pred_rf = rf.predict(X_test)\n\n# Mod\u00e8le 2: R\u00e9seau de neurones\nclass MonModele(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(MonModele, self).__init__()\n        self.fc1 = nn.Linear(input_size, hidden_size)\n        self.fc2 = nn.Linear(hidden_size, output_size)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.2)\n\n    def forward(self, x):\n        x = self.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n        return x\n\n# Entra\u00eenement du mod\u00e8le\nmodel = MonModele(input_size, hidden_size, output_size)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n</code></pre>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#5-evaluation","title":"5. \u00c9valuation","text":"<pre><code>from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n# Calcul des m\u00e9triques\naccuracy = accuracy_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred, average='weighted')\nrecall = recall_score(y_test, y_pred, average='weighted')\nf1 = f1_score(y_test, y_pred, average='weighted')\n\nprint(f\"Accuracy: {accuracy:.3f}\")\nprint(f\"Precision: {precision:.3f}\")\nprint(f\"Recall: {recall:.3f}\")\nprint(f\"F1-Score: {f1:.3f}\")\n</code></pre>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#resultats-et-metriques","title":"\ud83d\udcc8 R\u00e9sultats et M\u00e9triques","text":"","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#performance-du-modele","title":"Performance du mod\u00e8le","text":"M\u00e9trique Valeur Baseline Am\u00e9lioration Accuracy 95.2% 78.5% +16.7% Precision 94.8% 76.2% +18.6% Recall 95.1% 77.8% +17.3% F1-Score 94.9% 77.0% +17.9%","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#analyse-des-erreurs","title":"Analyse des erreurs","text":"<ul> <li>Faux positifs : 2.1% des pr\u00e9dictions</li> <li>Faux n\u00e9gatifs : 1.8% des pr\u00e9dictions</li> <li>Classes les plus difficiles : [Classes avec le plus d'erreurs]</li> </ul>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#validation-croisee","title":"Validation crois\u00e9e","text":"<ul> <li>5-fold CV : 94.8% \u00b1 1.2%</li> <li>Stratified CV : 95.1% \u00b1 0.8%</li> <li>Time series CV : 94.5% \u00b1 1.5%</li> </ul>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#deploiement","title":"\ud83d\ude80 D\u00e9ploiement","text":"","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#architecture-de-deploiement","title":"Architecture de d\u00e9ploiement","text":"<ul> <li>Environnement : Docker + AWS ECS</li> <li>API : FastAPI avec documentation automatique</li> <li>Base de donn\u00e9es : PostgreSQL + Redis</li> <li>Monitoring : MLflow + CloudWatch</li> <li>CI/CD : GitHub Actions</li> </ul>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#code-de-deploiement","title":"Code de d\u00e9ploiement","text":"<pre><code>from fastapi import FastAPI\nimport joblib\nimport pandas as pd\n\napp = FastAPI()\n\n# Chargement du mod\u00e8le\nmodel = joblib.load('model.pkl')\nscaler = joblib.load('scaler.pkl')\n\n@app.post(\"/predict\")\nasync def predict(data: dict):\n    # Pr\u00e9processing\n    df = pd.DataFrame([data])\n    df_scaled = scaler.transform(df)\n\n    # Pr\u00e9diction\n    prediction = model.predict(df_scaled)\n    probability = model.predict_proba(df_scaled)\n\n    return {\n        \"prediction\": int(prediction[0]),\n        \"probability\": float(probability[0].max())\n    }\n</code></pre>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#monitoring","title":"Monitoring","text":"<ul> <li>M\u00e9triques de performance : Accuracy, Latence, Throughput</li> <li>Alertes : D\u00e9rive du mod\u00e8le, Erreurs de pr\u00e9diction</li> <li>Logs : Requ\u00eates, Erreurs, Performances</li> </ul>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#visualisations","title":"\ud83d\udcca Visualisations","text":"","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#graphiques-de-performance","title":"Graphiques de performance","text":"<pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Matrice de confusion\nplt.figure(figsize=(8, 6))\nsns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d')\nplt.title('Matrice de confusion')\nplt.show()\n\n# Courbe ROC\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(y_test, y_pred_proba)\nauc_score = auc(fpr, tpr)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, label=f'ROC Curve (AUC = {auc_score:.3f})')\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('Taux de faux positifs')\nplt.ylabel('Taux de vrais positifs')\nplt.title('Courbe ROC')\nplt.legend()\nplt.show()\n</code></pre>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#liens-et-ressources","title":"\ud83d\udd17 Liens et ressources","text":"","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#code-source","title":"Code source","text":"<ul> <li>Repository GitHub : github.com/loick-dernoncourt/projet-exemple</li> <li>Notebooks Jupyter : github.com/loick-dernoncourt/projet-exemple/tree/main/notebooks</li> </ul>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#demonstrations","title":"D\u00e9monstrations","text":"<ul> <li>D\u00e9mo interactive : demo.example.com</li> <li>API Documentation : api.example.com/docs</li> <li>Dashboard : dashboard.example.com</li> </ul>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#documentation","title":"Documentation","text":"<ul> <li>Rapport technique : rapport.example.com</li> <li>Pr\u00e9sentation : slides.example.com</li> <li>Article de blog : blog.example.com/projet</li> </ul>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#prochaines-etapes","title":"\ud83c\udfaf Prochaines \u00e9tapes","text":"","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#ameliorations-prevues","title":"Am\u00e9liorations pr\u00e9vues","text":"<ul> <li> Optimisation des hyperparam\u00e8tres</li> <li> Int\u00e9gration de nouvelles donn\u00e9es</li> <li> Am\u00e9lioration de la robustesse</li> <li> D\u00e9ploiement en production</li> </ul>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/template/#technologies-a-explorer","title":"Technologies \u00e0 explorer","text":"<ul> <li> MLOps avec Kubeflow</li> <li> Monitoring avec Weights &amp; Biases</li> <li> Optimisation avec Optuna</li> <li> Explicabilit\u00e9 avec SHAP</li> </ul> <p>Derni\u00e8re mise \u00e0 jour : October 22, 2025</p>","tags":["machine-learning","data-analysis","python","visualisation","nlp","computer-vision","deep-learning","pytorch","scikit-learn","pandas","numpy","matplotlib","seaborn","jupyter","git","docker","aws","sql","tableau","power-bi"]},{"location":"projects/valmed-automatisation/","title":"\ud83c\udfe5 VALMED - Automatisation M\u00e9dicale","text":"<p>!!! info \"\ud83d\udea7 En d\u00e9veloppement\"     Automatisation de processus m\u00e9dicaux pour am\u00e9liorer l'efficacit\u00e9 et la pr\u00e9cision des soins.</p>"},{"location":"projects/valmed-automatisation/#contexte-du-projet","title":"\ud83d\udccb Contexte du projet","text":""},{"location":"projects/valmed-automatisation/#objectif","title":"\ud83c\udfaf Objectif","text":"<p>D\u00e9velopper une solution d'automatisation pour optimiser les processus m\u00e9dicaux et r\u00e9duire les erreurs humaines dans le domaine de la sant\u00e9.</p>"},{"location":"projects/valmed-automatisation/#defi","title":"\ud83d\udd0d D\u00e9fi","text":"<ul> <li>Automatiser les t\u00e2ches r\u00e9p\u00e9titives</li> <li>Am\u00e9liorer la pr\u00e9cision des diagnostics</li> <li>R\u00e9duire les temps de traitement</li> <li>Assurer la conformit\u00e9 r\u00e9glementaire</li> </ul>"},{"location":"projects/valmed-automatisation/#stack-technique","title":"\u2699\ufe0f Stack technique","text":"<ul> <li> <p> Langages</p> <p>Python - D\u00e9veloppement principal</p> </li> <li> <p> IA/ML</p> <p>Machine Learning - Automatisation intelligente</p> </li> <li> <p> Donn\u00e9es</p> <p>APIs m\u00e9dicales - Int\u00e9gration syst\u00e8mes</p> </li> </ul>"},{"location":"projects/valmed-automatisation/#resultats-performance","title":"\ud83d\udcca R\u00e9sultats &amp; Performance","text":""},{"location":"projects/valmed-automatisation/#metriques-cibles","title":"\ud83c\udfaf M\u00e9triques cibles","text":"<ul> <li>Automatisation : 80% des t\u00e2ches r\u00e9p\u00e9titives</li> <li>Pr\u00e9cision : &gt;95% de fiabilit\u00e9</li> <li>Temps : R\u00e9duction de 50% des d\u00e9lais</li> <li>Erreurs : Diminution de 70% des erreurs humaines</li> </ul>"},{"location":"projects/valmed-automatisation/#impact-business","title":"\ud83d\udcc8 Impact business","text":"<ul> <li>Efficacit\u00e9 : Optimisation des processus</li> <li>Qualit\u00e9 : Am\u00e9lioration des soins</li> <li>Co\u00fbts : R\u00e9duction des d\u00e9penses op\u00e9rationnelles</li> <li>Satisfaction : Meilleure exp\u00e9rience patient</li> </ul>"},{"location":"projects/valmed-automatisation/#fonctionnalites-prevues","title":"\ud83d\ude80 Fonctionnalit\u00e9s pr\u00e9vues","text":""},{"location":"projects/valmed-automatisation/#automatisation-intelligente","title":"\ud83e\udd16 Automatisation intelligente","text":"<ul> <li>Traitement automatique des donn\u00e9es m\u00e9dicales</li> <li>Classification des cas par priorit\u00e9</li> <li>G\u00e9n\u00e9ration de rapports automatis\u00e9s</li> </ul>"},{"location":"projects/valmed-automatisation/#analytics-medicales","title":"\ud83d\udcca Analytics m\u00e9dicales","text":"<ul> <li>Tableaux de bord en temps r\u00e9el</li> <li>M\u00e9triques de performance</li> <li>Alertes et notifications</li> </ul>"},{"location":"projects/valmed-automatisation/#securite-conformite","title":"\ud83d\udd12 S\u00e9curit\u00e9 &amp; Conformit\u00e9","text":"<ul> <li>Chiffrement des donn\u00e9es sensibles</li> <li>Audit trails complets</li> <li>Conformit\u00e9 RGPD et HIPAA</li> </ul>"},{"location":"projects/valmed-automatisation/#liens-developpement","title":"\ud83d\udd17 Liens &amp; D\u00e9veloppement","text":"<ul> <li> <p> Repository</p> <p>Code source En d\u00e9veloppement actif</p> </li> <li> <p>:material-document:{ .lg .middle } Documentation</p> <p>Documentation technique \u00c0 cr\u00e9er</p> </li> <li> <p> Tests</p> <p>Environnement de test \u00c0 d\u00e9ployer</p> </li> </ul>"},{"location":"projects/valmed-automatisation/#apprentissages","title":"\ud83c\udf93 Apprentissages","text":""},{"location":"projects/valmed-automatisation/#defis-techniques","title":"\ud83d\udca1 D\u00e9fis techniques","text":"<ul> <li>Int\u00e9gration avec syst\u00e8mes m\u00e9dicaux existants</li> <li>Gestion des donn\u00e9es sensibles</li> <li>Conformit\u00e9 r\u00e9glementaire stricte</li> </ul>"},{"location":"projects/valmed-automatisation/#competences-developpees","title":"\ud83d\ude80 Comp\u00e9tences d\u00e9velopp\u00e9es","text":"<ul> <li>Automatisation de processus m\u00e9tier</li> <li>Int\u00e9gration de syst\u00e8mes complexes</li> <li>S\u00e9curit\u00e9 des donn\u00e9es m\u00e9dicales</li> <li>D\u00e9veloppement d'applications critiques</li> </ul> <p>Projet en cours de d\u00e9veloppement - 2024</p>"},{"location":"projects/exemples/analyse-sentiment/","title":"\ud83d\udcac Analyse de sentiment en temps r\u00e9el avec BERT","text":"","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#contexte-et-objectifs","title":"\ud83c\udfaf Contexte et Objectifs","text":"","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#probleme-a-resoudre","title":"Probl\u00e8me \u00e0 r\u00e9soudre","text":"<p>D\u00e9veloppement d'un syst\u00e8me d'analyse de sentiment en temps r\u00e9el pour monitorer l'opinion publique sur les r\u00e9seaux sociaux et les plateformes de e-commerce.</p>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#objectifs","title":"Objectifs","text":"<ul> <li>Objectif principal : Classifier le sentiment de textes en 3 cat\u00e9gories (Positif, N\u00e9gatif, Neutre)</li> <li>Objectifs secondaires : Traitement en temps r\u00e9el avec latence &lt; 100ms</li> <li>M\u00e9triques de succ\u00e8s : Accuracy &gt; 90%, Latence &lt; 100ms</li> </ul>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#contexte-metier","title":"Contexte m\u00e9tier","text":"<ul> <li>Secteur : E-commerce / Social Media</li> <li>Utilisateurs : \u00c9quipes marketing, Customer success</li> <li>Impact attendu : Am\u00e9lioration de 30% de la satisfaction client</li> </ul>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#donnees-et-sources","title":"\ud83d\udcca Donn\u00e9es et Sources","text":"","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#sources-de-donnees","title":"Sources de donn\u00e9es","text":"<ul> <li>Source principale : Twitter API + Amazon Reviews</li> <li>Format : JSON (texte + m\u00e9tadonn\u00e9es)</li> <li>Taille : 500,000 tweets + 100,000 avis</li> <li>P\u00e9riode : 2022-2024</li> <li>Fr\u00e9quence : Collecte en temps r\u00e9el</li> </ul>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#qualite-des-donnees","title":"Qualit\u00e9 des donn\u00e9es","text":"<ul> <li>Compl\u00e9tude : 92% de compl\u00e9tude</li> <li>Coh\u00e9rence : Validation par annotateurs experts</li> <li>Exactitude : Inter-annotateur agreement &gt; 85%</li> <li>Actualit\u00e9 : Donn\u00e9es r\u00e9centes et repr\u00e9sentatives</li> </ul>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#distribution-des-classes","title":"Distribution des classes","text":"Classe Nombre Pourcentage Description Positif 200,000 40% Sentiment positif N\u00e9gatif 150,000 30% Sentiment n\u00e9gatif Neutre 150,000 30% Sentiment neutre","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#methodologie","title":"\ud83d\udd2c M\u00e9thodologie","text":"","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#1-analyse-exploratoire-des-donnees-eda","title":"1. Analyse exploratoire des donn\u00e9es (EDA)","text":"<pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\n\n# Chargement des donn\u00e9es\ndf = pd.read_json('sentiment_data.json')\n\n# Visualisation de la distribution\nplt.figure(figsize=(12, 6))\ndf['sentiment'].value_counts().plot(kind='bar')\nplt.title('Distribution des sentiments')\nplt.xlabel('Sentiment')\nplt.ylabel('Nombre d\\'\u00e9chantillons')\nplt.show()\n\n# Nuage de mots par sentiment\nfor sentiment in df['sentiment'].unique():\n    text = ' '.join(df[df['sentiment'] == sentiment]['text'])\n    wordcloud = WordCloud(width=800, height=400).generate(text)\n    plt.figure(figsize=(10, 5))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.title(f'Nuage de mots - {sentiment}')\n    plt.axis('off')\n    plt.show()\n</code></pre>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#2-preprocessing","title":"2. Pr\u00e9processing","text":"<pre><code>import re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\n# T\u00e9l\u00e9chargement des ressources NLTK\nnltk.download('stopwords')\nnltk.download('punkt')\n\ndef preprocess_text(text):\n    # Nettoyage du texte\n    text = re.sub(r'@\\w+|#\\w+', '', text)  # Suppression des mentions\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # Suppression des URLs\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Suppression de la ponctuation\n    text = text.lower()  # Minuscules\n\n    # Tokenisation\n    tokens = word_tokenize(text)\n\n    # Suppression des stop words\n    stop_words = set(stopwords.words('french'))\n    tokens = [token for token in tokens if token not in stop_words]\n\n    return ' '.join(tokens)\n\n# Application du preprocessing\ndf['cleaned_text'] = df['text'].apply(preprocess_text)\n</code></pre>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#3-modelisation-avec-bert","title":"3. Mod\u00e9lisation avec BERT","text":"<pre><code>from transformers import BertTokenizer, BertForSequenceClassification\nfrom transformers import TrainingArguments, Trainer\nimport torch\nfrom torch.utils.data import Dataset\n\nclass SentimentDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = self.labels[idx]\n\n        encoding = self.tokenizer(\n            text,\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\n# Initialisation du mod\u00e8le BERT\nmodel_name = 'bert-base-multilingual-cased'\ntokenizer = BertTokenizer.from_pretrained(model_name)\nmodel = BertForSequenceClassification.from_pretrained(\n    model_name, \n    num_labels=3\n)\n\n# Pr\u00e9paration des donn\u00e9es\ntrain_dataset = SentimentDataset(\n    train_texts, train_labels, tokenizer\n)\nval_dataset = SentimentDataset(\n    val_texts, val_labels, tokenizer\n)\n</code></pre>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#4-entrainement","title":"4. Entra\u00eenement","text":"<pre><code>from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        labels, predictions, average='weighted'\n    )\n    accuracy = accuracy_score(labels, predictions)\n\n    return {\n        'accuracy': accuracy,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n    }\n\n# Configuration de l'entra\u00eenement\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n    logging_steps=100,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n)\n\n# Entra\u00eeneur\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n)\n\n# Entra\u00eenement\ntrainer.train()\n</code></pre>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#5-evaluation","title":"5. \u00c9valuation","text":"<pre><code># \u00c9valuation sur le jeu de test\ntest_results = trainer.evaluate(test_dataset)\nprint(f\"Accuracy: {test_results['eval_accuracy']:.3f}\")\nprint(f\"F1-Score: {test_results['eval_f1']:.3f}\")\n\n# Pr\u00e9dictions sur des exemples\ndef predict_sentiment(text, model, tokenizer):\n    inputs = tokenizer(\n        text, \n        return_tensors='pt', \n        truncation=True, \n        padding=True, \n        max_length=128\n    )\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n        predicted_class = torch.argmax(predictions, dim=-1).item()\n        confidence = predictions[0][predicted_class].item()\n\n    return predicted_class, confidence\n\n# Test sur des exemples\nexamples = [\n    \"J'adore ce produit, il est fantastique !\",\n    \"Service client d\u00e9cevant, je ne recommande pas.\",\n    \"Le produit est correct, rien de sp\u00e9cial.\"\n]\n\nfor example in examples:\n    pred_class, confidence = predict_sentiment(example, model, tokenizer)\n    sentiment = ['N\u00e9gatif', 'Neutre', 'Positif'][pred_class]\n    print(f\"Texte: {example}\")\n    print(f\"Sentiment: {sentiment} (Confiance: {confidence:.3f})\")\n    print()\n</code></pre>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#resultats-et-metriques","title":"\ud83d\udcc8 R\u00e9sultats et M\u00e9triques","text":"","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#performance-du-modele","title":"Performance du mod\u00e8le","text":"M\u00e9trique Valeur Baseline Am\u00e9lioration Accuracy 94.5% 78.2% +16.3% Precision 94.1% 76.8% +17.3% Recall 94.8% 77.5% +17.3% F1-Score 94.4% 77.1% +17.3%","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#performance-par-classe","title":"Performance par classe","text":"Classe Precision Recall F1-Score Support Positif 95.2% 93.8% 94.5% 1,000 N\u00e9gatif 94.1% 96.3% 95.2% 1,000 Neutre 93.8% 94.2% 94.0% 1,000","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#metriques-de-performance","title":"M\u00e9triques de performance","text":"<ul> <li>Latence moyenne : 45ms</li> <li>Throughput : 1000 requ\u00eates/minute</li> <li>Disponibilit\u00e9 : 99.9%</li> </ul>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#deploiement","title":"\ud83d\ude80 D\u00e9ploiement","text":"","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#architecture-de-deploiement","title":"Architecture de d\u00e9ploiement","text":"<ul> <li>Environnement : Docker + AWS ECS</li> <li>API : FastAPI avec documentation automatique</li> <li>Base de donn\u00e9es : Redis pour le cache</li> <li>Monitoring : CloudWatch + Custom metrics</li> <li>CI/CD : GitHub Actions</li> </ul>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#code-de-deploiement","title":"Code de d\u00e9ploiement","text":"<pre><code>from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification\nimport redis\nimport json\nimport time\n\napp = FastAPI(title=\"Sentiment Analysis API\")\n\n# Configuration Redis\nredis_client = redis.Redis(host='localhost', port=6379, db=0)\n\n# Chargement du mod\u00e8le\nmodel = BertForSequenceClassification.from_pretrained('./model')\ntokenizer = BertTokenizer.from_pretrained('./model')\nmodel.eval()\n\nclass TextInput(BaseModel):\n    text: str\n\nclass SentimentOutput(BaseModel):\n    sentiment: str\n    confidence: float\n    processing_time: float\n\n@app.post(\"/predict\", response_model=SentimentOutput)\nasync def predict_sentiment(input_data: TextInput):\n    start_time = time.time()\n\n    # V\u00e9rification du cache\n    cache_key = f\"sentiment:{hash(input_data.text)}\"\n    cached_result = redis_client.get(cache_key)\n\n    if cached_result:\n        result = json.loads(cached_result)\n        result['processing_time'] = time.time() - start_time\n        return SentimentOutput(**result)\n\n    # Pr\u00e9diction\n    inputs = tokenizer(\n        input_data.text, \n        return_tensors='pt', \n        truncation=True, \n        padding=True, \n        max_length=128\n    )\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n        predicted_class = torch.argmax(predictions, dim=-1).item()\n        confidence = predictions[0][predicted_class].item()\n\n    sentiment_labels = ['N\u00e9gatif', 'Neutre', 'Positif']\n    sentiment = sentiment_labels[predicted_class]\n\n    result = {\n        'sentiment': sentiment,\n        'confidence': float(confidence),\n        'processing_time': time.time() - start_time\n    }\n\n    # Mise en cache\n    redis_client.setex(cache_key, 3600, json.dumps(result))\n\n    return SentimentOutput(**result)\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\"status\": \"healthy\", \"timestamp\": time.time()}\n</code></pre>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#monitoring","title":"Monitoring","text":"<pre><code>import logging\nfrom prometheus_client import Counter, Histogram, generate_latest\n\n# M\u00e9triques Prometheus\nREQUEST_COUNT = Counter('sentiment_requests_total', 'Total requests')\nREQUEST_LATENCY = Histogram('sentiment_request_duration_seconds', 'Request latency')\nPREDICTION_ACCURACY = Histogram('sentiment_prediction_confidence', 'Prediction confidence')\n\n@app.middleware(\"http\")\nasync def add_process_time_header(request, call_next):\n    start_time = time.time()\n    response = await call_next(request)\n    process_time = time.time() - start_time\n\n    REQUEST_COUNT.inc()\n    REQUEST_LATENCY.observe(process_time)\n\n    response.headers[\"X-Process-Time\"] = str(process_time)\n    return response\n\n@app.get(\"/metrics\")\nasync def metrics():\n    return Response(generate_latest(), media_type=\"text/plain\")\n</code></pre>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#visualisations","title":"\ud83d\udcca Visualisations","text":"","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#matrice-de-confusion","title":"Matrice de confusion","text":"<pre><code>from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Matrice de confusion\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=['N\u00e9gatif', 'Neutre', 'Positif'],\n            yticklabels=['N\u00e9gatif', 'Neutre', 'Positif'])\nplt.title('Matrice de confusion')\nplt.xlabel('Pr\u00e9dictions')\nplt.ylabel('Vraies valeurs')\nplt.show()\n</code></pre>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#analyse-des-erreurs","title":"Analyse des erreurs","text":"<pre><code># Analyse des erreurs de classification\nerrors = df[df['true_sentiment'] != df['predicted_sentiment']]\n\n# Mots les plus fr\u00e9quents dans les erreurs\nerror_words = []\nfor text in errors['text']:\n    words = text.split()\n    error_words.extend(words)\n\nfrom collections import Counter\nword_freq = Counter(error_words)\nprint(\"Mots les plus fr\u00e9quents dans les erreurs:\")\nprint(word_freq.most_common(10))\n</code></pre>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#liens-et-ressources","title":"\ud83d\udd17 Liens et ressources","text":"","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#code-source","title":"Code source","text":"<ul> <li>Repository GitHub : github.com/loick-dernoncourt/sentiment-analysis</li> <li>Notebooks Jupyter : github.com/loick-dernoncourt/sentiment-analysis/tree/main/notebooks</li> </ul>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#demonstrations","title":"D\u00e9monstrations","text":"<ul> <li>D\u00e9mo interactive : sentiment-demo.example.com</li> <li>API Documentation : sentiment-api.example.com/docs</li> <li>Dashboard : sentiment-dashboard.example.com</li> </ul>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#documentation","title":"Documentation","text":"<ul> <li>Rapport technique : sentiment-report.example.com</li> <li>Pr\u00e9sentation : sentiment-slides.example.com</li> <li>Article de blog : blog.example.com/sentiment-analysis</li> </ul>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#prochaines-etapes","title":"\ud83c\udfaf Prochaines \u00e9tapes","text":"","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#ameliorations-prevues","title":"Am\u00e9liorations pr\u00e9vues","text":"<ul> <li> Support multilingue (anglais, espagnol)</li> <li> Analyse d'\u00e9motions (joie, col\u00e8re, tristesse)</li> <li> Int\u00e9gration avec les r\u00e9seaux sociaux</li> <li> Dashboard de monitoring en temps r\u00e9el</li> </ul>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/analyse-sentiment/#technologies-a-explorer","title":"Technologies \u00e0 explorer","text":"<ul> <li> RoBERTa pour de meilleures performances</li> <li> DistilBERT pour la latence</li> <li> ONNX pour l'optimisation</li> <li> Kafka pour le streaming</li> </ul> <p>Derni\u00e8re mise \u00e0 jour : October 22, 2025</p>","tags":["nlp","deep-learning","bert","transformers","sentiment-analysis","fastapi","real-time"]},{"location":"projects/exemples/classification-images/","title":"\ud83d\uddbc\ufe0f Classification d'images m\u00e9dicales avec CNN","text":"","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#contexte-et-objectifs","title":"\ud83c\udfaf Contexte et Objectifs","text":"","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#probleme-a-resoudre","title":"Probl\u00e8me \u00e0 r\u00e9soudre","text":"<p>D\u00e9veloppement d'un syst\u00e8me de classification automatique d'images m\u00e9dicales pour assister les radiologues dans le diagnostic de pathologies pulmonaires.</p>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#objectifs","title":"Objectifs","text":"<ul> <li>Objectif principal : Classifier les images de radiographies pulmonaires en 4 cat\u00e9gories</li> <li>Objectifs secondaires : R\u00e9duire le temps de diagnostic de 50%</li> <li>M\u00e9triques de succ\u00e8s : Accuracy &gt; 90%, Pr\u00e9cision &gt; 85%</li> </ul>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#contexte-metier","title":"Contexte m\u00e9tier","text":"<ul> <li>Secteur : Sant\u00e9 / Radiologie</li> <li>Utilisateurs : Radiologues, M\u00e9decins</li> <li>Impact attendu : Am\u00e9lioration de la pr\u00e9cision diagnostique</li> </ul>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#donnees-et-sources","title":"\ud83d\udcca Donn\u00e9es et Sources","text":"","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#sources-de-donnees","title":"Sources de donn\u00e9es","text":"<ul> <li>Source principale : NIH Chest X-ray Dataset</li> <li>Format : Images PNG (1024x1024)</li> <li>Taille : 10,000 images</li> <li>P\u00e9riode : 2017-2020</li> <li>Fr\u00e9quence : Collecte continue</li> </ul>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#qualite-des-donnees","title":"Qualit\u00e9 des donn\u00e9es","text":"<ul> <li>Compl\u00e9tude : 98% de compl\u00e9tude</li> <li>Coh\u00e9rence : Validation par radiologues experts</li> <li>Exactitude : Double validation des annotations</li> <li>Actualit\u00e9 : Donn\u00e9es r\u00e9centes et repr\u00e9sentatives</li> </ul>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#classes-de-classification","title":"Classes de classification","text":"Classe Nombre Description Exemples Normal 2,500 Radiographie normale Poumons sains Pneumonie 3,000 Infection pulmonaire Opacit\u00e9s alv\u00e9olaires COVID-19 2,000 Infection COVID-19 Opacit\u00e9s en verre d\u00e9poli Autres 2,500 Autres pathologies Tuberculose, Cancer","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#methodologie","title":"\ud83d\udd2c M\u00e9thodologie","text":"","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#1-analyse-exploratoire-des-donnees-eda","title":"1. Analyse exploratoire des donn\u00e9es (EDA)","text":"<pre><code>import torch\nimport torchvision\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Chargement des donn\u00e9es\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                        std=[0.229, 0.224, 0.225])\n])\n\ndataset = torchvision.datasets.ImageFolder('data/', transform=transform)\n\n# Visualisation des distributions\nclass_counts = [2500, 3000, 2000, 2500]\nclasses = ['Normal', 'Pneumonie', 'COVID-19', 'Autres']\n\nplt.figure(figsize=(10, 6))\nplt.bar(classes, class_counts)\nplt.title('Distribution des classes')\nplt.xlabel('Classes')\nplt.ylabel('Nombre d\\'images')\nplt.show()\n</code></pre>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#2-preprocessing","title":"2. Pr\u00e9processing","text":"<pre><code># Augmentation de donn\u00e9es\ntrain_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                        std=[0.229, 0.224, 0.225])\n])\n\n# Division train/validation/test\ntrain_size = int(0.7 * len(dataset))\nval_size = int(0.15 * len(dataset))\ntest_size = len(dataset) - train_size - val_size\n\ntrain_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n    dataset, [train_size, val_size, test_size]\n)\n</code></pre>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#3-architecture-du-modele","title":"3. Architecture du mod\u00e8le","text":"<pre><code>import torch.nn as nn\nimport torchvision.models as models\n\nclass MedicalCNN(nn.Module):\n    def __init__(self, num_classes=4):\n        super(MedicalCNN, self).__init__()\n\n        # Backbone ResNet50 pr\u00e9-entra\u00een\u00e9\n        self.backbone = models.resnet50(pretrained=True)\n\n        # Modification de la derni\u00e8re couche\n        num_features = self.backbone.fc.in_features\n        self.backbone.fc = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(num_features, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, num_classes)\n        )\n\n    def forward(self, x):\n        return self.backbone(x)\n\n# Initialisation du mod\u00e8le\nmodel = MedicalCNN(num_classes=4)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n</code></pre>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#4-entrainement","title":"4. Entra\u00eenement","text":"<pre><code>import torch.optim as optim\nfrom torch.utils.data import DataLoader\n\n# Configuration de l'entra\u00eenement\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n\n# Data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# Boucle d'entra\u00eenement\ndef train_epoch(model, train_loader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = output.max(1)\n        total += target.size(0)\n        correct += predicted.eq(target).sum().item()\n\n    return running_loss / len(train_loader), 100. * correct / total\n</code></pre>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#5-evaluation","title":"5. \u00c9valuation","text":"<pre><code>from sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\ndef evaluate_model(model, test_loader, device):\n    model.eval()\n    all_preds = []\n    all_targets = []\n\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            _, predicted = output.max(1)\n\n            all_preds.extend(predicted.cpu().numpy())\n            all_targets.extend(target.cpu().numpy())\n\n    return np.array(all_preds), np.array(all_targets)\n\n# \u00c9valuation finale\npredictions, targets = evaluate_model(model, test_loader, device)\nprint(classification_report(targets, predictions, target_names=classes))\n</code></pre>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#resultats-et-metriques","title":"\ud83d\udcc8 R\u00e9sultats et M\u00e9triques","text":"","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#performance-du-modele","title":"Performance du mod\u00e8le","text":"M\u00e9trique Valeur Baseline Am\u00e9lioration Accuracy 95.2% 78.5% +16.7% Precision 94.8% 76.2% +18.6% Recall 95.1% 77.8% +17.3% F1-Score 94.9% 77.0% +17.9%","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#performance-par-classe","title":"Performance par classe","text":"Classe Precision Recall F1-Score Support Normal 96.2% 94.8% 95.5% 375 Pneumonie 94.1% 96.3% 95.2% 450 COVID-19 95.8% 93.2% 94.5% 300 Autres 94.9% 96.1% 95.5% 375","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#analyse-des-erreurs","title":"Analyse des erreurs","text":"<ul> <li>Faux positifs : 2.1% des pr\u00e9dictions</li> <li>Faux n\u00e9gatifs : 1.8% des pr\u00e9dictions</li> <li>Classes les plus difficiles : COVID-19 vs Pneumonie (confusion fr\u00e9quente)</li> </ul>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#deploiement","title":"\ud83d\ude80 D\u00e9ploiement","text":"","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#architecture-de-deploiement","title":"Architecture de d\u00e9ploiement","text":"<ul> <li>Environnement : Docker + AWS ECS</li> <li>API : FastAPI avec documentation automatique</li> <li>Base de donn\u00e9es : PostgreSQL + Redis</li> <li>Monitoring : MLflow + CloudWatch</li> <li>CI/CD : GitHub Actions</li> </ul>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#code-de-deploiement","title":"Code de d\u00e9ploiement","text":"<pre><code>from fastapi import FastAPI, File, UploadFile\nimport torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport io\n\napp = FastAPI(title=\"Medical Image Classification API\")\n\n# Chargement du mod\u00e8le\nmodel = torch.load('medical_cnn.pth', map_location='cpu')\nmodel.eval()\n\n# Transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                        std=[0.229, 0.224, 0.225])\n])\n\n@app.post(\"/predict\")\nasync def predict(file: UploadFile = File(...)):\n    # Lecture de l'image\n    image = Image.open(io.BytesIO(await file.read()))\n\n    # Pr\u00e9processing\n    image_tensor = transform(image).unsqueeze(0)\n\n    # Pr\u00e9diction\n    with torch.no_grad():\n        outputs = model(image_tensor)\n        probabilities = torch.softmax(outputs, dim=1)\n        predicted_class = torch.argmax(probabilities, dim=1).item()\n        confidence = probabilities[0][predicted_class].item()\n\n    return {\n        \"predicted_class\": classes[predicted_class],\n        \"confidence\": float(confidence),\n        \"probabilities\": {\n            class_name: float(prob) \n            for class_name, prob in zip(classes, probabilities[0])\n        }\n    }\n</code></pre>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#visualisations","title":"\ud83d\udcca Visualisations","text":"","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#matrice-de-confusion","title":"Matrice de confusion","text":"<pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Matrice de confusion\ncm = confusion_matrix(targets, predictions)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=classes, yticklabels=classes)\nplt.title('Matrice de confusion')\nplt.xlabel('Pr\u00e9dictions')\nplt.ylabel('Vraies valeurs')\nplt.show()\n</code></pre>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#courbe-roc","title":"Courbe ROC","text":"<pre><code>from sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import label_binarize\n\n# Binarisation des labels pour ROC\ny_bin = label_binarize(targets, classes=[0, 1, 2, 3])\ny_scores = torch.softmax(torch.tensor(predictions), dim=1).numpy()\n\n# Calcul des courbes ROC pour chaque classe\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\n\nfor i in range(4):\n    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_scores[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Visualisation\nplt.figure(figsize=(12, 8))\nfor i in range(4):\n    plt.plot(fpr[i], tpr[i], label=f'{classes[i]} (AUC = {roc_auc[i]:.3f})')\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('Taux de faux positifs')\nplt.ylabel('Taux de vrais positifs')\nplt.title('Courbes ROC par classe')\nplt.legend()\nplt.show()\n</code></pre>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#liens-et-ressources","title":"\ud83d\udd17 Liens et ressources","text":"","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#code-source","title":"Code source","text":"<ul> <li>Repository GitHub : github.com/loick-dernoncourt/medical-cnn</li> <li>Notebooks Jupyter : github.com/loick-dernoncourt/medical-cnn/tree/main/notebooks</li> </ul>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#demonstrations","title":"D\u00e9monstrations","text":"<ul> <li>D\u00e9mo interactive : medical-demo.example.com</li> <li>API Documentation : medical-api.example.com/docs</li> <li>Dashboard : medical-dashboard.example.com</li> </ul>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#documentation","title":"Documentation","text":"<ul> <li>Rapport technique : medical-report.example.com</li> <li>Pr\u00e9sentation : medical-slides.example.com</li> <li>Article de blog : blog.example.com/medical-cnn</li> </ul>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#prochaines-etapes","title":"\ud83c\udfaf Prochaines \u00e9tapes","text":"","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#ameliorations-prevues","title":"Am\u00e9liorations pr\u00e9vues","text":"<ul> <li> Int\u00e9gration de donn\u00e9es 3D (CT scans)</li> <li> Am\u00e9lioration de l'explicabilit\u00e9 avec Grad-CAM</li> <li> Optimisation pour mobile (quantification)</li> <li> Int\u00e9gration avec PACS hospitalier</li> </ul>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/classification-images/#technologies-a-explorer","title":"Technologies \u00e0 explorer","text":"<ul> <li> Vision Transformers (ViT)</li> <li> Self-supervised learning</li> <li> Federated learning</li> <li> Edge deployment avec ONNX</li> </ul> <p>Derni\u00e8re mise \u00e0 jour : October 22, 2025</p>","tags":["computer-vision","deep-learning","pytorch","cnn","classification","medical-imaging"]},{"location":"projects/exemples/prediction-prix/","title":"\ud83c\udfe0 Pr\u00e9diction de prix immobiliers avec XGBoost","text":"","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#contexte-et-objectifs","title":"\ud83c\udfaf Contexte et Objectifs","text":"","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#probleme-a-resoudre","title":"Probl\u00e8me \u00e0 r\u00e9soudre","text":"<p>D\u00e9veloppement d'un mod\u00e8le de pr\u00e9diction de prix immobiliers pour aider les acheteurs et vendeurs \u00e0 estimer la valeur d'un bien immobilier.</p>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#objectifs","title":"Objectifs","text":"<ul> <li>Objectif principal : Pr\u00e9dire le prix d'un bien immobilier avec une erreur &lt; 20%</li> <li>Objectifs secondaires : Identifier les facteurs les plus influents sur le prix</li> <li>M\u00e9triques de succ\u00e8s : RMSE &lt; 0.2, R\u00b2 &gt; 0.85</li> </ul>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#contexte-metier","title":"Contexte m\u00e9tier","text":"<ul> <li>Secteur : Immobilier / Fintech</li> <li>Utilisateurs : Acheteurs, Vendeurs, Agents immobiliers</li> <li>Impact attendu : R\u00e9duction de 30% du temps d'estimation</li> </ul>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#donnees-et-sources","title":"\ud83d\udcca Donn\u00e9es et Sources","text":"","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#sources-de-donnees","title":"Sources de donn\u00e9es","text":"<ul> <li>Source principale : Donn\u00e9es publiques immobili\u00e8res</li> <li>Format : CSV (propri\u00e9t\u00e9s + prix)</li> <li>Taille : 50,000 propri\u00e9t\u00e9s</li> <li>P\u00e9riode : 2020-2024</li> <li>Fr\u00e9quence : Mise \u00e0 jour mensuelle</li> </ul>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#qualite-des-donnees","title":"Qualit\u00e9 des donn\u00e9es","text":"<ul> <li>Compl\u00e9tude : 88% de compl\u00e9tude</li> <li>Coh\u00e9rence : Validation des prix avec les transactions</li> <li>Exactitude : V\u00e9rification avec les notaires</li> <li>Actualit\u00e9 : Donn\u00e9es r\u00e9centes et repr\u00e9sentatives</li> </ul>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#variables-disponibles","title":"Variables disponibles","text":"Variable Type Description Importance surface Num\u00e9rique Surface en m\u00b2 Haute nb_pieces Num\u00e9rique Nombre de pi\u00e8ces Haute nb_chambres Num\u00e9rique Nombre de chambres Haute etage Num\u00e9rique \u00c9tage Moyenne ascenseur Binaire Pr\u00e9sence d'ascenseur Moyenne parking Binaire Place de parking Moyenne balcon Binaire Balcon/terrasse Faible quartier Cat\u00e9gorielle Quartier Haute type_bien Cat\u00e9gorielle Type de bien Haute","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#methodologie","title":"\ud83d\udd2c M\u00e9thodologie","text":"","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#1-analyse-exploratoire-des-donnees-eda","title":"1. Analyse exploratoire des donn\u00e9es (EDA)","text":"<pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Chargement des donn\u00e9es\ndf = pd.read_csv('real_estate_data.csv')\n\n# Statistiques descriptives\nprint(df.describe())\n\n# Visualisation de la distribution des prix\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.hist(df['prix'], bins=50, alpha=0.7)\nplt.title('Distribution des prix')\nplt.xlabel('Prix (\u20ac)')\nplt.ylabel('Fr\u00e9quence')\n\nplt.subplot(1, 2, 2)\nplt.hist(np.log(df['prix']), bins=50, alpha=0.7)\nplt.title('Distribution des prix (log)')\nplt.xlabel('Log(Prix)')\nplt.ylabel('Fr\u00e9quence')\nplt.show()\n\n# Corr\u00e9lation avec la surface\nplt.figure(figsize=(10, 6))\nplt.scatter(df['surface'], df['prix'], alpha=0.5)\nplt.title('Prix vs Surface')\nplt.xlabel('Surface (m\u00b2)')\nplt.ylabel('Prix (\u20ac)')\nplt.show()\n</code></pre>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#2-preprocessing","title":"2. Pr\u00e9processing","text":"<pre><code>from sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Nettoyage des donn\u00e9es\ndf = df.dropna()\ndf = df[df['prix'] &gt; 0]  # Suppression des prix n\u00e9gatifs\ndf = df[df['surface'] &gt; 0]  # Suppression des surfaces n\u00e9gatives\n\n# Transformation logarithmique du prix\ndf['log_prix'] = np.log(df['prix'])\n\n# Encodage des variables cat\u00e9gorielles\nle_quartier = LabelEncoder()\nle_type = LabelEncoder()\n\ndf['quartier_encoded'] = le_quartier.fit_transform(df['quartier'])\ndf['type_encoded'] = le_type.fit_transform(df['type_bien'])\n\n# S\u00e9lection des features\nfeatures = ['surface', 'nb_pieces', 'nb_chambres', 'etage', \n           'ascenseur', 'parking', 'balcon', 'quartier_encoded', 'type_encoded']\nX = df[features]\ny = df['log_prix']\n\n# Division train/validation/test\nX_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\nX_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n</code></pre>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#3-feature-engineering","title":"3. Feature Engineering","text":"<pre><code># Cr\u00e9ation de nouvelles features\ndef create_features(df):\n    # Prix au m\u00b2\n    df['prix_m2'] = df['prix'] / df['surface']\n\n    # Ratio chambres/pi\u00e8ces\n    df['ratio_chambres_pieces'] = df['nb_chambres'] / df['nb_pieces']\n\n    # Surface par pi\u00e8ce\n    df['surface_par_piece'] = df['surface'] / df['nb_pieces']\n\n    # Indicateur de luxe (surface &gt; 100m\u00b2 et \u00e9tage &gt; 5)\n    df['luxe'] = ((df['surface'] &gt; 100) &amp; (df['etage'] &gt; 5)).astype(int)\n\n    # Indicateur de r\u00e9novation (bien r\u00e9cent)\n    df['renove'] = (df['annee_construction'] &gt; 2010).astype(int)\n\n    return df\n\n# Application du feature engineering\ndf = create_features(df)\n\n# S\u00e9lection des features finales\nfinal_features = ['surface', 'nb_pieces', 'nb_chambres', 'etage', \n                 'ascenseur', 'parking', 'balcon', 'quartier_encoded', \n                 'type_encoded', 'prix_m2', 'ratio_chambres_pieces', \n                 'surface_par_piece', 'luxe', 'renove']\n</code></pre>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#4-modelisation-avec-xgboost","title":"4. Mod\u00e9lisation avec XGBoost","text":"<pre><code>import xgboost as xgb\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport mlflow\nimport mlflow.xgboost\n\n# Configuration MLflow\nmlflow.set_experiment(\"real_estate_prediction\")\n\nwith mlflow.start_run():\n    # Configuration du mod\u00e8le\n    params = {\n        'n_estimators': 1000,\n        'max_depth': 6,\n        'learning_rate': 0.1,\n        'subsample': 0.8,\n        'colsample_bytree': 0.8,\n        'random_state': 42\n    }\n\n    # Entra\u00eenement du mod\u00e8le\n    model = xgb.XGBRegressor(**params)\n    model.fit(X_train, y_train)\n\n    # Pr\u00e9dictions\n    y_pred_train = model.predict(X_train)\n    y_pred_val = model.predict(X_val)\n    y_pred_test = model.predict(X_test)\n\n    # Calcul des m\u00e9triques\n    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n    rmse_val = np.sqrt(mean_squared_error(y_val, y_pred_val))\n    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n\n    r2_train = r2_score(y_train, y_pred_train)\n    r2_val = r2_score(y_val, y_pred_val)\n    r2_test = r2_score(y_test, y_pred_test)\n\n    # Logging des m\u00e9triques\n    mlflow.log_params(params)\n    mlflow.log_metric(\"rmse_train\", rmse_train)\n    mlflow.log_metric(\"rmse_val\", rmse_val)\n    mlflow.log_metric(\"rmse_test\", rmse_test)\n    mlflow.log_metric(\"r2_train\", r2_train)\n    mlflow.log_metric(\"r2_val\", r2_val)\n    mlflow.log_metric(\"r2_test\", r2_test)\n\n    # Sauvegarde du mod\u00e8le\n    mlflow.xgboost.log_model(model, \"model\")\n\n    print(f\"RMSE Train: {rmse_train:.3f}\")\n    print(f\"RMSE Validation: {rmse_val:.3f}\")\n    print(f\"RMSE Test: {rmse_test:.3f}\")\n    print(f\"R\u00b2 Train: {r2_train:.3f}\")\n    print(f\"R\u00b2 Validation: {r2_val:.3f}\")\n    print(f\"R\u00b2 Test: {r2_test:.3f}\")\n</code></pre>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#5-optimisation-des-hyperparametres","title":"5. Optimisation des hyperparam\u00e8tres","text":"<pre><code>from sklearn.model_selection import GridSearchCV\n\n# Grille de param\u00e8tres\nparam_grid = {\n    'n_estimators': [500, 1000, 1500],\n    'max_depth': [4, 6, 8],\n    'learning_rate': [0.05, 0.1, 0.15],\n    'subsample': [0.8, 0.9, 1.0],\n    'colsample_bytree': [0.8, 0.9, 1.0]\n}\n\n# Recherche par grille\ngrid_search = GridSearchCV(\n    xgb.XGBRegressor(random_state=42),\n    param_grid,\n    cv=5,\n    scoring='neg_mean_squared_error',\n    n_jobs=-1\n)\n\ngrid_search.fit(X_train, y_train)\n\n# Meilleurs param\u00e8tres\nprint(\"Meilleurs param\u00e8tres:\", grid_search.best_params_)\nprint(\"Meilleur score:\", grid_search.best_score_)\n\n# Mod\u00e8le optimis\u00e9\nbest_model = grid_search.best_estimator_\n</code></pre>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#6-evaluation-et-interpretation","title":"6. \u00c9valuation et interpr\u00e9tation","text":"<pre><code># Importance des features\nfeature_importance = model.feature_importances_\nfeature_names = X.columns\n\n# Tri par importance\nimportance_df = pd.DataFrame({\n    'feature': feature_names,\n    'importance': feature_importance\n}).sort_values('importance', ascending=False)\n\n# Visualisation de l'importance\nplt.figure(figsize=(10, 8))\nsns.barplot(data=importance_df.head(10), x='importance', y='feature')\nplt.title('Importance des features')\nplt.xlabel('Importance')\nplt.show()\n\n# Pr\u00e9dictions sur des exemples\ndef predict_price(model, surface, nb_pieces, nb_chambres, etage, \n                 ascenseur, parking, balcon, quartier, type_bien):\n    # Cr\u00e9ation d'un DataFrame avec les features\n    data = pd.DataFrame({\n        'surface': [surface],\n        'nb_pieces': [nb_pieces],\n        'nb_chambres': [nb_chambres],\n        'etage': [etage],\n        'ascenseur': [ascenseur],\n        'parking': [parking],\n        'balcon': [balcon],\n        'quartier_encoded': [quartier],\n        'type_encoded': [type_bien]\n    })\n\n    # Pr\u00e9diction\n    log_price = model.predict(data)[0]\n    price = np.exp(log_price)\n\n    return price\n\n# Exemple de pr\u00e9diction\npredicted_price = predict_price(\n    model, surface=80, nb_pieces=3, nb_chambres=2, etage=3,\n    ascenseur=1, parking=1, balcon=0, quartier=5, type_bien=1\n)\nprint(f\"Prix pr\u00e9dit: {predicted_price:,.0f} \u20ac\")\n</code></pre>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#resultats-et-metriques","title":"\ud83d\udcc8 R\u00e9sultats et M\u00e9triques","text":"","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#performance-du-modele","title":"Performance du mod\u00e8le","text":"M\u00e9trique Valeur Baseline Am\u00e9lioration RMSE 0.15 0.25 +40% R\u00b2 0.87 0.65 +22% MAE 0.12 0.20 +40% MAPE 15.2% 28.5% +13.3%","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#performance-par-type-de-bien","title":"Performance par type de bien","text":"Type de bien RMSE R\u00b2 Nombre d'\u00e9chantillons Appartement 0.14 0.89 30,000 Maison 0.16 0.85 15,000 Studio 0.13 0.91 5,000","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#importance-des-features","title":"Importance des features","text":"Feature Importance Description surface 0.35 Surface en m\u00b2 quartier 0.25 Quartier nb_pieces 0.15 Nombre de pi\u00e8ces type_bien 0.10 Type de bien etage 0.08 \u00c9tage parking 0.04 Place de parking ascenseur 0.03 Ascenseur","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#deploiement","title":"\ud83d\ude80 D\u00e9ploiement","text":"","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#architecture-de-deploiement","title":"Architecture de d\u00e9ploiement","text":"<ul> <li>Environnement : Docker + AWS ECS</li> <li>API : FastAPI avec documentation automatique</li> <li>Base de donn\u00e9es : PostgreSQL</li> <li>Monitoring : MLflow + CloudWatch</li> <li>CI/CD : GitHub Actions</li> </ul>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#code-de-deploiement","title":"Code de d\u00e9ploiement","text":"<pre><code>from fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nimport joblib\nimport numpy as np\nimport pandas as pd\n\napp = FastAPI(title=\"Real Estate Price Prediction API\")\n\n# Chargement du mod\u00e8le\nmodel = joblib.load('xgboost_model.pkl')\nscaler = joblib.load('scaler.pkl')\n\nclass PropertyInput(BaseModel):\n    surface: float\n    nb_pieces: int\n    nb_chambres: int\n    etage: int\n    ascenseur: bool\n    parking: bool\n    balcon: bool\n    quartier: str\n    type_bien: str\n\nclass PriceOutput(BaseModel):\n    predicted_price: float\n    confidence_interval: dict\n    feature_importance: dict\n\n@app.post(\"/predict\", response_model=PriceOutput)\nasync def predict_price(property_data: PropertyInput):\n    try:\n        # Pr\u00e9processing des donn\u00e9es\n        data = pd.DataFrame([property_data.dict()])\n\n        # Encodage des variables cat\u00e9gorielles\n        data['quartier_encoded'] = le_quartier.transform(data['quartier'])\n        data['type_encoded'] = le_type.transform(data['type_bien'])\n\n        # S\u00e9lection des features\n        features = ['surface', 'nb_pieces', 'nb_chambres', 'etage', \n                   'ascenseur', 'parking', 'balcon', 'quartier_encoded', 'type_encoded']\n        X = data[features]\n\n        # Pr\u00e9diction\n        log_price = model.predict(X)[0]\n        predicted_price = np.exp(log_price)\n\n        # Intervalle de confiance (approximatif)\n        confidence_interval = {\n            'lower': predicted_price * 0.85,\n            'upper': predicted_price * 1.15\n        }\n\n        # Importance des features pour cette pr\u00e9diction\n        feature_importance = dict(zip(features, model.feature_importances_))\n\n        return PriceOutput(\n            predicted_price=float(predicted_price),\n            confidence_interval=confidence_interval,\n            feature_importance=feature_importance\n        )\n\n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\"status\": \"healthy\", \"model_loaded\": True}\n</code></pre>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#visualisations","title":"\ud83d\udcca Visualisations","text":"","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#distribution-des-erreurs","title":"Distribution des erreurs","text":"<pre><code># Calcul des erreurs\nerrors = y_test - y_pred_test\nerrors_percent = (errors / y_test) * 100\n\n# Visualisation des erreurs\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.hist(errors, bins=50, alpha=0.7)\nplt.title('Distribution des erreurs')\nplt.xlabel('Erreur (log prix)')\nplt.ylabel('Fr\u00e9quence')\n\nplt.subplot(1, 2, 2)\nplt.hist(errors_percent, bins=50, alpha=0.7)\nplt.title('Distribution des erreurs (%)')\nplt.xlabel('Erreur (%)')\nplt.ylabel('Fr\u00e9quence')\nplt.show()\n</code></pre>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#predictions-vs-vraies-valeurs","title":"Pr\u00e9dictions vs Vraies valeurs","text":"<pre><code># Scatter plot des pr\u00e9dictions\nplt.figure(figsize=(10, 8))\nplt.scatter(y_test, y_pred_test, alpha=0.5)\nplt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\nplt.xlabel('Vraies valeurs (log prix)')\nplt.ylabel('Pr\u00e9dictions (log prix)')\nplt.title('Pr\u00e9dictions vs Vraies valeurs')\nplt.show()\n</code></pre>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#liens-et-ressources","title":"\ud83d\udd17 Liens et ressources","text":"","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#code-source","title":"Code source","text":"<ul> <li>Repository GitHub : github.com/loick-dernoncourt/real-estate-prediction</li> <li>Notebooks Jupyter : github.com/loick-dernoncourt/real-estate-prediction/tree/main/notebooks</li> </ul>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#demonstrations","title":"D\u00e9monstrations","text":"<ul> <li>D\u00e9mo interactive : real-estate-demo.example.com</li> <li>API Documentation : real-estate-api.example.com/docs</li> <li>Dashboard : real-estate-dashboard.example.com</li> </ul>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#documentation","title":"Documentation","text":"<ul> <li>Rapport technique : real-estate-report.example.com</li> <li>Pr\u00e9sentation : real-estate-slides.example.com</li> <li>Article de blog : blog.example.com/real-estate-prediction</li> </ul>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#prochaines-etapes","title":"\ud83c\udfaf Prochaines \u00e9tapes","text":"","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#ameliorations-prevues","title":"Am\u00e9liorations pr\u00e9vues","text":"<ul> <li> Int\u00e9gration de donn\u00e9es g\u00e9ographiques (GIS)</li> <li> Mod\u00e8le de pr\u00e9diction des tendances</li> <li> Analyse de la valeur ajout\u00e9e des r\u00e9novations</li> <li> Pr\u00e9diction des prix de location</li> </ul>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"projects/exemples/prediction-prix/#technologies-a-explorer","title":"Technologies \u00e0 explorer","text":"<ul> <li> LightGBM pour de meilleures performances</li> <li> SHAP pour l'explicabilit\u00e9</li> <li> Time series pour les tendances</li> <li> Deep learning pour les patterns complexes</li> </ul> <p>Derni\u00e8re mise \u00e0 jour : October 22, 2025</p>","tags":["machine-learning","regression","xgboost","feature-engineering","real-estate","mlflow"]},{"location":"skills/","title":"\ud83d\udee0\ufe0f Comp\u00e9tences Techniques","text":"<p>D\u00e9couvrez mes comp\u00e9tences en data science, machine learning et technologies associ\u00e9es.</p>"},{"location":"skills/#apercu-des-competences","title":"\ud83c\udfaf Aper\u00e7u des comp\u00e9tences","text":"<ul> <li> <p> Machine Learning</p> <p>Classification, R\u00e9gression, Clustering, Feature Engineering</p> </li> <li> <p> Deep Learning</p> <p>CNN, RNN, Transformers, PyTorch, TensorFlow</p> </li> <li> <p> Data Engineering</p> <p>ETL, Big Data, AWS, Docker, CI/CD</p> </li> <li> <p> Visualisation</p> <p>Matplotlib, Seaborn, Plotly, Tableau, Power BI</p> </li> </ul>"},{"location":"skills/#niveau-de-competences","title":"\ud83d\udcca Niveau de comp\u00e9tences","text":""},{"location":"skills/#langages-de-programmation","title":"Langages de programmation","text":"Langage Niveau Exp\u00e9rience Projets Python Expert 5+ ans 20+ projets R Interm\u00e9diaire 3 ans 5 projets SQL Expert 5+ ans 15+ projets JavaScript Interm\u00e9diaire 2 ans 3 projets"},{"location":"skills/#frameworks-et-bibliotheques","title":"Frameworks et biblioth\u00e8ques","text":"Framework Niveau Utilisation Derni\u00e8re version Scikit-learn Expert 4 ans 1.3.0 PyTorch Expert 3 ans 2.0.0 XGBoost Expert 3 ans 1.7.0 Pandas Expert 5 ans 2.0.0 NumPy Expert 5 ans 1.24.0 Matplotlib Expert 4 ans 3.7.0 Seaborn Expert 4 ans 0.12.0 Plotly Interm\u00e9diaire 2 ans 5.15.0"},{"location":"skills/#outils-et-plateformes","title":"Outils et plateformes","text":"Outil Niveau Exp\u00e9rience Certification AWS Expert 3 ans \u2705 Certified Docker Expert 3 ans - Kubernetes Interm\u00e9diaire 2 ans - Git Expert 5 ans - MLflow Expert 2 ans - Tableau Interm\u00e9diaire 2 ans - Power BI Interm\u00e9diaire 1 an -"},{"location":"skills/#certifications","title":"\ud83c\udf93 Certifications","text":""},{"location":"skills/#cloud-et-ml","title":"Cloud et ML","text":"<ul> <li>AWS Certified Machine Learning - Specialty (2023)</li> <li>Google Cloud Professional Machine Learning Engineer (2023)</li> <li>Microsoft Azure Data Scientist Associate (2022)</li> </ul>"},{"location":"skills/#data-science","title":"Data Science","text":"<ul> <li>IBM Data Science Professional Certificate (2021)</li> <li>Coursera Deep Learning Specialization (2020)</li> </ul>"},{"location":"skills/#projets-par-competence","title":"\ud83c\udfc6 Projets par comp\u00e9tence","text":""},{"location":"skills/#machine-learning-20-projets","title":"Machine Learning (20+ projets)","text":"<ul> <li>Classification : 8 projets (images, texte, tabulaire)</li> <li>R\u00e9gression : 6 projets (prix, pr\u00e9dictions)</li> <li>Clustering : 4 projets (segmentation, recommandation)</li> <li>Feature Engineering : 15+ projets</li> </ul>"},{"location":"skills/#deep-learning-10-projets","title":"Deep Learning (10+ projets)","text":"<ul> <li>Computer Vision : 5 projets (CNN, YOLO)</li> <li>NLP : 4 projets (BERT, Transformers)</li> <li>Time Series : 2 projets (LSTM, GRU)</li> <li>Reinforcement Learning : 1 projet</li> </ul>"},{"location":"skills/#data-engineering-8-projets","title":"Data Engineering (8+ projets)","text":"<ul> <li>ETL Pipelines : 5 projets</li> <li>Big Data : 3 projets (Spark, Hadoop)</li> <li>APIs : 6 projets (FastAPI, Flask)</li> <li>D\u00e9ploiement : 10+ projets (Docker, AWS)</li> </ul>"},{"location":"skills/#evolution-des-competences","title":"\ud83d\udcc8 \u00c9volution des comp\u00e9tences","text":""},{"location":"skills/#2024","title":"2024","text":"<ul> <li>Nouveau : LangChain, Ray, Weights &amp; Biases</li> <li>Am\u00e9lioration : MLOps, Kubernetes, ONNX</li> <li>Projets : 5 nouveaux projets</li> </ul>"},{"location":"skills/#2023","title":"2023","text":"<ul> <li>Nouveau : Transformers, BERT, GPT</li> <li>Am\u00e9lioration : PyTorch, Computer Vision</li> <li>Projets : 8 nouveaux projets</li> </ul>"},{"location":"skills/#2022","title":"2022","text":"<ul> <li>Nouveau : Deep Learning, AWS</li> <li>Am\u00e9lioration : Machine Learning, Python</li> <li>Projets : 6 nouveaux projets</li> </ul>"},{"location":"skills/#objectifs-dapprentissage","title":"\ud83c\udfaf Objectifs d'apprentissage","text":""},{"location":"skills/#court-terme-6-mois","title":"Court terme (6 mois)","text":"<ul> <li> Ma\u00eetrise de LangChain pour les applications LLM</li> <li> Expertise en Ray pour le ML distribu\u00e9</li> <li> Certification Kubernetes</li> <li> Projet de computer vision avanc\u00e9</li> </ul>"},{"location":"skills/#moyen-terme-1-an","title":"Moyen terme (1 an)","text":"<ul> <li> Expertise en MLOps avec Kubeflow</li> <li> Ma\u00eetrise de l'optimisation de mod\u00e8les (ONNX, TensorRT)</li> <li> Projet de recherche en deep learning</li> <li> Contribution \u00e0 des projets open source</li> </ul>"},{"location":"skills/#long-terme-2-ans","title":"Long terme (2 ans)","text":"<ul> <li> Expertise en recherche en IA</li> <li> Leadership technique</li> <li> Cr\u00e9ation d'un framework ML</li> <li> Publication d'articles scientifiques</li> </ul>"},{"location":"skills/#stack-technique-prefere","title":"\ud83d\udee0\ufe0f Stack technique pr\u00e9f\u00e9r\u00e9","text":""},{"location":"skills/#developpement","title":"D\u00e9veloppement","text":"<ul> <li>IDE : VS Code, Jupyter Lab</li> <li>Versioning : Git, GitHub</li> <li>Environnement : Conda, Docker</li> <li>Testing : pytest, unittest</li> </ul>"},{"location":"skills/#mlai","title":"ML/AI","text":"<ul> <li>Frameworks : PyTorch, Scikit-learn</li> <li>Optimisation : Optuna, Hyperopt</li> <li>Monitoring : MLflow, Weights &amp; Biases</li> <li>D\u00e9ploiement : FastAPI, Docker</li> </ul>"},{"location":"skills/#data","title":"Data","text":"<ul> <li>Processing : Pandas, NumPy, Spark</li> <li>Visualisation : Matplotlib, Seaborn, Plotly</li> <li>Databases : PostgreSQL, Redis, MongoDB</li> <li>Cloud : AWS (S3, EC2, ECS, Lambda)</li> </ul>"},{"location":"skills/#ressources-dapprentissage","title":"\ud83d\udcda Ressources d'apprentissage","text":""},{"location":"skills/#cours-et-formations","title":"Cours et formations","text":"<ul> <li>Coursera : Deep Learning Specialization (Andrew Ng)</li> <li>Udacity : Machine Learning Engineer Nanodegree</li> <li>Fast.ai : Practical Deep Learning for Coders</li> <li>Coursera : Machine Learning (Stanford)</li> </ul>"},{"location":"skills/#livres-recommandes","title":"Livres recommand\u00e9s","text":"<ul> <li>Hands-On Machine Learning (Aur\u00e9lien G\u00e9ron)</li> <li>Deep Learning (Ian Goodfellow)</li> <li>Pattern Recognition and Machine Learning (Christopher Bishop)</li> <li>The Elements of Statistical Learning (Hastie, Tibshirani, Friedman)</li> </ul>"},{"location":"skills/#blogs-et-ressources","title":"Blogs et ressources","text":"<ul> <li>Towards Data Science (Medium)</li> <li>Distill.pub (Visualisations ML)</li> <li>Papers with Code (Recherche)</li> <li>Kaggle Learn (Tutoriels pratiques)</li> </ul>"},{"location":"skills/#collaboration-et-contribution","title":"\ud83e\udd1d Collaboration et contribution","text":""},{"location":"skills/#open-source","title":"Open Source","text":"<ul> <li>Contributions : 15+ repositories</li> <li>Stars : 500+ sur mes projets</li> <li>Forks : 100+ sur mes projets</li> <li>Issues : 50+ r\u00e9solues</li> </ul>"},{"location":"skills/#communaute","title":"Communaut\u00e9","text":"<ul> <li>Meetups : 20+ participations</li> <li>Conf\u00e9rences : 5+ pr\u00e9sentations</li> <li>Mentoring : 10+ \u00e9tudiants</li> <li>Blog : 25+ articles techniques</li> </ul>"},{"location":"skills/#contact","title":"\ud83d\udcde Contact","text":"<p>Int\u00e9ress\u00e9 par une collaboration ? N'h\u00e9sitez pas \u00e0 me contacter !</p> <ul> <li> <p> Email</p> <p>Dernoncourt.ck@gmail.com</p> </li> <li> <p> LinkedIn</p> <p>Profil professionnel</p> </li> <li> <p> GitHub</p> <p>Code &amp; Projets</p> </li> </ul> <p>Derni\u00e8re mise \u00e0 jour : October 23, 2025</p>"},{"location":"skills/data-engineering/","title":"\ud83d\uddc4\ufe0f Data Engineering","text":"<p>Expertise en data engineering avec 3+ ann\u00e9es d'exp\u00e9rience et 8+ projets r\u00e9alis\u00e9s.</p>"},{"location":"skills/data-engineering/#competences-principales","title":"\ud83c\udfaf Comp\u00e9tences principales","text":""},{"location":"skills/data-engineering/#technologies-de-donnees","title":"Technologies de donn\u00e9es","text":"<ul> <li>Big Data : Apache Spark, Hadoop, Hive</li> <li>Databases : PostgreSQL, MongoDB, Redis, Elasticsearch</li> <li>Cloud : AWS (S3, EC2, ECS, Lambda), Google Cloud, Azure</li> <li>Streaming : Kafka, Apache Flink, Apache Storm</li> <li>Orchestration : Airflow, Prefect, Dagster</li> </ul>"},{"location":"skills/data-engineering/#outils-de-developpement","title":"Outils de d\u00e9veloppement","text":"<ul> <li>Conteneurisation : Docker, Kubernetes</li> <li>CI/CD : GitHub Actions, GitLab CI, Jenkins</li> <li>Monitoring : Prometheus, Grafana, ELK Stack</li> <li>Versioning : Git, DVC (Data Version Control)</li> </ul>"},{"location":"skills/data-engineering/#langages-et-frameworks","title":"Langages et frameworks","text":"<ul> <li>Python : Pandas, NumPy, PySpark, FastAPI</li> <li>SQL : PostgreSQL, MySQL, BigQuery</li> <li>Scala : Apache Spark</li> <li>Bash : Scripting et automation</li> </ul>"},{"location":"skills/data-engineering/#stack-technique","title":"\ud83d\udee0\ufe0f Stack technique","text":""},{"location":"skills/data-engineering/#frameworks-principaux","title":"Frameworks principaux","text":"<pre><code># Apache Spark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *\n\n# FastAPI\nfrom fastapi import FastAPI, HTTPException\nfrom pydantic import BaseModel\nimport uvicorn\n\n# Airflow\nfrom airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.bash import BashOperator\n</code></pre>"},{"location":"skills/data-engineering/#outils-de-developpement_1","title":"Outils de d\u00e9veloppement","text":"<ul> <li>Docker : Conteneurisation des applications</li> <li>Kubernetes : Orchestration des conteneurs</li> <li>Terraform : Infrastructure as Code</li> <li>Ansible : Configuration management</li> </ul>"},{"location":"skills/data-engineering/#projets-realises","title":"\ud83d\udcca Projets r\u00e9alis\u00e9s","text":""},{"location":"skills/data-engineering/#pipeline-etl-pour-e-commerce","title":"Pipeline ETL pour e-commerce","text":"<p>Technologies : Apache Spark, PostgreSQL, Airflow R\u00e9sultat : Traitement de 10M+ enregistrements/jour Impact : R\u00e9duction de 60% du temps de traitement</p>"},{"location":"skills/data-engineering/#api-de-donnees-en-temps-reel","title":"API de donn\u00e9es en temps r\u00e9el","text":"<p>Technologies : FastAPI, Redis, Kafka R\u00e9sultat : 1000 requ\u00eates/seconde, 99.9% de disponibilit\u00e9 Impact : Am\u00e9lioration de 40% des performances</p>"},{"location":"skills/data-engineering/#data-lake-sur-aws","title":"Data Lake sur AWS","text":"<p>Technologies : S3, Glue, Athena, Redshift R\u00e9sultat : 100TB+ de donn\u00e9es stock\u00e9es Impact : R\u00e9duction de 50% des co\u00fbts de stockage</p>"},{"location":"skills/data-engineering/#methodologie","title":"\ud83d\udd2c M\u00e9thodologie","text":""},{"location":"skills/data-engineering/#1-architecture-de-donnees","title":"1. Architecture de donn\u00e9es","text":"<pre><code># Configuration Spark\nspark = SparkSession.builder \\\n    .appName(\"DataPipeline\") \\\n    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n    .getOrCreate()\n\n# Lecture des donn\u00e9es\ndf = spark.read \\\n    .format(\"parquet\") \\\n    .option(\"path\", \"s3://bucket/data/\") \\\n    .load()\n\n# Transformation des donn\u00e9es\ndf_transformed = df \\\n    .withColumn(\"date\", to_date(col(\"timestamp\"))) \\\n    .withColumn(\"hour\", hour(col(\"timestamp\"))) \\\n    .filter(col(\"amount\") &gt; 0) \\\n    .groupBy(\"date\", \"hour\") \\\n    .agg(sum(\"amount\").alias(\"total_amount\"))\n</code></pre>"},{"location":"skills/data-engineering/#2-pipeline-etl","title":"2. Pipeline ETL","text":"<pre><code>from airflow import DAG\nfrom airflow.operators.python import PythonOperator\nfrom airflow.operators.bash import BashOperator\nfrom datetime import datetime, timedelta\n\ndef extract_data():\n    \"\"\"Extraction des donn\u00e9es depuis la source\"\"\"\n    import pandas as pd\n    import requests\n\n    # Extraction depuis API\n    response = requests.get(\"https://api.example.com/data\")\n    data = response.json()\n\n    # Sauvegarde en local\n    df = pd.DataFrame(data)\n    df.to_parquet(\"/tmp/raw_data.parquet\")\n\n    return \"Data extracted successfully\"\n\ndef transform_data():\n    \"\"\"Transformation des donn\u00e9es\"\"\"\n    import pandas as pd\n    import numpy as np\n\n    # Lecture des donn\u00e9es\n    df = pd.read_parquet(\"/tmp/raw_data.parquet\")\n\n    # Nettoyage et transformation\n    df = df.dropna()\n    df['amount'] = df['amount'].astype(float)\n    df['date'] = pd.to_datetime(df['date'])\n\n    # Calculs m\u00e9tier\n    df['amount_category'] = np.where(\n        df['amount'] &gt; 1000, 'high', \n        np.where(df['amount'] &gt; 100, 'medium', 'low')\n    )\n\n    # Sauvegarde\n    df.to_parquet(\"/tmp/transformed_data.parquet\")\n\n    return \"Data transformed successfully\"\n\ndef load_data():\n    \"\"\"Chargement des donn\u00e9es vers la destination\"\"\"\n    import pandas as pd\n    import psycopg2\n\n    # Lecture des donn\u00e9es transform\u00e9es\n    df = pd.read_parquet(\"/tmp/transformed_data.parquet\")\n\n    # Connexion \u00e0 la base de donn\u00e9es\n    conn = psycopg2.connect(\n        host=\"localhost\",\n        database=\"analytics\",\n        user=\"user\",\n        password=\"password\"\n    )\n\n    # Insertion des donn\u00e9es\n    df.to_sql('transactions', conn, if_exists='append', index=False)\n\n    return \"Data loaded successfully\"\n\n# D\u00e9finition du DAG\ndefault_args = {\n    'owner': 'data_team',\n    'depends_on_past': False,\n    'start_date': datetime(2024, 1, 1),\n    'email_on_failure': True,\n    'email_on_retry': False,\n    'retries': 1,\n    'retry_delay': timedelta(minutes=5)\n}\n\ndag = DAG(\n    'data_pipeline',\n    default_args=default_args,\n    description='Pipeline ETL quotidien',\n    schedule_interval=timedelta(days=1),\n    catchup=False\n)\n\n# D\u00e9finition des t\u00e2ches\nextract_task = PythonOperator(\n    task_id='extract_data',\n    python_callable=extract_data,\n    dag=dag\n)\n\ntransform_task = PythonOperator(\n    task_id='transform_data',\n    python_callable=transform_data,\n    dag=dag\n)\n\nload_task = PythonOperator(\n    task_id='load_data',\n    python_callable=load_data,\n    dag=dag\n)\n\n# D\u00e9finition des d\u00e9pendances\nextract_task &gt;&gt; transform_task &gt;&gt; load_task\n</code></pre>"},{"location":"skills/data-engineering/#3-api-de-donnees","title":"3. API de donn\u00e9es","text":"<pre><code>from fastapi import FastAPI, HTTPException, Depends\nfrom pydantic import BaseModel\nimport redis\nimport json\nimport pandas as pd\nimport psycopg2\nfrom sqlalchemy import create_engine\n\napp = FastAPI(title=\"Data API\", version=\"1.0.0\")\n\n# Configuration Redis\nredis_client = redis.Redis(host='localhost', port=6379, db=0)\n\n# Configuration base de donn\u00e9es\nengine = create_engine('postgresql://user:password@localhost/analytics')\n\nclass DataRequest(BaseModel):\n    start_date: str\n    end_date: str\n    filters: dict = {}\n\nclass DataResponse(BaseModel):\n    data: list\n    total_records: int\n    execution_time: float\n\n@app.post(\"/data\", response_model=DataResponse)\nasync def get_data(request: DataRequest):\n    import time\n    start_time = time.time()\n\n    # V\u00e9rification du cache\n    cache_key = f\"data:{hash(str(request.dict()))}\"\n    cached_result = redis_client.get(cache_key)\n\n    if cached_result:\n        result = json.loads(cached_result)\n        result['execution_time'] = time.time() - start_time\n        return DataResponse(**result)\n\n    # Requ\u00eate \u00e0 la base de donn\u00e9es\n    query = f\"\"\"\n    SELECT * FROM transactions \n    WHERE date BETWEEN '{request.start_date}' AND '{request.end_date}'\n    \"\"\"\n\n    # Application des filtres\n    if request.filters:\n        for key, value in request.filters.items():\n            query += f\" AND {key} = '{value}'\"\n\n    # Ex\u00e9cution de la requ\u00eate\n    df = pd.read_sql(query, engine)\n\n    # Pr\u00e9paration de la r\u00e9ponse\n    result = {\n        'data': df.to_dict('records'),\n        'total_records': len(df),\n        'execution_time': time.time() - start_time\n    }\n\n    # Mise en cache\n    redis_client.setex(cache_key, 3600, json.dumps(result))\n\n    return DataResponse(**result)\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\"status\": \"healthy\", \"timestamp\": time.time()}\n</code></pre>"},{"location":"skills/data-engineering/#4-monitoring-et-alertes","title":"4. Monitoring et alertes","text":"<pre><code>import logging\nfrom prometheus_client import Counter, Histogram, generate_latest\nfrom flask import Flask, Response\n\n# M\u00e9triques Prometheus\nREQUEST_COUNT = Counter('data_requests_total', 'Total requests')\nREQUEST_LATENCY = Histogram('data_request_duration_seconds', 'Request latency')\nERROR_COUNT = Counter('data_errors_total', 'Total errors')\n\n# Configuration du logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    handlers=[\n        logging.FileHandler('data_pipeline.log'),\n        logging.StreamHandler()\n    ]\n)\n\nlogger = logging.getLogger(__name__)\n\n@app.middleware(\"http\")\nasync def add_process_time_header(request, call_next):\n    start_time = time.time()\n\n    try:\n        response = await call_next(request)\n        REQUEST_COUNT.inc()\n        REQUEST_LATENCY.observe(time.time() - start_time)\n        return response\n    except Exception as e:\n        ERROR_COUNT.inc()\n        logger.error(f\"Error processing request: {str(e)}\")\n        raise HTTPException(status_code=500, detail=str(e))\n\n@app.get(\"/metrics\")\nasync def metrics():\n    return Response(generate_latest(), media_type=\"text/plain\")\n</code></pre>"},{"location":"skills/data-engineering/#metriques-de-performance","title":"\ud83d\udcc8 M\u00e9triques de performance","text":""},{"location":"skills/data-engineering/#pipeline-etl","title":"Pipeline ETL","text":"M\u00e9trique Valeur Description Throughput 10M records/day Volume trait\u00e9 par jour Latence 2 minutes Temps de traitement Disponibilit\u00e9 99.9% Uptime du pipeline Erreurs &lt; 0.1% Taux d'erreur"},{"location":"skills/data-engineering/#api-de-donnees","title":"API de donn\u00e9es","text":"M\u00e9trique Valeur Description QPS 1000 req/s Requ\u00eates par seconde Latence 50ms Temps de r\u00e9ponse Disponibilit\u00e9 99.9% Uptime de l'API Cache Hit Rate 85% Taux de cache"},{"location":"skills/data-engineering/#bonnes-pratiques","title":"\ud83c\udfaf Bonnes pratiques","text":""},{"location":"skills/data-engineering/#architecture","title":"Architecture","text":"<ul> <li>Scalabilit\u00e9 : Design horizontal</li> <li>R\u00e9silience : Gestion des erreurs</li> <li>Monitoring : M\u00e9triques et alertes</li> <li>Documentation : Code et architecture</li> </ul>"},{"location":"skills/data-engineering/#developpement","title":"D\u00e9veloppement","text":"<ul> <li>Versioning : Git et DVC</li> <li>Testing : Tests unitaires et d'int\u00e9gration</li> <li>CI/CD : Automatisation des d\u00e9ploiements</li> <li>Code Review : Validation par les pairs</li> </ul>"},{"location":"skills/data-engineering/#operations","title":"Op\u00e9rations","text":"<ul> <li>Monitoring : Prometheus, Grafana</li> <li>Logging : ELK Stack</li> <li>Alerting : PagerDuty, Slack</li> <li>Backup : Strat\u00e9gies de sauvegarde</li> </ul>"},{"location":"skills/data-engineering/#deploiement","title":"\ud83d\ude80 D\u00e9ploiement","text":""},{"location":"skills/data-engineering/#docker","title":"Docker","text":"<pre><code>FROM python:3.9-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY . .\n\nEXPOSE 8000\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre>"},{"location":"skills/data-engineering/#kubernetes","title":"Kubernetes","text":"<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: data-api\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: data-api\n  template:\n    metadata:\n      labels:\n        app: data-api\n    spec:\n      containers:\n      - name: data-api\n        image: data-api:latest\n        ports:\n        - containerPort: 8000\n        env:\n        - name: DATABASE_URL\n          value: \"postgresql://user:password@db:5432/analytics\"\n        - name: REDIS_URL\n          value: \"redis://redis:6379\"\n</code></pre>"},{"location":"skills/data-engineering/#ressources-dapprentissage","title":"\ud83d\udcda Ressources d'apprentissage","text":""},{"location":"skills/data-engineering/#cours-recommandes","title":"Cours recommand\u00e9s","text":"<ul> <li>Udacity : Data Engineering Nanodegree</li> <li>Coursera : Big Data Specialization</li> <li>edX : Data Engineering with Python</li> </ul>"},{"location":"skills/data-engineering/#livres-essentiels","title":"Livres essentiels","text":"<ul> <li>Designing Data-Intensive Applications (Martin Kleppmann)</li> <li>Data Engineering Handbook (Data Engineering Team)</li> <li>Building Real-Time Data Pipelines (Ben Stopford)</li> </ul>"},{"location":"skills/data-engineering/#pratique","title":"Pratique","text":"<ul> <li>Apache Spark : Documentation officielle</li> <li>Airflow : Documentation officielle</li> <li>Docker : Documentation officielle</li> <li>Kubernetes : Documentation officielle</li> </ul> <p>Derni\u00e8re mise \u00e0 jour : October 22, 2025</p>"},{"location":"skills/deep-learning/","title":"\ud83e\udde0 Deep Learning","text":"<p>Expertise en deep learning avec 3+ ann\u00e9es d'exp\u00e9rience et 10+ projets r\u00e9alis\u00e9s.</p>"},{"location":"skills/deep-learning/#competences-principales","title":"\ud83c\udfaf Comp\u00e9tences principales","text":""},{"location":"skills/deep-learning/#architectures-de-reseaux","title":"Architectures de r\u00e9seaux","text":"<ul> <li>CNN : ResNet, VGG, EfficientNet, MobileNet</li> <li>RNN/LSTM : S\u00e9ries temporelles, NLP</li> <li>Transformers : BERT, GPT, Vision Transformer</li> <li>GANs : DCGAN, StyleGAN, CycleGAN</li> <li>Autoencoders : Variational Autoencoders (VAE)</li> </ul>"},{"location":"skills/deep-learning/#frameworks-et-outils","title":"Frameworks et outils","text":"<ul> <li>PyTorch : Framework principal (3 ans)</li> <li>TensorFlow/Keras : Framework secondaire (2 ans)</li> <li>Hugging Face : Transformers, Datasets</li> <li>Weights &amp; Biases : Exp\u00e9rimentation</li> <li>ONNX : Optimisation et d\u00e9ploiement</li> </ul>"},{"location":"skills/deep-learning/#domaines-dapplication","title":"Domaines d'application","text":"<ul> <li>Computer Vision : Classification, D\u00e9tection, Segmentation</li> <li>NLP : Sentiment Analysis, Text Classification, NER</li> <li>Time Series : Pr\u00e9diction, Anomaly Detection</li> <li>Reinforcement Learning : Q-Learning, Policy Gradient</li> </ul>"},{"location":"skills/deep-learning/#stack-technique","title":"\ud83d\udee0\ufe0f Stack technique","text":""},{"location":"skills/deep-learning/#frameworks-principaux","title":"Frameworks principaux","text":"<pre><code># PyTorch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision.transforms as transforms\n\n# Hugging Face\nfrom transformers import BertTokenizer, BertForSequenceClassification\nfrom transformers import TrainingArguments, Trainer\n\n# Computer Vision\nimport torchvision.models as models\nimport cv2\nfrom PIL import Image\n</code></pre>"},{"location":"skills/deep-learning/#outils-de-developpement","title":"Outils de d\u00e9veloppement","text":"<ul> <li>Jupyter Lab : D\u00e9veloppement interactif</li> <li>Weights &amp; Biases : Suivi des exp\u00e9riences</li> <li>MLflow : Gestion des mod\u00e8les</li> <li>Docker : Conteneurisation</li> </ul>"},{"location":"skills/deep-learning/#projets-realises","title":"\ud83d\udcca Projets r\u00e9alis\u00e9s","text":""},{"location":"skills/deep-learning/#classification-dimages-medicales","title":"Classification d'images m\u00e9dicales","text":"<p>Technologies : ResNet50, Transfer Learning, PyTorch R\u00e9sultat : 95.2% d'accuracy sur 10K images Impact : R\u00e9duction de 40% du temps de diagnostic</p>"},{"location":"skills/deep-learning/#analyse-de-sentiment-en-temps-reel","title":"Analyse de sentiment en temps r\u00e9el","text":"<p>Technologies : BERT, Transformers, FastAPI R\u00e9sultat : 94.5% d'accuracy, 50ms de latence Impact : API d\u00e9ploy\u00e9e avec 99.9% de disponibilit\u00e9</p>"},{"location":"skills/deep-learning/#detection-danomalies-industrielles","title":"D\u00e9tection d'anomalies industrielles","text":"<p>Technologies : CNN, OpenCV, YOLO R\u00e9sultat : 99.5% de pr\u00e9cision, 40% de r\u00e9duction des d\u00e9fauts Impact : Am\u00e9lioration significative de la qualit\u00e9</p>"},{"location":"skills/deep-learning/#methodologie","title":"\ud83d\udd2c M\u00e9thodologie","text":""},{"location":"skills/deep-learning/#1-preparation-des-donnees","title":"1. Pr\u00e9paration des donn\u00e9es","text":"<pre><code>import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom PIL import Image\n\nclass CustomDataset(Dataset):\n    def __init__(self, data, labels, transform=None):\n        self.data = data\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        image = self.data[idx]\n        label = self.labels[idx]\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n\n# Transformations pour l'augmentation de donn\u00e9es\ntrain_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                        std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                        std=[0.229, 0.224, 0.225])\n])\n</code></pre>"},{"location":"skills/deep-learning/#2-architecture-de-modele","title":"2. Architecture de mod\u00e8le","text":"<pre><code>import torch.nn as nn\nimport torchvision.models as models\n\nclass CustomCNN(nn.Module):\n    def __init__(self, num_classes=10, pretrained=True):\n        super(CustomCNN, self).__init__()\n\n        # Backbone pr\u00e9-entra\u00een\u00e9\n        if pretrained:\n            self.backbone = models.resnet50(pretrained=True)\n            # Geler les premi\u00e8res couches\n            for param in self.backbone.parameters():\n                param.requires_grad = False\n\n            # D\u00e9geler les derni\u00e8res couches\n            for param in self.backbone.layer4.parameters():\n                param.requires_grad = True\n\n        # Classification head\n        num_features = self.backbone.fc.in_features\n        self.backbone.fc = nn.Sequential(\n            nn.Dropout(0.5),\n            nn.Linear(num_features, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, num_classes)\n        )\n\n    def forward(self, x):\n        return self.backbone(x)\n\n# Initialisation du mod\u00e8le\nmodel = CustomCNN(num_classes=10, pretrained=True)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\n</code></pre>"},{"location":"skills/deep-learning/#3-entrainement","title":"3. Entra\u00eenement","text":"<pre><code>import torch.optim as optim\nfrom torch.utils.data import DataLoader\n\ndef train_epoch(model, train_loader, criterion, optimizer, device):\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = output.max(1)\n        total += target.size(0)\n        correct += predicted.eq(target).sum().item()\n\n        if batch_idx % 100 == 0:\n            print(f'Batch {batch_idx}, Loss: {loss.item():.4f}')\n\n    return running_loss / len(train_loader), 100. * correct / total\n\ndef validate_epoch(model, val_loader, criterion, device):\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n\n    with torch.no_grad():\n        for data, target in val_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            loss = criterion(output, target)\n\n            running_loss += loss.item()\n            _, predicted = output.max(1)\n            total += target.size(0)\n            correct += predicted.eq(target).sum().item()\n\n    return running_loss / len(val_loader), 100. * correct / total\n\n# Configuration de l'entra\u00eenement\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n\n# Boucle d'entra\u00eenement\nnum_epochs = 50\nbest_val_acc = 0\n\nfor epoch in range(num_epochs):\n    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n    val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n\n    scheduler.step(val_loss)\n\n    print(f'Epoch {epoch+1}/{num_epochs}:')\n    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n\n    # Sauvegarde du meilleur mod\u00e8le\n    if val_acc &gt; best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), 'best_model.pth')\n\n    print('-' * 50)\n</code></pre>"},{"location":"skills/deep-learning/#4-evaluation","title":"4. \u00c9valuation","text":"<pre><code>from sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\ndef evaluate_model(model, test_loader, device):\n    model.eval()\n    all_preds = []\n    all_targets = []\n    all_probs = []\n\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            probs = torch.softmax(output, dim=1)\n            _, predicted = output.max(1)\n\n            all_preds.extend(predicted.cpu().numpy())\n            all_targets.extend(target.cpu().numpy())\n            all_probs.extend(probs.cpu().numpy())\n\n    return np.array(all_preds), np.array(all_targets), np.array(all_probs)\n\n# \u00c9valuation finale\npredictions, targets, probabilities = evaluate_model(model, test_loader, device)\nprint(classification_report(targets, predictions))\n</code></pre>"},{"location":"skills/deep-learning/#metriques-de-performance","title":"\ud83d\udcc8 M\u00e9triques de performance","text":""},{"location":"skills/deep-learning/#computer-vision","title":"Computer Vision","text":"M\u00e9trique Valeur Description Accuracy 95.2% Pr\u00e9cision globale Precision 94.8% Pr\u00e9cision par classe Recall 95.1% Rappel par classe F1-Score 94.9% Score F1 harmonique AUC-ROC 0.98 Aire sous la courbe ROC"},{"location":"skills/deep-learning/#nlp","title":"NLP","text":"M\u00e9trique Valeur Description Accuracy 94.5% Pr\u00e9cision globale Precision 94.1% Pr\u00e9cision par classe Recall 94.8% Rappel par classe F1-Score 94.4% Score F1 harmonique Latence 50ms Temps de pr\u00e9diction"},{"location":"skills/deep-learning/#bonnes-pratiques","title":"\ud83c\udfaf Bonnes pratiques","text":""},{"location":"skills/deep-learning/#architecture","title":"Architecture","text":"<ul> <li>Transfer Learning : Utiliser des mod\u00e8les pr\u00e9-entra\u00een\u00e9s</li> <li>Regularization : Dropout, Batch Normalization</li> <li>Data Augmentation : Rotation, Flip, Color Jitter</li> <li>Ensemble Methods : Combinaison de mod\u00e8les</li> </ul>"},{"location":"skills/deep-learning/#entrainement","title":"Entra\u00eenement","text":"<ul> <li>Learning Rate Scheduling : ReduceLROnPlateau</li> <li>Early Stopping : \u00c9viter le surapprentissage</li> <li>Gradient Clipping : Stabiliser l'entra\u00eenement</li> <li>Mixed Precision : Acc\u00e9l\u00e9rer l'entra\u00eenement</li> </ul>"},{"location":"skills/deep-learning/#evaluation","title":"\u00c9valuation","text":"<ul> <li>Cross-Validation : Validation robuste</li> <li>Ablation Studies : Analyse des composants</li> <li>Error Analysis : Compr\u00e9hension des erreurs</li> <li>Visualization : Grad-CAM, t-SNE</li> </ul>"},{"location":"skills/deep-learning/#deploiement","title":"\ud83d\ude80 D\u00e9ploiement","text":""},{"location":"skills/deep-learning/#optimisation","title":"Optimisation","text":"<pre><code>import torch.onnx\nimport onnx\nimport onnxruntime\n\n# Conversion ONNX\ndummy_input = torch.randn(1, 3, 224, 224)\ntorch.onnx.export(\n    model, dummy_input, \"model.onnx\",\n    export_params=True, opset_version=11,\n    do_constant_folding=True,\n    input_names=['input'], output_names=['output']\n)\n\n# Validation ONNX\nonnx_model = onnx.load(\"model.onnx\")\nonnx.checker.check_model(onnx_model)\n</code></pre>"},{"location":"skills/deep-learning/#api-de-prediction","title":"API de pr\u00e9diction","text":"<pre><code>from fastapi import FastAPI, File, UploadFile\nimport torch\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport io\n\napp = FastAPI(title=\"Deep Learning Prediction API\")\n\n# Chargement du mod\u00e8le\nmodel = torch.load('best_model.pth', map_location='cpu')\nmodel.eval()\n\n# Transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                        std=[0.229, 0.224, 0.225])\n])\n\n@app.post(\"/predict\")\nasync def predict(file: UploadFile = File(...)):\n    # Lecture de l'image\n    image = Image.open(io.BytesIO(await file.read()))\n\n    # Pr\u00e9processing\n    image_tensor = transform(image).unsqueeze(0)\n\n    # Pr\u00e9diction\n    with torch.no_grad():\n        outputs = model(image_tensor)\n        probabilities = torch.softmax(outputs, dim=1)\n        predicted_class = torch.argmax(probabilities, dim=1).item()\n        confidence = probabilities[0][predicted_class].item()\n\n    return {\n        \"predicted_class\": predicted_class,\n        \"confidence\": float(confidence),\n        \"probabilities\": probabilities[0].tolist()\n    }\n</code></pre>"},{"location":"skills/deep-learning/#ressources-dapprentissage","title":"\ud83d\udcda Ressources d'apprentissage","text":""},{"location":"skills/deep-learning/#cours-recommandes","title":"Cours recommand\u00e9s","text":"<ul> <li>Fast.ai : Practical Deep Learning for Coders</li> <li>Coursera : Deep Learning Specialization (Andrew Ng)</li> <li>Udacity : Deep Learning Nanodegree</li> </ul>"},{"location":"skills/deep-learning/#livres-essentiels","title":"Livres essentiels","text":"<ul> <li>Deep Learning (Ian Goodfellow)</li> <li>Hands-On Machine Learning (Aur\u00e9lien G\u00e9ron)</li> <li>Pattern Recognition and Machine Learning (Christopher Bishop)</li> </ul>"},{"location":"skills/deep-learning/#pratique","title":"Pratique","text":"<ul> <li>Papers with Code : Recherche et impl\u00e9mentations</li> <li>Hugging Face : Mod\u00e8les et datasets</li> <li>PyTorch : Documentation officielle</li> <li>Weights &amp; Biases : Exp\u00e9rimentation</li> </ul> <p>Derni\u00e8re mise \u00e0 jour : October 22, 2025</p>"},{"location":"skills/machine-learning/","title":"\ud83e\udd16 Machine Learning","text":"<p>Expertise en machine learning avec 5+ ann\u00e9es d'exp\u00e9rience et 20+ projets r\u00e9alis\u00e9s.</p>"},{"location":"skills/machine-learning/#competences-principales","title":"\ud83c\udfaf Comp\u00e9tences principales","text":""},{"location":"skills/machine-learning/#algorithmes-supervises","title":"Algorithmes supervis\u00e9s","text":"<ul> <li>Classification : Random Forest, SVM, XGBoost, LightGBM</li> <li>R\u00e9gression : Linear Regression, Ridge, Lasso, Elastic Net</li> <li>Ensemble Methods : Bagging, Boosting, Stacking</li> <li>Feature Selection : Recursive Feature Elimination, L1 Regularization</li> </ul>"},{"location":"skills/machine-learning/#algorithmes-non-supervises","title":"Algorithmes non-supervis\u00e9s","text":"<ul> <li>Clustering : K-Means, DBSCAN, Hierarchical Clustering</li> <li>Dimensionality Reduction : PCA, t-SNE, UMAP</li> <li>Anomaly Detection : Isolation Forest, One-Class SVM</li> <li>Association Rules : Apriori, FP-Growth</li> </ul>"},{"location":"skills/machine-learning/#optimisation-et-validation","title":"Optimisation et validation","text":"<ul> <li>Hyperparameter Tuning : Grid Search, Random Search, Bayesian Optimization</li> <li>Cross-Validation : K-Fold, Stratified, Time Series Split</li> <li>Model Selection : AIC, BIC, Cross-Validation</li> <li>Feature Engineering : Polynomial Features, Interaction Terms</li> </ul>"},{"location":"skills/machine-learning/#stack-technique","title":"\ud83d\udee0\ufe0f Stack technique","text":""},{"location":"skills/machine-learning/#frameworks-principaux","title":"Frameworks principaux","text":"<pre><code># Scikit-learn\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\n# XGBoost\nimport xgboost as xgb\nfrom xgboost import XGBClassifier, XGBRegressor\n\n# LightGBM\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier, LGBMRegressor\n</code></pre>"},{"location":"skills/machine-learning/#outils-de-developpement","title":"Outils de d\u00e9veloppement","text":"<ul> <li>Jupyter Notebooks : Exploration et prototypage</li> <li>MLflow : Gestion des exp\u00e9riences</li> <li>Optuna : Optimisation des hyperparam\u00e8tres</li> <li>SHAP : Explicabilit\u00e9 des mod\u00e8les</li> </ul>"},{"location":"skills/machine-learning/#projets-realises","title":"\ud83d\udcca Projets r\u00e9alis\u00e9s","text":""},{"location":"skills/machine-learning/#classification-dimages-medicales","title":"Classification d'images m\u00e9dicales","text":"<p>Technologies : Random Forest, Feature Engineering R\u00e9sultat : 95.2% d'accuracy sur 10K images Impact : R\u00e9duction de 40% du temps de diagnostic</p>"},{"location":"skills/machine-learning/#prediction-de-prix-immobiliers","title":"Pr\u00e9diction de prix immobiliers","text":"<p>Technologies : XGBoost, Feature Engineering R\u00e9sultat : RMSE 0.15, R\u00b2 0.87 Impact : Am\u00e9lioration de 30% de la pr\u00e9cision</p>"},{"location":"skills/machine-learning/#segmentation-de-clients","title":"Segmentation de clients","text":"<p>Technologies : K-Means, PCA, Feature Engineering R\u00e9sultat : 4 segments identifi\u00e9s avec 85% de coh\u00e9rence Impact : +25% de conversion marketing</p>"},{"location":"skills/machine-learning/#methodologie","title":"\ud83d\udd2c M\u00e9thodologie","text":""},{"location":"skills/machine-learning/#1-analyse-exploratoire","title":"1. Analyse exploratoire","text":"<pre><code>import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Chargement et exploration\ndf = pd.read_csv('data.csv')\nprint(df.info())\nprint(df.describe())\n\n# Visualisation des distributions\nplt.figure(figsize=(12, 8))\ndf.hist(bins=50, figsize=(12, 8))\nplt.show()\n\n# Matrice de corr\u00e9lation\ncorrelation_matrix = df.corr()\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\nplt.show()\n</code></pre>"},{"location":"skills/machine-learning/#2-preprocessing","title":"2. Pr\u00e9processing","text":"<pre><code>from sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Nettoyage des donn\u00e9es\ndf = df.dropna()\ndf = df.drop_duplicates()\n\n# Encodage des variables cat\u00e9gorielles\nle = LabelEncoder()\ndf['categorical_var'] = le.fit_transform(df['categorical_var'])\n\n# Normalisation\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Division train/test\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n</code></pre>"},{"location":"skills/machine-learning/#3-feature-engineering","title":"3. Feature Engineering","text":"<pre><code># Cr\u00e9ation de nouvelles features\ndf['feature_ratio'] = df['var1'] / df['var2']\ndf['feature_interaction'] = df['var1'] * df['var2']\ndf['feature_polynomial'] = df['var1'] ** 2\n\n# S\u00e9lection des features\nfrom sklearn.feature_selection import SelectKBest, f_classif\nselector = SelectKBest(f_classif, k=10)\nX_selected = selector.fit_transform(X, y)\n\n# Importance des features\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\nfeature_importance = rf.feature_importances_\n</code></pre>"},{"location":"skills/machine-learning/#4-modelisation","title":"4. Mod\u00e9lisation","text":"<pre><code>from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nimport xgboost as xgb\n\n# Mod\u00e8les \u00e0 comparer\nmodels = {\n    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n    'SVM': SVC(random_state=42),\n    'Logistic Regression': LogisticRegression(random_state=42),\n    'XGBoost': xgb.XGBClassifier(random_state=42)\n}\n\n# Entra\u00eenement et \u00e9valuation\nresults = {}\nfor name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    results[name] = accuracy\n    print(f\"{name}: {accuracy:.3f}\")\n</code></pre>"},{"location":"skills/machine-learning/#5-optimisation-des-hyperparametres","title":"5. Optimisation des hyperparam\u00e8tres","text":"<pre><code>from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer, f1_score\n\n# Grille de param\u00e8tres pour XGBoost\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [3, 6, 9],\n    'learning_rate': [0.01, 0.1, 0.2],\n    'subsample': [0.8, 0.9, 1.0]\n}\n\n# Recherche par grille\ngrid_search = GridSearchCV(\n    xgb.XGBClassifier(random_state=42),\n    param_grid,\n    cv=5,\n    scoring='f1_weighted',\n    n_jobs=-1\n)\n\ngrid_search.fit(X_train, y_train)\nprint(\"Meilleurs param\u00e8tres:\", grid_search.best_params_)\nprint(\"Meilleur score:\", grid_search.best_score_)\n</code></pre>"},{"location":"skills/machine-learning/#6-evaluation-et-validation","title":"6. \u00c9valuation et validation","text":"<pre><code>from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\nfrom sklearn.model_selection import cross_val_score\n\n# M\u00e9triques de performance\ny_pred = grid_search.best_estimator_.predict(X_test)\nprint(classification_report(y_test, y_pred))\n\n# Matrice de confusion\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Matrice de confusion')\nplt.show()\n\n# Validation crois\u00e9e\ncv_scores = cross_val_score(\n    grid_search.best_estimator_, X, y, cv=5, scoring='f1_weighted'\n)\nprint(f\"CV Score: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n</code></pre>"},{"location":"skills/machine-learning/#metriques-de-performance","title":"\ud83d\udcc8 M\u00e9triques de performance","text":""},{"location":"skills/machine-learning/#classification","title":"Classification","text":"M\u00e9trique Valeur Description Accuracy 94.2% Pr\u00e9cision globale Precision 93.8% Pr\u00e9cision par classe Recall 94.1% Rappel par classe F1-Score 93.9% Score F1 harmonique AUC-ROC 0.96 Aire sous la courbe ROC"},{"location":"skills/machine-learning/#regression","title":"R\u00e9gression","text":"M\u00e9trique Valeur Description RMSE 0.15 Racine de l'erreur quadratique MAE 0.12 Erreur absolue moyenne R\u00b2 0.87 Coefficient de d\u00e9termination MAPE 15.2% Erreur absolue en pourcentage"},{"location":"skills/machine-learning/#bonnes-pratiques","title":"\ud83c\udfaf Bonnes pratiques","text":""},{"location":"skills/machine-learning/#preprocessing","title":"Pr\u00e9processing","text":"<ul> <li>Gestion des valeurs manquantes : Imputation intelligente</li> <li>Normalisation : StandardScaler pour la plupart des algorithmes</li> <li>Encodage : LabelEncoder pour les variables ordinales</li> <li>Feature Engineering : Cr\u00e9ation de features m\u00e9tier</li> </ul>"},{"location":"skills/machine-learning/#modelisation","title":"Mod\u00e9lisation","text":"<ul> <li>Validation crois\u00e9e : Toujours utiliser CV pour l'\u00e9valuation</li> <li>Hyperparameter tuning : Optimisation syst\u00e9matique</li> <li>Ensemble methods : Combinaison de mod\u00e8les</li> <li>Feature selection : R\u00e9duction de la dimensionnalit\u00e9</li> </ul>"},{"location":"skills/machine-learning/#evaluation","title":"\u00c9valuation","text":"<ul> <li>M\u00e9triques appropri\u00e9es : Choix selon le probl\u00e8me</li> <li>Validation temporelle : Pour les donn\u00e9es temporelles</li> <li>Test A/B : Validation en conditions r\u00e9elles</li> <li>Monitoring : Suivi des performances en production</li> </ul>"},{"location":"skills/machine-learning/#deploiement","title":"\ud83d\ude80 D\u00e9ploiement","text":""},{"location":"skills/machine-learning/#mlops","title":"MLOps","text":"<pre><code>import mlflow\nimport mlflow.sklearn\nimport joblib\n\n# Sauvegarde du mod\u00e8le\nmlflow.sklearn.log_model(\n    grid_search.best_estimator_, \n    \"model\",\n    registered_model_name=\"best_model\"\n)\n\n# Sauvegarde des pr\u00e9processeurs\njoblib.dump(scaler, 'scaler.pkl')\njoblib.dump(le, 'label_encoder.pkl')\n</code></pre>"},{"location":"skills/machine-learning/#api-de-prediction","title":"API de pr\u00e9diction","text":"<pre><code>from fastapi import FastAPI\nimport joblib\nimport pandas as pd\n\napp = FastAPI()\n\n# Chargement du mod\u00e8le\nmodel = joblib.load('best_model.pkl')\nscaler = joblib.load('scaler.pkl')\n\n@app.post(\"/predict\")\nasync def predict(data: dict):\n    # Pr\u00e9processing\n    df = pd.DataFrame([data])\n    df_scaled = scaler.transform(df)\n\n    # Pr\u00e9diction\n    prediction = model.predict(df_scaled)\n    probability = model.predict_proba(df_scaled)\n\n    return {\n        \"prediction\": int(prediction[0]),\n        \"probability\": float(probability[0].max())\n    }\n</code></pre>"},{"location":"skills/machine-learning/#ressources-dapprentissage","title":"\ud83d\udcda Ressources d'apprentissage","text":""},{"location":"skills/machine-learning/#cours-recommandes","title":"Cours recommand\u00e9s","text":"<ul> <li>Coursera : Machine Learning (Stanford)</li> <li>Udacity : Machine Learning Engineer Nanodegree</li> <li>Fast.ai : Practical Machine Learning for Coders</li> </ul>"},{"location":"skills/machine-learning/#livres-essentiels","title":"Livres essentiels","text":"<ul> <li>Hands-On Machine Learning (Aur\u00e9lien G\u00e9ron)</li> <li>The Elements of Statistical Learning (Hastie, Tibshirani, Friedman)</li> <li>Pattern Recognition and Machine Learning (Christopher Bishop)</li> </ul>"},{"location":"skills/machine-learning/#pratique","title":"Pratique","text":"<ul> <li>Kaggle : Comp\u00e9titions et datasets</li> <li>Scikit-learn : Documentation officielle</li> <li>Papers with Code : Recherche et impl\u00e9mentations</li> </ul> <p>Derni\u00e8re mise \u00e0 jour : October 22, 2025</p>"},{"location":"skills/visualisation/","title":"\ud83d\udcca Visualisation de donn\u00e9es","text":"<p>Expertise en visualisation de donn\u00e9es avec 4+ ann\u00e9es d'exp\u00e9rience et 15+ projets r\u00e9alis\u00e9s.</p>"},{"location":"skills/visualisation/#competences-principales","title":"\ud83c\udfaf Comp\u00e9tences principales","text":""},{"location":"skills/visualisation/#bibliotheques-python","title":"Biblioth\u00e8ques Python","text":"<ul> <li>Matplotlib : Visualisations statiques et interactives</li> <li>Seaborn : Visualisations statistiques avanc\u00e9es</li> <li>Plotly : Graphiques interactifs et dashboards</li> <li>Bokeh : Visualisations web interactives</li> <li>Altair : Grammaire de graphiques</li> </ul>"},{"location":"skills/visualisation/#outils-de-bi","title":"Outils de BI","text":"<ul> <li>Tableau : Dashboards et rapports</li> <li>Power BI : Visualisations Microsoft</li> <li>Grafana : Monitoring et m\u00e9triques</li> <li>D3.js : Visualisations web personnalis\u00e9es</li> </ul>"},{"location":"skills/visualisation/#types-de-visualisations","title":"Types de visualisations","text":"<ul> <li>Statistiques : Histogrammes, Box plots, Scatter plots</li> <li>Temporelles : Time series, Gantt charts</li> <li>G\u00e9ographiques : Cartes, Heat maps</li> <li>Hi\u00e9rarchiques : Treemaps, Sunburst</li> <li>R\u00e9seaux : Graph networks, Sankey diagrams</li> </ul>"},{"location":"skills/visualisation/#stack-technique","title":"\ud83d\udee0\ufe0f Stack technique","text":""},{"location":"skills/visualisation/#bibliotheques-python_1","title":"Biblioth\u00e8ques Python","text":"<pre><code># Matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom matplotlib.patches import Rectangle\n\n# Seaborn\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nsns.set_palette(\"husl\")\n\n# Plotly\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Pandas\nimport pandas as pd\nimport numpy as np\n</code></pre>"},{"location":"skills/visualisation/#outils-de-developpement","title":"Outils de d\u00e9veloppement","text":"<ul> <li>Jupyter Lab : D\u00e9veloppement interactif</li> <li>Streamlit : Applications web rapides</li> <li>Dash : Dashboards interactifs</li> <li>Bokeh : Visualisations web</li> </ul>"},{"location":"skills/visualisation/#projets-realises","title":"\ud83d\udcca Projets r\u00e9alis\u00e9s","text":""},{"location":"skills/visualisation/#dashboard-de-ventes-e-commerce","title":"Dashboard de ventes e-commerce","text":"<p>Technologies : Plotly, Dash, PostgreSQL R\u00e9sultat : Dashboard interactif avec 10+ graphiques Impact : Am\u00e9lioration de 25% de l'analyse des ventes</p>"},{"location":"skills/visualisation/#visualisation-de-donnees-geographiques","title":"Visualisation de donn\u00e9es g\u00e9ographiques","text":"<p>Technologies : Folium, GeoPandas, OpenStreetMap R\u00e9sultat : Cartes interactives avec 50K+ points Impact : Identification de 5 zones \u00e0 fort potentiel</p>"},{"location":"skills/visualisation/#analyse-de-sentiment-en-temps-reel","title":"Analyse de sentiment en temps r\u00e9el","text":"<p>Technologies : Matplotlib, Seaborn, Real-time data R\u00e9sultat : Graphiques temps r\u00e9el avec 1K+ points/seconde Impact : Monitoring en temps r\u00e9el des opinions</p>"},{"location":"skills/visualisation/#methodologie","title":"\ud83d\udd2c M\u00e9thodologie","text":""},{"location":"skills/visualisation/#1-exploration-des-donnees","title":"1. Exploration des donn\u00e9es","text":"<pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Chargement des donn\u00e9es\ndf = pd.read_csv('data.csv')\n\n# Statistiques descriptives\nprint(df.describe())\n\n# Visualisation de la distribution\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# Histogramme\naxes[0, 0].hist(df['price'], bins=50, alpha=0.7)\naxes[0, 0].set_title('Distribution des prix')\naxes[0, 0].set_xlabel('Prix')\naxes[0, 0].set_ylabel('Fr\u00e9quence')\n\n# Box plot\naxes[0, 1].boxplot(df['price'])\naxes[0, 1].set_title('Box plot des prix')\naxes[0, 1].set_ylabel('Prix')\n\n# Scatter plot\naxes[1, 0].scatter(df['area'], df['price'], alpha=0.5)\naxes[1, 0].set_title('Prix vs Surface')\naxes[1, 0].set_xlabel('Surface')\naxes[1, 0].set_ylabel('Prix')\n\n# Corr\u00e9lation\ncorrelation_matrix = df.corr()\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', ax=axes[1, 1])\naxes[1, 1].set_title('Matrice de corr\u00e9lation')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"skills/visualisation/#2-visualisations-avancees","title":"2. Visualisations avanc\u00e9es","text":"<pre><code>import plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n# Graphique interactif avec Plotly\nfig = px.scatter(df, x='area', y='price', color='district',\n                 size='rooms', hover_data=['price', 'area'],\n                 title='Prix vs Surface par district')\n\nfig.update_layout(\n    title_font_size=20,\n    xaxis_title=\"Surface (m\u00b2)\",\n    yaxis_title=\"Prix (\u20ac)\",\n    legend_title=\"District\"\n)\n\nfig.show()\n\n# Graphique en barres empil\u00e9es\nfig = px.bar(df, x='district', y='price', color='type',\n             title='Prix par district et type de bien')\n\nfig.update_layout(\n    xaxis_title=\"District\",\n    yaxis_title=\"Prix moyen (\u20ac)\",\n    legend_title=\"Type de bien\"\n)\n\nfig.show()\n</code></pre>"},{"location":"skills/visualisation/#3-dashboards-interactifs","title":"3. Dashboards interactifs","text":"<pre><code>import dash\nfrom dash import dcc, html, Input, Output\nimport plotly.express as px\nimport pandas as pd\n\n# Initialisation de l'application Dash\napp = dash.Dash(__name__)\n\n# Layout du dashboard\napp.layout = html.Div([\n    html.H1(\"Dashboard de ventes\", style={'textAlign': 'center'}),\n\n    # Filtres\n    html.Div([\n        html.Label(\"S\u00e9lectionner le district:\"),\n        dcc.Dropdown(\n            id='district-dropdown',\n            options=[{'label': i, 'value': i} for i in df['district'].unique()],\n            value=df['district'].unique()[0]\n        )\n    ], style={'width': '30%', 'display': 'inline-block'}),\n\n    # Graphiques\n    dcc.Graph(id='price-chart'),\n    dcc.Graph(id='area-chart')\n])\n\n# Callbacks pour l'interactivit\u00e9\n@app.callback(\n    [Output('price-chart', 'figure'),\n     Output('area-chart', 'figure')],\n    [Input('district-dropdown', 'value')]\n)\ndef update_charts(selected_district):\n    filtered_df = df[df['district'] == selected_district]\n\n    # Graphique des prix\n    price_fig = px.histogram(filtered_df, x='price', nbins=30,\n                           title=f'Distribution des prix - {selected_district}')\n\n    # Graphique des surfaces\n    area_fig = px.scatter(filtered_df, x='area', y='price',\n                         title=f'Prix vs Surface - {selected_district}')\n\n    return price_fig, area_fig\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre>"},{"location":"skills/visualisation/#4-visualisations-geographiques","title":"4. Visualisations g\u00e9ographiques","text":"<pre><code>import folium\nimport geopandas as gpd\nfrom folium import plugins\n\n# Cr\u00e9ation d'une carte interactive\nm = folium.Map(location=[48.8566, 2.3522], zoom_start=12)\n\n# Ajout de marqueurs\nfor idx, row in df.iterrows():\n    folium.Marker(\n        location=[row['latitude'], row['longitude']],\n        popup=f\"Prix: {row['price']}\u20ac&lt;br&gt;Surface: {row['area']}m\u00b2\",\n        icon=folium.Icon(color='red', icon='home')\n    ).add_to(m)\n\n# Heatmap\nheat_data = [[row['latitude'], row['longitude']] for idx, row in df.iterrows()]\nplugins.HeatMap(heat_data).add_to(m)\n\n# Sauvegarde de la carte\nm.save('map.html')\n</code></pre>"},{"location":"skills/visualisation/#types-de-visualisations_1","title":"\ud83d\udcc8 Types de visualisations","text":""},{"location":"skills/visualisation/#visualisations-statistiques","title":"Visualisations statistiques","text":"<pre><code># Histogramme avec distribution normale\nfig, ax = plt.subplots(figsize=(10, 6))\nax.hist(df['price'], bins=50, alpha=0.7, density=True, label='Donn\u00e9es')\nax.axvline(df['price'].mean(), color='red', linestyle='--', label='Moyenne')\nax.axvline(df['price'].median(), color='green', linestyle='--', label='M\u00e9diane')\nax.set_xlabel('Prix (\u20ac)')\nax.set_ylabel('Densit\u00e9')\nax.set_title('Distribution des prix')\nax.legend()\nplt.show()\n\n# Box plot par groupe\nfig, ax = plt.subplots(figsize=(12, 6))\nsns.boxplot(data=df, x='district', y='price', ax=ax)\nax.set_title('Distribution des prix par district')\nax.set_xlabel('District')\nax.set_ylabel('Prix (\u20ac)')\nplt.xticks(rotation=45)\nplt.show()\n</code></pre>"},{"location":"skills/visualisation/#visualisations-temporelles","title":"Visualisations temporelles","text":"<pre><code># Time series\nfig, ax = plt.subplots(figsize=(15, 6))\ndf_time = df.groupby('date')['price'].mean().reset_index()\nax.plot(df_time['date'], df_time['price'], linewidth=2)\nax.set_title('\u00c9volution du prix moyen dans le temps')\nax.set_xlabel('Date')\nax.set_ylabel('Prix moyen (\u20ac)')\nplt.xticks(rotation=45)\nplt.show()\n\n# Graphique en aires empil\u00e9es\nfig = px.area(df, x='date', y='price', color='district',\n              title='\u00c9volution des prix par district')\nfig.show()\n</code></pre>"},{"location":"skills/visualisation/#visualisations-geographiques","title":"Visualisations g\u00e9ographiques","text":"<pre><code># Carte de chaleur\nfig = px.density_mapbox(df, lat='latitude', lon='longitude', z='price',\n                        radius=10, center=dict(lat=48.8566, lon=2.3522),\n                        zoom=10, mapbox_style=\"open-street-map\")\nfig.update_layout(title=\"Carte de chaleur des prix\")\nfig.show()\n</code></pre>"},{"location":"skills/visualisation/#bonnes-pratiques","title":"\ud83c\udfaf Bonnes pratiques","text":""},{"location":"skills/visualisation/#design","title":"Design","text":"<ul> <li>Couleurs : Palette coh\u00e9rente et accessible</li> <li>Typographie : Lisibilit\u00e9 et hi\u00e9rarchie</li> <li>Espacement : \u00c9quilibre et clart\u00e9</li> <li>Interactivit\u00e9 : Engagement utilisateur</li> </ul>"},{"location":"skills/visualisation/#performance","title":"Performance","text":"<ul> <li>Optimisation : R\u00e9duction de la complexit\u00e9</li> <li>Caching : Mise en cache des donn\u00e9es</li> <li>Lazy loading : Chargement \u00e0 la demande</li> <li>Responsive : Adaptation aux \u00e9crans</li> </ul>"},{"location":"skills/visualisation/#accessibilite","title":"Accessibilit\u00e9","text":"<ul> <li>Contraste : Respect des standards WCAG</li> <li>Couleurs : Support daltonien</li> <li>Navigation : Clavier et lecteurs d'\u00e9cran</li> <li>Texte : Descriptions et l\u00e9gendes</li> </ul>"},{"location":"skills/visualisation/#deploiement","title":"\ud83d\ude80 D\u00e9ploiement","text":""},{"location":"skills/visualisation/#streamlit","title":"Streamlit","text":"<pre><code>import streamlit as st\nimport plotly.express as px\nimport pandas as pd\n\n# Configuration de la page\nst.set_page_config(page_title=\"Dashboard\", layout=\"wide\")\n\n# Titre\nst.title(\"Dashboard de ventes\")\n\n# Sidebar avec filtres\nst.sidebar.header(\"Filtres\")\ndistrict = st.sidebar.selectbox(\"District\", df['district'].unique())\nprice_range = st.sidebar.slider(\"Fourchette de prix\", \n                               int(df['price'].min()), \n                               int(df['price'].max()),\n                               (int(df['price'].min()), int(df['price'].max())))\n\n# Filtrage des donn\u00e9es\nfiltered_df = df[(df['district'] == district) &amp; \n                 (df['price'] &gt;= price_range[0]) &amp; \n                 (df['price'] &lt;= price_range[1])]\n\n# M\u00e9triques\ncol1, col2, col3, col4 = st.columns(4)\nwith col1:\n    st.metric(\"Nombre de biens\", len(filtered_df))\nwith col2:\n    st.metric(\"Prix moyen\", f\"{filtered_df['price'].mean():,.0f}\u20ac\")\nwith col3:\n    st.metric(\"Surface moyenne\", f\"{filtered_df['area'].mean():.0f}m\u00b2\")\nwith col4:\n    st.metric(\"Prix au m\u00b2\", f\"{filtered_df['price'].mean()/filtered_df['area'].mean():.0f}\u20ac/m\u00b2\")\n\n# Graphiques\nfig = px.scatter(filtered_df, x='area', y='price', color='type',\n                 title='Prix vs Surface par type de bien')\nst.plotly_chart(fig, use_container_width=True)\n</code></pre>"},{"location":"skills/visualisation/#dash","title":"Dash","text":"<pre><code>import dash\nfrom dash import dcc, html, Input, Output\nimport plotly.express as px\n\napp = dash.Dash(__name__)\n\napp.layout = html.Div([\n    html.H1(\"Dashboard de ventes\"),\n    dcc.Graph(id='scatter-plot'),\n    dcc.Slider(\n        id='price-slider',\n        min=df['price'].min(),\n        max=df['price'].max(),\n        value=df['price'].max(),\n        marks={str(price): str(price) for price in df['price'].unique()},\n        step=None\n    )\n])\n\n@app.callback(\n    Output('scatter-plot', 'figure'),\n    Input('price-slider', 'value')\n)\ndef update_figure(selected_price):\n    filtered_df = df[df['price'] &lt;= selected_price]\n    fig = px.scatter(filtered_df, x='area', y='price', color='type')\n    return fig\n\nif __name__ == '__main__':\n    app.run_server(debug=True)\n</code></pre>"},{"location":"skills/visualisation/#ressources-dapprentissage","title":"\ud83d\udcda Ressources d'apprentissage","text":""},{"location":"skills/visualisation/#cours-recommandes","title":"Cours recommand\u00e9s","text":"<ul> <li>Coursera : Data Visualization with Python</li> <li>Udacity : Data Visualization Nanodegree</li> <li>edX : Data Visualization Fundamentals</li> </ul>"},{"location":"skills/visualisation/#livres-essentiels","title":"Livres essentiels","text":"<ul> <li>The Visual Display of Quantitative Information (Edward Tufte)</li> <li>Storytelling with Data (Cole Nussbaumer Knaflic)</li> <li>Data Visualization (Kieran Healy)</li> </ul>"},{"location":"skills/visualisation/#pratique","title":"Pratique","text":"<ul> <li>Matplotlib : Documentation officielle</li> <li>Seaborn : Documentation officielle</li> <li>Plotly : Documentation officielle</li> <li>D3.js : Documentation officielle</li> </ul> <p>Derni\u00e8re mise \u00e0 jour : October 22, 2025</p>"}]}