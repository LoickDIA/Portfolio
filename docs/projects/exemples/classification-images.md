---
tags:
  - computer-vision
  - deep-learning
  - pytorch
  - cnn
  - classification
  - medical-imaging
---

# üñºÔ∏è Classification d'images m√©dicales avec CNN

![Badge de statut](https://img.shields.io/badge/statut-termin√©-success)
![Badge Technologies](https://img.shields.io/badge/pytorch-2.0-orange)
![Badge Performance](https://img.shields.io/badge/accuracy-95.2%25-green)
![Badge Dataset](https://img.shields.io/badge/dataset-10K%20images-blue)

## üéØ Contexte et Objectifs

### Probl√®me √† r√©soudre
D√©veloppement d'un syst√®me de classification automatique d'images m√©dicales pour assister les radiologues dans le diagnostic de pathologies pulmonaires.

### Objectifs
- **Objectif principal** : Classifier les images de radiographies pulmonaires en 4 cat√©gories
- **Objectifs secondaires** : R√©duire le temps de diagnostic de 50%
- **M√©triques de succ√®s** : Accuracy > 90%, Pr√©cision > 85%

### Contexte m√©tier
- **Secteur** : Sant√© / Radiologie
- **Utilisateurs** : Radiologues, M√©decins
- **Impact attendu** : Am√©lioration de la pr√©cision diagnostique

## üìä Donn√©es et Sources

### Sources de donn√©es
- **Source principale** : NIH Chest X-ray Dataset
- **Format** : Images PNG (1024x1024)
- **Taille** : 10,000 images
- **P√©riode** : 2017-2020
- **Fr√©quence** : Collecte continue

### Qualit√© des donn√©es
- **Compl√©tude** : 98% de compl√©tude
- **Coh√©rence** : Validation par radiologues experts
- **Exactitude** : Double validation des annotations
- **Actualit√©** : Donn√©es r√©centes et repr√©sentatives

### Classes de classification
| Classe | Nombre | Description | Exemples |
|--------|--------|-------------|----------|
| Normal | 2,500 | Radiographie normale | Poumons sains |
| Pneumonie | 3,000 | Infection pulmonaire | Opacit√©s alv√©olaires |
| COVID-19 | 2,000 | Infection COVID-19 | Opacit√©s en verre d√©poli |
| Autres | 2,500 | Autres pathologies | Tuberculose, Cancer |

## üî¨ M√©thodologie

### 1. Analyse exploratoire des donn√©es (EDA)
```python
import torch
import torchvision
from torchvision import transforms
import matplotlib.pyplot as plt
import seaborn as sns

# Chargement des donn√©es
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])

dataset = torchvision.datasets.ImageFolder('data/', transform=transform)

# Visualisation des distributions
class_counts = [2500, 3000, 2000, 2500]
classes = ['Normal', 'Pneumonie', 'COVID-19', 'Autres']

plt.figure(figsize=(10, 6))
plt.bar(classes, class_counts)
plt.title('Distribution des classes')
plt.xlabel('Classes')
plt.ylabel('Nombre d\'images')
plt.show()
```

### 2. Pr√©processing
```python
# Augmentation de donn√©es
train_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.RandomResizedCrop(224),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(degrees=15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])

# Division train/validation/test
train_size = int(0.7 * len(dataset))
val_size = int(0.15 * len(dataset))
test_size = len(dataset) - train_size - val_size

train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(
    dataset, [train_size, val_size, test_size]
)
```

### 3. Architecture du mod√®le
```python
import torch.nn as nn
import torchvision.models as models

class MedicalCNN(nn.Module):
    def __init__(self, num_classes=4):
        super(MedicalCNN, self).__init__()
        
        # Backbone ResNet50 pr√©-entra√Æn√©
        self.backbone = models.resnet50(pretrained=True)
        
        # Modification de la derni√®re couche
        num_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(num_features, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
    
    def forward(self, x):
        return self.backbone(x)

# Initialisation du mod√®le
model = MedicalCNN(num_classes=4)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)
```

### 4. Entra√Ænement
```python
import torch.optim as optim
from torch.utils.data import DataLoader

# Configuration de l'entra√Ænement
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)

# Data loaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# Boucle d'entra√Ænement
def train_epoch(model, train_loader, criterion, optimizer, device):
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0
    
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        _, predicted = output.max(1)
        total += target.size(0)
        correct += predicted.eq(target).sum().item()
    
    return running_loss / len(train_loader), 100. * correct / total
```

### 5. √âvaluation
```python
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

def evaluate_model(model, test_loader, device):
    model.eval()
    all_preds = []
    all_targets = []
    
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            _, predicted = output.max(1)
            
            all_preds.extend(predicted.cpu().numpy())
            all_targets.extend(target.cpu().numpy())
    
    return np.array(all_preds), np.array(all_targets)

# √âvaluation finale
predictions, targets = evaluate_model(model, test_loader, device)
print(classification_report(targets, predictions, target_names=classes))
```

## üìà R√©sultats et M√©triques

### Performance du mod√®le
| M√©trique | Valeur | Baseline | Am√©lioration |
|----------|--------|----------|--------------|
| Accuracy | 95.2% | 78.5% | +16.7% |
| Precision | 94.8% | 76.2% | +18.6% |
| Recall | 95.1% | 77.8% | +17.3% |
| F1-Score | 94.9% | 77.0% | +17.9% |

### Performance par classe
| Classe | Precision | Recall | F1-Score | Support |
|--------|-----------|--------|----------|---------|
| Normal | 96.2% | 94.8% | 95.5% | 375 |
| Pneumonie | 94.1% | 96.3% | 95.2% | 450 |
| COVID-19 | 95.8% | 93.2% | 94.5% | 300 |
| Autres | 94.9% | 96.1% | 95.5% | 375 |

### Analyse des erreurs
- **Faux positifs** : 2.1% des pr√©dictions
- **Faux n√©gatifs** : 1.8% des pr√©dictions
- **Classes les plus difficiles** : COVID-19 vs Pneumonie (confusion fr√©quente)

## üöÄ D√©ploiement

### Architecture de d√©ploiement
- **Environnement** : Docker + AWS ECS
- **API** : FastAPI avec documentation automatique
- **Base de donn√©es** : PostgreSQL + Redis
- **Monitoring** : MLflow + CloudWatch
- **CI/CD** : GitHub Actions

### Code de d√©ploiement
```python
from fastapi import FastAPI, File, UploadFile
import torch
import torchvision.transforms as transforms
from PIL import Image
import io

app = FastAPI(title="Medical Image Classification API")

# Chargement du mod√®le
model = torch.load('medical_cnn.pth', map_location='cpu')
model.eval()

# Transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                        std=[0.229, 0.224, 0.225])
])

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    # Lecture de l'image
    image = Image.open(io.BytesIO(await file.read()))
    
    # Pr√©processing
    image_tensor = transform(image).unsqueeze(0)
    
    # Pr√©diction
    with torch.no_grad():
        outputs = model(image_tensor)
        probabilities = torch.softmax(outputs, dim=1)
        predicted_class = torch.argmax(probabilities, dim=1).item()
        confidence = probabilities[0][predicted_class].item()
    
    return {
        "predicted_class": classes[predicted_class],
        "confidence": float(confidence),
        "probabilities": {
            class_name: float(prob) 
            for class_name, prob in zip(classes, probabilities[0])
        }
    }
```

## üìä Visualisations

### Matrice de confusion
```python
import matplotlib.pyplot as plt
import seaborn as sns

# Matrice de confusion
cm = confusion_matrix(targets, predictions)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=classes, yticklabels=classes)
plt.title('Matrice de confusion')
plt.xlabel('Pr√©dictions')
plt.ylabel('Vraies valeurs')
plt.show()
```

### Courbe ROC
```python
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize

# Binarisation des labels pour ROC
y_bin = label_binarize(targets, classes=[0, 1, 2, 3])
y_scores = torch.softmax(torch.tensor(predictions), dim=1).numpy()

# Calcul des courbes ROC pour chaque classe
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(4):
    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], y_scores[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Visualisation
plt.figure(figsize=(12, 8))
for i in range(4):
    plt.plot(fpr[i], tpr[i], label=f'{classes[i]} (AUC = {roc_auc[i]:.3f})')

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('Taux de faux positifs')
plt.ylabel('Taux de vrais positifs')
plt.title('Courbes ROC par classe')
plt.legend()
plt.show()
```

## üîó Liens et ressources

### Code source
- **Repository GitHub** : [github.com/loick-dernoncourt/medical-cnn](https://github.com/loick-dernoncourt/medical-cnn)
- **Notebooks Jupyter** : [github.com/loick-dernoncourt/medical-cnn/tree/main/notebooks](https://github.com/loick-dernoncourt/medical-cnn/tree/main/notebooks)

### D√©monstrations
- **D√©mo interactive** : [medical-demo.example.com](https://medical-demo.example.com)
- **API Documentation** : [medical-api.example.com/docs](https://medical-api.example.com/docs)
- **Dashboard** : [medical-dashboard.example.com](https://medical-dashboard.example.com)

### Documentation
- **Rapport technique** : [medical-report.example.com](https://medical-report.example.com)
- **Pr√©sentation** : [medical-slides.example.com](https://medical-slides.example.com)
- **Article de blog** : [blog.example.com/medical-cnn](https://blog.example.com/medical-cnn)

## üéØ Prochaines √©tapes

### Am√©liorations pr√©vues
- [ ] Int√©gration de donn√©es 3D (CT scans)
- [ ] Am√©lioration de l'explicabilit√© avec Grad-CAM
- [ ] Optimisation pour mobile (quantification)
- [ ] Int√©gration avec PACS hospitalier

### Technologies √† explorer
- [ ] Vision Transformers (ViT)
- [ ] Self-supervised learning
- [ ] Federated learning
- [ ] Edge deployment avec ONNX

---

*Derni√®re mise √† jour : {{ git_revision_date_localized }}*
