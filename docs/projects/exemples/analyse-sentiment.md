---
tags:
  - nlp
  - deep-learning
  - bert
  - transformers
  - sentiment-analysis
  - fastapi
  - real-time
---

# üí¨ Analyse de sentiment en temps r√©el avec BERT

![Badge de statut](https://img.shields.io/badge/statut-termin√©-success)
![Badge Technologies](https://img.shields.io/badge/bert-transformers-orange)
![Badge Performance](https://img.shields.io/badge/accuracy-94.5%25-green)
![Badge Latence](https://img.shields.io/badge/latence-50ms-blue)

## üéØ Contexte et Objectifs

### Probl√®me √† r√©soudre
D√©veloppement d'un syst√®me d'analyse de sentiment en temps r√©el pour monitorer l'opinion publique sur les r√©seaux sociaux et les plateformes de e-commerce.

### Objectifs
- **Objectif principal** : Classifier le sentiment de textes en 3 cat√©gories (Positif, N√©gatif, Neutre)
- **Objectifs secondaires** : Traitement en temps r√©el avec latence < 100ms
- **M√©triques de succ√®s** : Accuracy > 90%, Latence < 100ms

### Contexte m√©tier
- **Secteur** : E-commerce / Social Media
- **Utilisateurs** : √âquipes marketing, Customer success
- **Impact attendu** : Am√©lioration de 30% de la satisfaction client

## üìä Donn√©es et Sources

### Sources de donn√©es
- **Source principale** : Twitter API + Amazon Reviews
- **Format** : JSON (texte + m√©tadonn√©es)
- **Taille** : 500,000 tweets + 100,000 avis
- **P√©riode** : 2022-2024
- **Fr√©quence** : Collecte en temps r√©el

### Qualit√© des donn√©es
- **Compl√©tude** : 92% de compl√©tude
- **Coh√©rence** : Validation par annotateurs experts
- **Exactitude** : Inter-annotateur agreement > 85%
- **Actualit√©** : Donn√©es r√©centes et repr√©sentatives

### Distribution des classes
| Classe | Nombre | Pourcentage | Description |
|--------|--------|-------------|-------------|
| Positif | 200,000 | 40% | Sentiment positif |
| N√©gatif | 150,000 | 30% | Sentiment n√©gatif |
| Neutre | 150,000 | 30% | Sentiment neutre |

## üî¨ M√©thodologie

### 1. Analyse exploratoire des donn√©es (EDA)
```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud

# Chargement des donn√©es
df = pd.read_json('sentiment_data.json')

# Visualisation de la distribution
plt.figure(figsize=(12, 6))
df['sentiment'].value_counts().plot(kind='bar')
plt.title('Distribution des sentiments')
plt.xlabel('Sentiment')
plt.ylabel('Nombre d\'√©chantillons')
plt.show()

# Nuage de mots par sentiment
for sentiment in df['sentiment'].unique():
    text = ' '.join(df[df['sentiment'] == sentiment]['text'])
    wordcloud = WordCloud(width=800, height=400).generate(text)
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.title(f'Nuage de mots - {sentiment}')
    plt.axis('off')
    plt.show()
```

### 2. Pr√©processing
```python
import re
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize

# T√©l√©chargement des ressources NLTK
nltk.download('stopwords')
nltk.download('punkt')

def preprocess_text(text):
    # Nettoyage du texte
    text = re.sub(r'@\w+|#\w+', '', text)  # Suppression des mentions
    text = re.sub(r'http\S+|www\S+|https\S+', '', text)  # Suppression des URLs
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Suppression de la ponctuation
    text = text.lower()  # Minuscules
    
    # Tokenisation
    tokens = word_tokenize(text)
    
    # Suppression des stop words
    stop_words = set(stopwords.words('french'))
    tokens = [token for token in tokens if token not in stop_words]
    
    return ' '.join(tokens)

# Application du preprocessing
df['cleaned_text'] = df['text'].apply(preprocess_text)
```

### 3. Mod√©lisation avec BERT
```python
from transformers import BertTokenizer, BertForSequenceClassification
from transformers import TrainingArguments, Trainer
import torch
from torch.utils.data import Dataset

class SentimentDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, max_length=128):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = self.labels[idx]
        
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }

# Initialisation du mod√®le BERT
model_name = 'bert-base-multilingual-cased'
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertForSequenceClassification.from_pretrained(
    model_name, 
    num_labels=3
)

# Pr√©paration des donn√©es
train_dataset = SentimentDataset(
    train_texts, train_labels, tokenizer
)
val_dataset = SentimentDataset(
    val_texts, val_labels, tokenizer
)
```

### 4. Entra√Ænement
```python
from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    
    precision, recall, f1, _ = precision_recall_fscore_support(
        labels, predictions, average='weighted'
    )
    accuracy = accuracy_score(labels, predictions)
    
    return {
        'accuracy': accuracy,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

# Configuration de l'entra√Ænement
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir='./logs',
    logging_steps=100,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
)

# Entra√Æneur
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
)

# Entra√Ænement
trainer.train()
```

### 5. √âvaluation
```python
# √âvaluation sur le jeu de test
test_results = trainer.evaluate(test_dataset)
print(f"Accuracy: {test_results['eval_accuracy']:.3f}")
print(f"F1-Score: {test_results['eval_f1']:.3f}")

# Pr√©dictions sur des exemples
def predict_sentiment(text, model, tokenizer):
    inputs = tokenizer(
        text, 
        return_tensors='pt', 
        truncation=True, 
        padding=True, 
        max_length=128
    )
    
    with torch.no_grad():
        outputs = model(**inputs)
        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
        predicted_class = torch.argmax(predictions, dim=-1).item()
        confidence = predictions[0][predicted_class].item()
    
    return predicted_class, confidence

# Test sur des exemples
examples = [
    "J'adore ce produit, il est fantastique !",
    "Service client d√©cevant, je ne recommande pas.",
    "Le produit est correct, rien de sp√©cial."
]

for example in examples:
    pred_class, confidence = predict_sentiment(example, model, tokenizer)
    sentiment = ['N√©gatif', 'Neutre', 'Positif'][pred_class]
    print(f"Texte: {example}")
    print(f"Sentiment: {sentiment} (Confiance: {confidence:.3f})")
    print()
```

## üìà R√©sultats et M√©triques

### Performance du mod√®le
| M√©trique | Valeur | Baseline | Am√©lioration |
|----------|--------|----------|--------------|
| Accuracy | 94.5% | 78.2% | +16.3% |
| Precision | 94.1% | 76.8% | +17.3% |
| Recall | 94.8% | 77.5% | +17.3% |
| F1-Score | 94.4% | 77.1% | +17.3% |

### Performance par classe
| Classe | Precision | Recall | F1-Score | Support |
|--------|-----------|--------|----------|---------|
| Positif | 95.2% | 93.8% | 94.5% | 1,000 |
| N√©gatif | 94.1% | 96.3% | 95.2% | 1,000 |
| Neutre | 93.8% | 94.2% | 94.0% | 1,000 |

### M√©triques de performance
- **Latence moyenne** : 45ms
- **Throughput** : 1000 requ√™tes/minute
- **Disponibilit√©** : 99.9%

## üöÄ D√©ploiement

### Architecture de d√©ploiement
- **Environnement** : Docker + AWS ECS
- **API** : FastAPI avec documentation automatique
- **Base de donn√©es** : Redis pour le cache
- **Monitoring** : CloudWatch + Custom metrics
- **CI/CD** : GitHub Actions

### Code de d√©ploiement
```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import torch
from transformers import BertTokenizer, BertForSequenceClassification
import redis
import json
import time

app = FastAPI(title="Sentiment Analysis API")

# Configuration Redis
redis_client = redis.Redis(host='localhost', port=6379, db=0)

# Chargement du mod√®le
model = BertForSequenceClassification.from_pretrained('./model')
tokenizer = BertTokenizer.from_pretrained('./model')
model.eval()

class TextInput(BaseModel):
    text: str

class SentimentOutput(BaseModel):
    sentiment: str
    confidence: float
    processing_time: float

@app.post("/predict", response_model=SentimentOutput)
async def predict_sentiment(input_data: TextInput):
    start_time = time.time()
    
    # V√©rification du cache
    cache_key = f"sentiment:{hash(input_data.text)}"
    cached_result = redis_client.get(cache_key)
    
    if cached_result:
        result = json.loads(cached_result)
        result['processing_time'] = time.time() - start_time
        return SentimentOutput(**result)
    
    # Pr√©diction
    inputs = tokenizer(
        input_data.text, 
        return_tensors='pt', 
        truncation=True, 
        padding=True, 
        max_length=128
    )
    
    with torch.no_grad():
        outputs = model(**inputs)
        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
        predicted_class = torch.argmax(predictions, dim=-1).item()
        confidence = predictions[0][predicted_class].item()
    
    sentiment_labels = ['N√©gatif', 'Neutre', 'Positif']
    sentiment = sentiment_labels[predicted_class]
    
    result = {
        'sentiment': sentiment,
        'confidence': float(confidence),
        'processing_time': time.time() - start_time
    }
    
    # Mise en cache
    redis_client.setex(cache_key, 3600, json.dumps(result))
    
    return SentimentOutput(**result)

@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": time.time()}
```

### Monitoring
```python
import logging
from prometheus_client import Counter, Histogram, generate_latest

# M√©triques Prometheus
REQUEST_COUNT = Counter('sentiment_requests_total', 'Total requests')
REQUEST_LATENCY = Histogram('sentiment_request_duration_seconds', 'Request latency')
PREDICTION_ACCURACY = Histogram('sentiment_prediction_confidence', 'Prediction confidence')

@app.middleware("http")
async def add_process_time_header(request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    
    REQUEST_COUNT.inc()
    REQUEST_LATENCY.observe(process_time)
    
    response.headers["X-Process-Time"] = str(process_time)
    return response

@app.get("/metrics")
async def metrics():
    return Response(generate_latest(), media_type="text/plain")
```

## üìä Visualisations

### Matrice de confusion
```python
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Matrice de confusion
cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['N√©gatif', 'Neutre', 'Positif'],
            yticklabels=['N√©gatif', 'Neutre', 'Positif'])
plt.title('Matrice de confusion')
plt.xlabel('Pr√©dictions')
plt.ylabel('Vraies valeurs')
plt.show()
```

### Analyse des erreurs
```python
# Analyse des erreurs de classification
errors = df[df['true_sentiment'] != df['predicted_sentiment']]

# Mots les plus fr√©quents dans les erreurs
error_words = []
for text in errors['text']:
    words = text.split()
    error_words.extend(words)

from collections import Counter
word_freq = Counter(error_words)
print("Mots les plus fr√©quents dans les erreurs:")
print(word_freq.most_common(10))
```

## üîó Liens et ressources

### Code source
- **Repository GitHub** : [github.com/loick-dernoncourt/sentiment-analysis](https://github.com/loick-dernoncourt/sentiment-analysis)
- **Notebooks Jupyter** : [github.com/loick-dernoncourt/sentiment-analysis/tree/main/notebooks](https://github.com/loick-dernoncourt/sentiment-analysis/tree/main/notebooks)

### D√©monstrations
- **D√©mo interactive** : [sentiment-demo.example.com](https://sentiment-demo.example.com)
- **API Documentation** : [sentiment-api.example.com/docs](https://sentiment-api.example.com/docs)
- **Dashboard** : [sentiment-dashboard.example.com](https://sentiment-dashboard.example.com)

### Documentation
- **Rapport technique** : [sentiment-report.example.com](https://sentiment-report.example.com)
- **Pr√©sentation** : [sentiment-slides.example.com](https://sentiment-slides.example.com)
- **Article de blog** : [blog.example.com/sentiment-analysis](https://blog.example.com/sentiment-analysis)

## üéØ Prochaines √©tapes

### Am√©liorations pr√©vues
- [ ] Support multilingue (anglais, espagnol)
- [ ] Analyse d'√©motions (joie, col√®re, tristesse)
- [ ] Int√©gration avec les r√©seaux sociaux
- [ ] Dashboard de monitoring en temps r√©el

### Technologies √† explorer
- [ ] RoBERTa pour de meilleures performances
- [ ] DistilBERT pour la latence
- [ ] ONNX pour l'optimisation
- [ ] Kafka pour le streaming

---

*Derni√®re mise √† jour : {{ git_revision_date_localized }}*
